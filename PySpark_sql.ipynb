{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbc4565",
   "metadata": {},
   "source": [
    "# Outline\n",
    "- [ 1 - Setup ](#1)\n",
    "\n",
    "\n",
    "- [ 2 - Load MAS tables](#2)\n",
    "\n",
    "\n",
    "- [ 3 - Load dblp xml](#3)\n",
    "\n",
    "\n",
    "- [ 4 - Query tasks](#4)\n",
    "\n",
    "    - [ 4.1 - List all the papers (year and title) of “Divesh Srivastava”from DBLP that are published after his last paper in the MAS database ](#4.1)\n",
    "        - [4.1.1 - Query 1 result](#4.1.1)\n",
    "        \n",
    "    - [ 4.2 - List the author(s) (names) who have collaborated most (in terms of number of publications) with “Divesh Srivastava”other than himself based on MAS database and DBLP data.](#4.2)\n",
    "        - [4.2.1 - Query 2 result](#4.2.1)\n",
    "    \n",
    "    - [ 4.3 - List the number of publications of “Divesh Srivastava”each year based on MAS database and DBLP data. Duplicate papers in both MAS and DBLP should be counted only once in the result.](#4.3)\n",
    "     - [4.3.1 - Query 3 result](#4.3.1)\n",
    "    \n",
    "    - [ 4.4 - Find papers published in 2021 that are relevant to keyword query ‘self attention transformer’ (or 'self-attention transformer'). Treat each paper title as one document and rank them using tf-idf. Return the top 10 relevant papers (title, authors, journal/conference and year).](#4.4)\n",
    "        \n",
    "        - [ 4.4.1 - Dataframe method ](#4.4.1)\n",
    "        \n",
    "        - [ 4.4.2 - With RDD map reduce method ](#4.4.2)\n",
    "            - [4.4.2.1 - Query 4 result](#4.4.2.1)\n",
    "\n",
    "\n",
    "- [ 5 - Preprocess xml to remove HTML escaped characters](#5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f27f4",
   "metadata": {},
   "source": [
    "# 1 - Setup<a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457ff979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#os.environ['HADOOP_HOME'] = r\"C:\\spark-3.1.3-bin-hadoop3.2\"\n",
    "#sys.path.append(r\"C:\\spark-3.1.3-bin-hadoop3.2\")\n",
    "\n",
    "#os.environ['SPARK_HOME'] = r\"C:\\spark-3.1.3-bin-hadoop3.2\"\n",
    "#sys.path.append(r\"C:\\spark-3.1.3-bin-hadoop3.2\")\n",
    "\n",
    "#os.environ['JAVA_HOME'] = r\"C:\\Program Files\\Java\\jdk1.8.0_351\"\n",
    "#sys.path.append(r\"C:\\Program Files\\Java\\jdk1.8.0_351\")\n",
    "\n",
    "#os.environ['CLASSPATH'] = r\"C:\\Program Files\\Java\\jdk1.8.0_351\"\n",
    "#sys.path.append(r\"C:\\Program Files\\Java\\jdk1.8.0_351\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9f89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext, sql\n",
    "\n",
    "from pyspark.sql.functions import array_contains, col, explode, regexp_replace, when, substring, length, expr, arrays_zip\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "       .config(\"spark.driver.memory\", \"9g\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "#df = spark.sql(\"select 'spark' as hello\")\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1686bbe",
   "metadata": {},
   "source": [
    "# 2 - Load MAS tables<a name=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc756eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- oid: integer (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- photo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author_mas = spark.read.format(\"jdbc\").options(\n",
    "    url=\"jdbc:mysql://localhost:3306/mas\",\n",
    "    driver = 'com.mysql.cj.jdbc.Driver',\n",
    "    dbtable = \"author\",\n",
    "    user=\"root\",\n",
    "    password=\"Harsvifsat(5\").load()\n",
    "\n",
    "author_mas.printSchema()\n",
    "author_mas.createOrReplaceTempView(\"author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d65f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pid: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- cid: integer (nullable = true)\n",
      " |-- jid: integer (nullable = true)\n",
      " |-- reference_num: integer (nullable = true)\n",
      " |-- citation_num: integer (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "publication_mas = spark.read.format(\"jdbc\").options(\n",
    "    url=\"jdbc:mysql://localhost:3306/mas\",\n",
    "    driver = 'com.mysql.cj.jdbc.Driver',\n",
    "    dbtable = \"publication\",\n",
    "    user=\"root\",\n",
    "    password=\"Harsvifsat(5\").load()\n",
    "\n",
    "publication_mas.printSchema()\n",
    "publication_mas.createOrReplaceTempView(\"publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d78f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aid: integer (nullable = true)\n",
      " |-- pid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writes_mas = spark.read.format(\"jdbc\").options(\n",
    "    url=\"jdbc:mysql://localhost:3306/mas\",\n",
    "    driver = 'com.mysql.cj.jdbc.Driver',\n",
    "    dbtable = \"writes\",\n",
    "    user=\"root\",\n",
    "    password=\"Harsvifsat(5\").load()\n",
    "\n",
    "writes_mas.printSchema()\n",
    "writes_mas.createOrReplaceTempView(\"writes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b3323",
   "metadata": {},
   "source": [
    "# 3 - Load dblp xml<a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e234cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"_cdate\", DateType(), True),\n",
    "    StructField(\"_key\", StringType(), True),\n",
    "    StructField(\"_mdate\", DateType(), True),\n",
    "    StructField(\"_publtype\", StringType(), True),\n",
    "    StructField(\"author\", \n",
    "                ArrayType(\n",
    "                     StructType([\n",
    "                         StructField(\"_VALUE\", StringType(), True),\n",
    "                         StructField(\"_aux\", StringType(), True),\n",
    "                         StructField(\"_orcid\", StringType(), True),\n",
    "                     ]),True),\n",
    "                True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"year\", LongType(), True),\n",
    "    StructField(\"publnr\", StringType(), True),\n",
    "    StructField(\"journal\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "906835ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _cdate: date (nullable = true)\n",
      " |-- _key: string (nullable = true)\n",
      " |-- _mdate: date (nullable = true)\n",
      " |-- _publtype: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- publnr: string (nullable = true)\n",
      " |-- journal: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_article = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"dblp\") \\\n",
    "    .option(\"rowTag\", \"article\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"dblp_cleaned.xml\")\n",
    "\n",
    "dblp_article.printSchema()\n",
    "dblp_article.createOrReplaceTempView(\"dblp_artv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "37ac9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema2 = StructType([\n",
    "    StructField(\"_key\", StringType(), True),\n",
    "    StructField(\"_mdate\", DateType(), True),\n",
    "    StructField(\"_publtype\", StringType(), True),\n",
    "    StructField(\"author\", \n",
    "                ArrayType(\n",
    "                     StructType([\n",
    "                         StructField(\"_VALUE\", StringType(), True),\n",
    "                         StructField(\"_aux\", StringType(), True),\n",
    "                         StructField(\"_orcid\", StringType(), True),\n",
    "                     ]),True),\n",
    "                True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"year\", LongType(), True),\n",
    "    StructField(\"publnr\", StringType(), True),\n",
    "    StructField(\"booktitle\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "73952a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _key: string (nullable = true)\n",
      " |-- _mdate: date (nullable = true)\n",
      " |-- _publtype: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- publnr: string (nullable = true)\n",
      " |-- booktitle: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_inproceedings = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"dblp\") \\\n",
    "    .option(\"rowTag\", \"inproceedings\") \\\n",
    "    .schema(schema2) \\\n",
    "    .load(\"dblp_cleaned.xml\")\n",
    "\n",
    "dblp_inproceedings.printSchema()\n",
    "dblp_inproceedings.createOrReplaceTempView(\"dblp_inpv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c6824",
   "metadata": {},
   "source": [
    "# 4 - Query Tasks<a name=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055be54",
   "metadata": {},
   "source": [
    "### 4.1 - List all the papers (year and title) of “Divesh Srivastava”from DBLP that are published after his last paper in the MAS database <a name=\"4.1\"></a>\n",
    "There are a few options here: \n",
    "\n",
    "Find the year and month information from DBLP for the last paper in MAS and then return new papers after that. \n",
    "\n",
    "Use the year information from MAS last paper and return papers published in the following year. \n",
    "\n",
    "(NEW!) Find papers in DBLP that are not in MAS database starting from the last year of Divesh's papers in the MAS database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5149b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- max(year): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get last year of Divesh's paper in MAS\n",
    "mas1 = spark.sql(\"select max(p.year) \\\n",
    "    from publication p \\\n",
    "    join writes w \\\n",
    "    on p.pid = w.pid \\\n",
    "    join author a \\\n",
    "    on w.aid = a.aid \\\n",
    "    where a.name = 'Divesh Srivastava' \")\n",
    "\n",
    "mas1.printSchema()\n",
    "mas1.createOrReplaceTempView(\"mas1v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca5fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get papers published by divesh in last year of Divesh's paper in MAS\n",
    "mas2 = spark.sql(\"select p.title \\\n",
    "    from publication p \\\n",
    "    join writes w \\\n",
    "    on p.pid = w.pid \\\n",
    "    join author a \\\n",
    "    on w.aid = a.aid \\\n",
    "    where a.name = 'Divesh Srivastava' \\\n",
    "    and p.year = {}\".format(mas1.collect()[0][0]))\n",
    "\n",
    "mas2.printSchema()\n",
    "mas2.createOrReplaceTempView(\"mas2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b320c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _cdate: date (nullable = true)\n",
      " |-- _key: string (nullable = true)\n",
      " |-- _mdate: date (nullable = true)\n",
      " |-- _publtype: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- publnr: string (nullable = true)\n",
      " |-- journal: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all papers from articles by divesh (need to remove '.' because MAS's titles do not have '.')\n",
    "dblp_filt_art = dblp_article.where(array_contains(col('author._VALUE'), 'Divesh Srivastava'))\n",
    "#dblp_filt_art = dblp_filt_art.withColumn('title', regexp_replace('title', '\\.', ''))\n",
    "dblp_filt_art = dblp_filt_art.withColumn('title', \n",
    "                                         when(dblp_filt_art.title.endswith('.'),expr(\"substring(title, 1, length(title)-1)\"))\n",
    "                                         .otherwise(dblp_filt_art.title))\n",
    "dblp_filt_art.printSchema()\n",
    "dblp_filt_art.createOrReplaceTempView(\"dblp_filt_artv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90b355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _key: string (nullable = true)\n",
      " |-- _mdate: date (nullable = true)\n",
      " |-- _publtype: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- publnr: string (nullable = true)\n",
      " |-- booktitle: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all papers from inproceedings by divesh\n",
    "dblp_filt_inp = dblp_inproceedings.where(array_contains(col('author._VALUE'), 'Divesh Srivastava'))\n",
    "#dblp_filt_inp = dblp_filt_inp.withColumn('title', regexp_replace('title', '\\.', ''))\n",
    "dblp_filt_inp = dblp_filt_inp.withColumn('title', \n",
    "                                         when(dblp_filt_inp.title.endswith('.'),expr(\"substring(title, 1, length(title)-1)\"))\n",
    "                                         .otherwise(dblp_filt_inp.title))\n",
    "dblp_filt_inp.printSchema()\n",
    "dblp_filt_inp.createOrReplaceTempView(\"dblp_filt_inpv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e622ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get divesh's paper in dblp after his last paper in mas\n",
    "dblp1 = spark.sql(\"select distinct upper(d.title) as title, d.year \\\n",
    "    from (select year, title from dblp_filt_artv \\\n",
    "        union \\\n",
    "        select year, title from dblp_filt_inpv \\\n",
    "       ) AS d \\\n",
    "    where d.year >= {} \\\n",
    "    and not exists (select title \\\n",
    "                    from mas2v m \\\n",
    "                    where lower(m.title) = lower(d.title)) \\\n",
    "    order by d.year desc, title asc\".format(mas1.collect()[0][0]))\n",
    "\n",
    "dblp1.printSchema()\n",
    "dblp1.createOrReplaceTempView(\"dblp1v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5fb8dc",
   "metadata": {},
   "source": [
    "### Query 1 result<a name=\"4.1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aef711b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------+----+\n",
      "|title                                                                                                            |year|\n",
      "+-----------------------------------------------------------------------------------------------------------------+----+\n",
      "|ABC OF ORDER DEPENDENCIES                                                                                        |2022|\n",
      "|ABCOD: MINING BAND ORDER DEPENDENCIES                                                                            |2022|\n",
      "|CERTEM: EXPLAINING AND DEBUGGING BLACK-BOX ENTITY RESOLUTION SYSTEMS WITH CERTA                                  |2022|\n",
      "|DATAPRISM: EXPOSING DISCONNECT BETWEEN DATA AND SYSTEMS                                                          |2022|\n",
      "|DISCOVERING DOMAIN ORDERS VIA ORDER DEPENDENCIES                                                                 |2022|\n",
      "|EFFECTIVE EXPLANATIONS FOR ENTITY RESOLUTION MODELS                                                              |2022|\n",
      "|EFFECTIVE KEYWORD SEARCH OVER WEIGHTED GRAPHS                                                                    |2022|\n",
      "|EXPLORING DATA USING PATTERNS: A SURVEY                                                                          |2022|\n",
      "|FINE-TUNING DEPENDENCIES WITH PARAMETERS                                                                         |2022|\n",
      "|HIERARCHICAL ENTITY RESOLUTION USING AN ORACLE                                                                   |2022|\n",
      "|LEDGERVIEW: ACCESS-CONTROL VIEWS ON HYPERLEDGER FABRIC                                                           |2022|\n",
      "|POEM: PATTERN-ORIENTED EXPLANATIONS OF CNN MODELS                                                                |2022|\n",
      "|PUBLICATION CULTURE AND REVIEW PROCESSES IN THE DATA MANAGEMENT COMMUNITY: AN OPEN DISCUSSION                    |2022|\n",
      "|SPECIAL ISSUE ON RESPONSIBLE DATA MANAGEMENT AND DATA SCIENCE                                                    |2022|\n",
      "|SUBGRAPH REPRESENTATION LEARNING FOR TEAM MINING                                                                 |2022|\n",
      "|ALASKA: A FLEXIBLE BENCHMARK FOR DATA INTEGRATION TASKS                                                          |2021|\n",
      "|BEER: BLOCKING FOR EFFECTIVE ENTITY RESOLUTION                                                                   |2021|\n",
      "|CONSTRAINED PRIVATE MECHANISMS FOR COUNT DATA                                                                    |2021|\n",
      "|DATAEXPOSER: EXPOSING DISCONNECT BETWEEN DATA AND SYSTEMS                                                        |2021|\n",
      "|EFFECTIVE KEYWORD SEARCH IN WEIGHTED GRAPHS (EXTENDED ABSTRACT)                                                  |2021|\n",
      "|EFFICIENT AND EFFECTIVE ER WITH PROGRESSIVE BLOCKING                                                             |2021|\n",
      "|EFFICIENT DISCOVERY OF APPROXIMATE ORDER DEPENDENCIES                                                            |2021|\n",
      "|EXPLORING DATA USING PA ERNS: A SURVEY AND OPEN PROBLEMS                                                         |2021|\n",
      "|FRAUD BUSTER: TRACKING IRSF USING BLOCKCHAIN WHILE PROTECTING BUSINESS CONFIDENTIALITY                           |2021|\n",
      "|LETTER FROM THE IMPACT AWARD WINNER                                                                              |2021|\n",
      "|REAL-WORLD TRAJECTORY SHARING WITH LOCAL DIFFERENTIAL PRIVACY                                                    |2021|\n",
      "|RETRIEVING SKILL-BASED TEAMS FROM COLLABORATION NETWORKS                                                         |2021|\n",
      "|SCALABLE SIGNAL RECONSTRUCTION FOR A BROAD RANGE OF APPLICATIONS                                                 |2021|\n",
      "|STRATIFIED RANDOM SAMPLING FROM STREAMING AND STORED DATA                                                        |2021|\n",
      "|STRUCTURED OBJECT MATCHING ACROSS WEB PAGE REVISIONS                                                             |2021|\n",
      "|THE SECRET LIFE OF WIKIPEDIA TABLES                                                                              |2021|\n",
      "|DATA-DRIVEN DOMAIN DISCOVERY FOR STRUCTURED DATASETS                                                             |2020|\n",
      "|DISCOVERING BAND ORDER DEPENDENCIES                                                                              |2020|\n",
      "|DISCOVERING DOMAIN ORDERS THROUGH ORDER DEPENDENCIES                                                             |2020|\n",
      "|EFFECTIVE DISCOVERY OF MEANINGFUL OUTLIER RELATIONSHIPS                                                          |2020|\n",
      "|EFFICIENT AND EFFECTIVE ER WITH PROGRESSIVE BLOCKING                                                             |2020|\n",
      "|ERRATUM FOR DISCOVERING ORDER DEPENDENCIES THROUGH ORDER COMPATIBILITY (EDBT 2019)                               |2020|\n",
      "|LOCAL DAMPENING: DIFFERENTIAL PRIVACY FOR NON-NUMERIC QUERIES VIA LOCAL SENSITIVITY                              |2020|\n",
      "|NATURAL KEY DISCOVERY IN WIKIPEDIA TABLES                                                                        |2020|\n",
      "|ORCA-SR: A REAL-TIME TRAFFIC ENGINEERING FRAMEWORK LEVERAGING SIMILARITY JOINS                                   |2020|\n",
      "|RANDOM SAMPLING FOR GROUP-BY QUERIES                                                                             |2020|\n",
      "|SCALABLE ALGORITHMS FOR SIGNAL RECONSTRUCTION BY LEVERAGING SIMILARITY JOINS                                     |2020|\n",
      "|SMARTMEDIA: LOCALLY AND CONTEXTUALLY-ADAPTED STREAMING MEDIA                                                     |2020|\n",
      "|SUMMARIZING HIERARCHICAL MULTIDIMENSIONAL DATA                                                                   |2020|\n",
      "|TOWARDS HIGH-QUALITY BIG DATA: LESSONS FROM FIT                                                                  |2020|\n",
      "|ANSWERING RANGE QUERIES UNDER LOCAL DIFFERENTIAL PRIVACY                                                         |2019|\n",
      "|BRING ORDER TO DATA                                                                                              |2019|\n",
      "|CROWD-SOURCED ENTITY RESOLUTION WITH CONTROL QUERIES                                                             |2019|\n",
      "|DBCHEX: INTERACTIVE EXPLORATION OF DATA AND SCHEMA CHANGE                                                        |2019|\n",
      "|DISCOVERY OF BAND ORDER DEPENDENCIES                                                                             |2019|\n",
      "|DON'T CRY WOLF                                                                                                   |2019|\n",
      "|EDITORIAL                                                                                                        |2019|\n",
      "|EFFICIENT DISCOVERY OF MEANINGFUL OUTLIER RELATIONSHIPS                                                          |2019|\n",
      "|EFFICIENT SIGNAL RECONSTRUCTION FOR A BROAD RANGE OF APPLICATIONS                                                |2019|\n",
      "|ENSURING HIGH-QUALITY PRIVATE DATA FOR RESPONSIBLE DATA SCIENCE: VISION AND CHALLENGES                           |2019|\n",
      "|ERRATA NOTE: DISCOVERING ORDER DEPENDENCIES THROUGH ORDER COMPATIBILITY                                          |2019|\n",
      "|EXPLORING CHANGE                                                                                                 |2019|\n",
      "|FROM ROCKS TO PEBBLES: SMOOTHING SPATIOTEMPORAL DATA STREAMS IN AN OVERLAY OF SENSORS                            |2019|\n",
      "|INFORMATIVE SUMMARIZATION OF NUMERIC DATA                                                                        |2019|\n",
      "|INTERPRETING DEEP LEARNING MODELS FOR ENTITY RESOLUTION: AN EXPERIENCE REPORT USING LIME                         |2019|\n",
      "|RANDOM SAMPLING FOR GROUP-BY QUERIES                                                                             |2019|\n",
      "|STRATIFIED RANDOM SAMPLING OVER STREAMING AND STORED DATA                                                        |2019|\n",
      "|ANSWERING RANGE QUERIES UNDER LOCAL DIFFERENTIAL PRIVACY                                                         |2018|\n",
      "|BIG DATA INTEGRATION FOR PRODUCT SPECIFICATIONS                                                                  |2018|\n",
      "|BIG DATA LINKAGE FOR PRODUCT SPECIFICATION PAGES                                                                 |2018|\n",
      "|CONSTRAINED PRIVATE MECHANISMS FOR COUNT DATA                                                                    |2018|\n",
      "|DATA CHANGE EXPLORATION USING TIME SERIES CLUSTERING                                                             |2018|\n",
      "|EFFECTIVE AND COMPLETE DISCOVERY OF BIDIRECTIONAL ORDER DEPENDENCIES VIA SET-BASED AXIOMS                        |2018|\n",
      "|EXPLANATION TABLES                                                                                               |2018|\n",
      "|EXPLORING CHANGE - A NEW DIMENSION OF DATA ANALYTICS                                                             |2018|\n",
      "|FASTOD: BRINGING ORDER TO DATA                                                                                   |2018|\n",
      "|FASTQRE: FAST QUERY REVERSE ENGINEERING                                                                          |2018|\n",
      "|GEOFENCES IN THE SKY: HERDING DRONES WITH BLOCKCHAINS AND 5G                                                     |2018|\n",
      "|LESSONS LEARNED AND RESEARCH AGENDA FOR BIG DATA INTEGRATION OF PRODUCT SPECIFICATIONS                           |2018|\n",
      "|LEVERAGING SIMILARITY JOINS FOR SIGNAL RECONSTRUCTION                                                            |2018|\n",
      "|MARGINAL RELEASE UNDER LOCAL DIFFERENTIAL PRIVACY                                                                |2018|\n",
      "|PRIVACY AT SCALE: LOCAL DIFFERENTIAL PRIVACY IN PRACTICE                                                         |2018|\n",
      "|REGAL+: REVERSE ENGINEERING SPJA QUERIES                                                                         |2018|\n",
      "|ROBUST ENTITY RESOLUTION USING A CROWDORACLE                                                                     |2018|\n",
      "|ROBUST ENTITY RESOLUTION USING RANDOM GRAPHS                                                                     |2018|\n",
      "|VARIANCE-OPTIMAL OFFLINE AND STREAMING STRATIFIED RANDOM SAMPLING                                                |2018|\n",
      "|\"TELL ME MORE\" USING LADDERS IN WIKIPEDIA                                                                        |2017|\n",
      "|A TOOL FOR STATISTICAL ANALYSIS ON NETWORK BIG DATA                                                              |2017|\n",
      "|COMPOSING DIFFERENTIAL PRIVACY AND SECURE COMPUTATION: A CASE STUDY ON SCALING PRIVATE RECORD LINKAGE            |2017|\n",
      "|CONSTRAINED DIFFERENTIAL PRIVACY FOR COUNT DATA                                                                  |2017|\n",
      "|DATA QUALITY: THE ROLE OF EMPIRICISM                                                                             |2017|\n",
      "|EFFECTIVE AND COMPLETE DISCOVERY OF ORDER DEPENDENCIES VIA SET-BASED AXIOMATIZATION                              |2017|\n",
      "|ENABLING CHANGE EXPLORATION: VISION PAPER                                                                        |2017|\n",
      "|GEOTAGGING IP PACKETS FOR LOCATION-AWARE SOFTWARE-DEFINED NETWORKING IN THE PRESENCE OF VIRTUAL NETWORK FUNCTIONS|2017|\n",
      "|INTEGRATING THE R LANGUAGE RUNTIME SYSTEM WITH A DATA STREAM WAREHOUSE                                           |2017|\n",
      "|MARGINAL RELEASE UNDER LOCAL DIFFERENTIAL PRIVACY                                                                |2017|\n",
      "|MIND THE GAPS (AND BUMPS): STATISTICAL SMOOTHING OF SPATIOTEMPORAL STREAMS                                       |2017|\n",
      "|PRIVBAYES: PRIVATE DATA RELEASE VIA BAYESIAN NETWORKS                                                            |2017|\n",
      "|REPAIRING NOISY GRAPHS                                                                                           |2017|\n",
      "|REVERSE ENGINEERING AGGREGATION QUERIES                                                                          |2017|\n",
      "|SCALABLE INFORMATIVE RULE MINING                                                                                 |2017|\n",
      "|SCALING PRIVATE RECORD LINKAGE USING OUTPUT CONSTRAINED DIFFERENTIAL PRIVACY                                     |2017|\n",
      "|DATA QUALITY FOR TEMPORAL STREAMS                                                                                |2016|\n",
      "|EFFECTIVE AND COMPLETE DISCOVERY OF ORDER DEPENDENCIES VIA SET-BASED AXIOMATIZATION                              |2016|\n",
      "|ESTIMATING QUANTILES FROM THE UNION OF HISTORICAL AND STREAMING DATA                                             |2016|\n",
      "|INDEXING EVOLVING EVENTS FROM TWEET STREAMS                                                                      |2016|\n",
      "|LETTER FROM THE SPECIAL ISSUE EDITORS                                                                            |2016|\n",
      "|ONLINE ENTITY RESOLUTION USING AN ORACLE                                                                         |2016|\n",
      "|ONLINE EVENT INTEGRATION WITH STORYPIVOT                                                                         |2016|\n",
      "|SOURCESIGHT: ENABLING EFFECTIVE SOURCE SELECTION                                                                 |2016|\n",
      "|COMBINING QUANTITATIVE AND LOGICAL DATA CLEANING                                                                 |2015|\n",
      "|CONDITIONAL HEAVY HITTERS: DETECTING INTERESTING CORRELATIONS IN DATA STREAMS                                    |2015|\n",
      "|DATA FUSION: RESOLVING CONFLICTS FROM MULTIPLE SOURCES                                                           |2015|\n",
      "|DEXTER: LARGE-SCALE DISCOVERY AND EXTRACTION OF PRODUCT SPECIFICATIONS ON THE WEB                                |2015|\n",
      "|DPT: DIFFERENTIALLY PRIVATE TRAJECTORY SYNTHESIS USING HIERARCHICAL REFERENCE SYSTEMS                            |2015|\n",
      "|FINDING QUALITY IN QUANTITY: THE CHALLENGE OF DISCOVERING VALUABLE SOURCES FOR INTEGRATION                       |2015|\n",
      "|FINE-GRAINED CONTROVERSY DETECTION IN WIKIPEDIA                                                                  |2015|\n",
      "|FIT TO MONITOR FEED QUALITY                                                                                      |2015|\n",
      "|FUSING DATA WITH CORRELATIONS                                                                                    |2015|\n",
      "|IDENTIFYING THE EXTENT OF COMPLETENESS OF QUERY ANSWERS OVER PARTIALLY COMPLETE DATABASES                        |2015|\n",
      "|INDEXING EVOLVING EVENTS FROM TWEET STREAMS                                                                      |2015|\n",
      "|KNOWLEDGE CURATION AND KNOWLEDGE FUSION: CHALLENGES, MODELS AND APPLICATIONS                                     |2015|\n",
      "|ON AXIOMATIZATION AND INFERENCE COMPLEXITY OVER A HIERARCHY OF FUNCTIONAL DEPENDENCIES                           |2015|\n",
      "|PRIVATE RELEASE OF GRAPH STATISTICS USING LADDER FUNCTIONS                                                       |2015|\n",
      "|ROBUST GROUP LINKAGE                                                                                             |2015|\n",
      "|SCALING UP COPY DETECTION                                                                                        |2015|\n",
      "|SIZE-CONSTRAINED WEIGHTED SET COVER                                                                              |2015|\n",
      "|STORYPIVOT: COMPARING AND CONTRASTING STORY EVOLUTION                                                            |2015|\n",
      "|THE ELEPHANT IN THE ROOM: GETTING VALUE FROM BIG DATA                                                            |2015|\n",
      "|TREESCOPE: FINDING STRUCTURAL ANOMALIES IN SEMI-STRUCTURED DATA                                                  |2015|\n",
      "|TRUTH FINDING ON THE DEEP WEB: IS THE PROBLEM SOLVED?                                                            |2015|\n",
      "|CHARACTERIZING AND SELECTING FRESH DATA SOURCES                                                                  |2014|\n",
      "|DATA QUALITY: THE OTHER FACE OF BIG DATA                                                                         |2014|\n",
      "|DENSE SUBGRAPH MAINTENANCE UNDER STREAMING EDGE WEIGHT UPDATES FOR REAL-TIME STORY IDENTIFICATION                |2014|\n",
      "|EMPIRICAL GLITCH EXPLANATIONS                                                                                    |2014|\n",
      "|FRONT MATTER                                                                                                     |2014|\n",
      "|FUSING DATA WITH CORRELATIONS                                                                                    |2014|\n",
      "|INCREMENTAL RECORD LINKAGE                                                                                       |2014|\n",
      "|INTERPRETABLE AND INFORMATIVE EXPLANATIONS OF OUTCOMES                                                           |2014|\n",
      "|PRIVBAYES: PRIVATE DATA RELEASE VIA BAYESIAN NETWORKS                                                            |2014|\n",
      "|ACCURATE AND EFFICIENT PRIVATE RELEASE OF DATACUBES AND CONTINGENCY TABLES                                       |2013|\n",
      "|BIG DATA INTEGRATION                                                                                             |2013|\n",
      "|COMPACT EXPLANATION OF DATA FUSION DECISIONS                                                                     |2013|\n",
      "|DATA FUSION: RESOLVING CONFLICTS FROM MULTIPLE SOURCES                                                           |2013|\n",
      "|EMPIRICAL PRIVACY AND EMPIRICAL UTILITY OF ANONYMIZED DATA                                                       |2013|\n",
      "|FINDING INTERESTING CORRELATIONS WITH CONDITIONAL HEAVY HITTERS                                                  |2013|\n",
      "|FRONT MATTER                                                                                                     |2013|\n",
      "|ON REPAIRING STRUCTURAL PROBLEMS IN SEMI-STRUCTURED DATA                                                         |2013|\n",
      "|ONLINE ORDERING OF OVERLAPPING DATA SOURCES                                                                      |2013|\n",
      "|REVERSE ENGINEERING COMPLEX JOIN QUERIES                                                                         |2013|\n",
      "|UMICS: FROM ANONYMIZED DATA TO USABLE MICRODATA                                                                  |2013|\n",
      "|ACCURATE AND EFFICIENT PRIVATE RELEASE OF DATACUBES AND CONTINGENCY TABLES                                       |2012|\n",
      "|CHRONOS: FACILITATING HISTORY DISCOVERY BY LINKING TEMPORAL RECORDS                                              |2012|\n",
      "|DATA MANAGEMENT CHALLENGES AND OPPORTUNITIES IN CLOUD COMPUTING                                                  |2012|\n",
      "|DENSE SUBGRAPH MAINTENANCE UNDER STREAMING EDGE WEIGHT UPDATES FOR REAL-TIME STORY IDENTIFICATION                |2012|\n",
      "|DETECTING CLONES, COPYING AND REUSE ON THE WEB (DASFAA 2012 TUTORIAL)                                            |2012|\n",
      "|DIFFERENTIALLY PRIVATE SUMMARIES FOR SPARSE DATA                                                                 |2012|\n",
      "|ENABLING REAL TIME DATA ANALYSIS                                                                                 |2012|\n",
      "|IN SEARCH OF TRUTH (ON THE DEEP WEB)                                                                             |2012|\n",
      "|LESS IS MORE: SELECTING SOURCES WISELY FOR INTEGRATION                                                           |2012|\n",
      "|LINKING TEMPORAL RECORDS                                                                                         |2012|\n",
      "|SPECIAL ISSUE: BEST PAPERS OF APWEB 2010                                                                         |2012|\n",
      "|TRUTH FINDING ON THE DEEP WEB: IS THE PROBLEM SOLVED?                                                            |2012|\n",
      "+-----------------------------------------------------------------------------------------------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp1.show(1000, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4017f7",
   "metadata": {},
   "source": [
    "### 4.2 - List the author(s) (names) who have collaborated most (in terms of number of publications) with “Divesh Srivastava”other than himself based on MAS database and DBLP data. <a name=\"4.2\"></a>\n",
    "The result may contain more than one author if they coauthored with him for same number of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fb4bc849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- countp: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get author name and paper count with divesh from mas\n",
    "mas3 = spark.sql(\"select distinct a2.aid, a2.name, count(distinct lower(p.title)) as countp \\\n",
    "                from author a1 \\\n",
    "                join writes w1 \\\n",
    "                    on a1.aid = w1.aid \\\n",
    "                join writes w2 \\\n",
    "                    on w1.pid = w2.pid \\\n",
    "                join author a2 \\\n",
    "                    on w2.aid = a2.aid \\\n",
    "                join publication p \\\n",
    "                    on w2.pid = p.pid \\\n",
    "                where a1.name = 'Divesh Srivastava' \\\n",
    "                    and a2.name <> 'Divesh Srivastava' \\\n",
    "                group by a2.aid, a2.name \\\n",
    "                order by countp desc\")\n",
    "\n",
    "mas3.printSchema()\n",
    "mas3.createOrReplaceTempView(\"mas3v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0f9dbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pid: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all paper by divesh from mas \n",
    "mas4 = spark.sql(\"select distinct p.pid, p.title \\\n",
    "                from publication p \\\n",
    "                join writes w \\\n",
    "                    on p.pid = w.pid join author a \\\n",
    "                    on w.aid = a.aid \\\n",
    "                where a.name = 'Divesh Srivastava' \")\n",
    "\n",
    "mas4.printSchema()\n",
    "mas4.createOrReplaceTempView(\"mas4v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "57aaa4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _VALUE: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get author name and paper by divesh from both article and inproceeding\n",
    "dblp2 = spark.sql(\"select d._VALUE, d.title \\\n",
    "    from (select author._VALUE, title from dblp_filt_artv \\\n",
    "        union \\\n",
    "        select author._VALUE, title from dblp_filt_inpv \\\n",
    "       ) AS d\")\n",
    "\n",
    "dblp2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "846f0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode author name column\n",
    "dblp3 = dblp2.select(explode(dblp2._VALUE),dblp2.title)\n",
    "dblp3.printSchema()\n",
    "dblp3.createOrReplaceTempView(\"dblp3v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0cd80052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: string (nullable = true)\n",
      " |-- countp: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get author name and paper count with divesh in dblp that is not in mas\n",
    "dblp4 = spark.sql(\"select distinct d32.col, count(distinct lower(d3.title)) as countp \\\n",
    "                from dblp3v d3 \\\n",
    "                join dblp3v d32 \\\n",
    "                    on d3.title = d32.title \\\n",
    "                where d3.col like '%Divesh Srivastava%' \\\n",
    "                    and d32.col <> 'Divesh Srivastava' \\\n",
    "                    and not exists (select title \\\n",
    "                                    from mas4v m \\\n",
    "                                    where lower(m.title) = lower(d3.title)) group by d32.col \\\n",
    "                order by countp desc\")\n",
    "\n",
    "dblp4.printSchema()\n",
    "dblp4.createOrReplaceTempView(\"dblp4v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e148a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- totalcount: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get author name with most paper with divesh\n",
    "dblp5 = spark.sql(\"select name, sum(countp) as totalcount \\\n",
    "                   from (select col as name, countp from dblp4v \\\n",
    "                        union all\\\n",
    "                        select name, countp from mas3v \\\n",
    "                        ) \\\n",
    "                   group by name \\\n",
    "                   order by totalcount desc \\\n",
    "                   limit 1\")\n",
    "\n",
    "dblp5.printSchema()\n",
    "dblp5.createOrReplaceTempView(\"dblp5v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2ac29",
   "metadata": {},
   "source": [
    "### Query 2 result<a name=\"4.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e8095ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       name|totalcount|\n",
      "+-----------+----------+\n",
      "|Nick Koudas|        75|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd29fd",
   "metadata": {},
   "source": [
    "### 4.3 - List the number of publications of “Divesh Srivastava”each year based on MAS database and DBLP data. Duplicate papers in both MAS and DBLP should be counted only once in the result.<a name=\"4.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c460d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pid: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all papers and year by divesh from MAS \n",
    "mas5 = spark.sql(\"select distinct p.pid, p.title, p.year \\\n",
    "                from publication p \\\n",
    "                join writes w \\\n",
    "                    on p.pid = w.pid \\\n",
    "                join author a \\\n",
    "                    on w.aid = a.aid \\\n",
    "                where a.name = 'Divesh Srivastava'\")\n",
    "\n",
    "mas5.printSchema()\n",
    "mas5.createOrReplaceTempView(\"mas5v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4c3cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all papers and year from dblp articles and inproceedings\n",
    "dblp6 = spark.sql(\"select distinct lower(d.title) as title, d.year \\\n",
    "        from (select title, year from dblp_filt_artv \\\n",
    "        union \\\n",
    "        select title, year from dblp_filt_inpv \\\n",
    "       ) AS d\")\n",
    "\n",
    "dblp6.printSchema()\n",
    "dblp6.createOrReplaceTempView(\"dblp6v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "812072f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countp: long (nullable = false)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union both table and get count of paper per year\n",
    "dblp7 = spark.sql(\"select count(distinct lower(d.title)) as countp, d.year \\\n",
    "        from (select lower(title) as title, year from dblp6v \\\n",
    "        union \\\n",
    "        select lower(title) as title, year from mas5v \\\n",
    "       ) AS d \\\n",
    "       group by d.year \\\n",
    "       order by d.year desc\")\n",
    "\n",
    "dblp7.printSchema()\n",
    "dblp7.createOrReplaceTempView(\"dblp7v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614aa093",
   "metadata": {},
   "source": [
    "### Query 3 result<a name=\"4.3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "440320a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|countp|year|\n",
      "+------+----+\n",
      "|15    |2022|\n",
      "|16    |2021|\n",
      "|14    |2020|\n",
      "|17    |2019|\n",
      "|19    |2018|\n",
      "|16    |2017|\n",
      "|8     |2016|\n",
      "|21    |2015|\n",
      "|10    |2014|\n",
      "|11    |2013|\n",
      "|17    |2012|\n",
      "|14    |2011|\n",
      "|23    |2010|\n",
      "|26    |2009|\n",
      "|20    |2008|\n",
      "|15    |2007|\n",
      "|15    |2006|\n",
      "|16    |2005|\n",
      "|10    |2004|\n",
      "|28    |2003|\n",
      "|17    |2002|\n",
      "|10    |2001|\n",
      "|13    |2000|\n",
      "|10    |1999|\n",
      "|7     |1998|\n",
      "|3     |1997|\n",
      "|9     |1996|\n",
      "|5     |1995|\n",
      "|8     |1994|\n",
      "|8     |1993|\n",
      "|7     |1992|\n",
      "|2     |1991|\n",
      "|3     |1990|\n",
      "|10    |0   |\n",
      "|1     |null|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp7.show(1000, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be90611",
   "metadata": {},
   "source": [
    "### 4.4 - Find papers published in 2021 that are relevant to keyword query ‘self attention transformer’ (or 'self-attention transformer'). Treat each paper title as one document and rank them using tf-idf. Return the top 10 relevant papers (title, authors, journal/conference and year).  <a name=\"4.4\"></a>\n",
    "\n",
    "Keyword query \"self attention transformer\" contains 3 keywords (terms) as \"self\", \"attention\", and \"transformer\". \n",
    "\n",
    "Keyword query \"self-attention transformer\" contains 2 keywords (terms) as \"self-attention\" and \"transformer\".\n",
    "\n",
    "Choose one of the keyword query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e03fa5",
   "metadata": {},
   "source": [
    "### Scenario used: \n",
    "\n",
    "- TF-IDF is case insensitive\n",
    "\n",
    "- \"self-attention\" and \"transformer\" are used for query\n",
    "\n",
    "- Grammer derivation of \"self-attention\" and \"transformer\" such as \"transformers\" are not counted\n",
    "\n",
    "- TF is normalized to length of title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2eb71",
   "metadata": {},
   "source": [
    "### 4.4.1 - Dataframe method <a name=\"4.4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b46b3724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- journal_conference: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all papers in dblp articles and proceedings\n",
    "dblp_all =  spark.sql(\"select distinct d.title, d.author, d.year, d.journal as journal_conference\\\n",
    "                        from (select distinct lower(title) as title, author, year, journal \\\n",
    "                            from dblp_artv \\\n",
    "                            union \\\n",
    "                            select distinct lower(title) as title, author, year, booktitle \\\n",
    "                            from dblp_inpv) as d \\\n",
    "                        where (lower(d.title) like '%self-attention%' \\\n",
    "                                or lower(d.title) like '%transformer%') \\\n",
    "                                and d.year = 2021 \\\n",
    "                                order by d.title\")\n",
    "\n",
    "dblp_all = dblp_all.withColumn('title', \n",
    "                             when(dblp_all.title.endswith('.'),expr(\"substring(title, 1, length(title)-1)\"))\n",
    "                             .otherwise(dblp_all.title))\n",
    "\n",
    "dblp_all.printSchema()\n",
    "dblp_all.createOrReplaceTempView(\"dblp_allv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7e7edfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _aux: string (nullable = true)\n",
      " |    |    |-- _orcid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all papers in dblp articles and proceedings that are in year 2021 that is relevant to self-attention transformer\n",
    "dblp_filt2 =  spark.sql(\"select distinct lower(d.title) title, d.author \\\n",
    "                        from (select distinct lower(title) as title, author, year, journal \\\n",
    "                            from dblp_artv \\\n",
    "                            union \\\n",
    "                            select distinct lower(title) as title, author, year, booktitle \\\n",
    "                            from dblp_inpv) as d \\\n",
    "                        where (lower(d.title) like '%self-attention%' \\\n",
    "                                or lower(d.title) like '%transformer%') \\\n",
    "                                and d.year = 2021 \\\n",
    "                                order by title\")\n",
    "\n",
    "dblp_filt2 = dblp_filt2.withColumn('title', \n",
    "                             when(dblp_filt2.title.endswith('.'),expr(\"substring(title, 1, length(title)-1)\"))\n",
    "                             .otherwise(dblp_filt2.title))\n",
    "\n",
    "dblp_filt2.printSchema()\n",
    "dblp_filt2.createOrReplaceTempView(\"dblp_filt2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ef4deccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               title|              author|\n",
      "+--------------------+--------------------+\n",
      "|$\\mathcal{laja}{-...|[{Veena Mayya, nu...|\n",
      "|1d self-attention...|[{Takahiro Suzuki...|\n",
      "|26.5 a watt-level...|[{Bingzheng Yang,...|\n",
      "|270-to-300ghz dou...|[{Zhiyu Chen, nul...|\n",
      "|2d self-attention...|[{Nam Tuan Ly, nu...|\n",
      "|2lspe: 2d learnab...|[{Zobeir Raisi, n...|\n",
      "|3-d ultrasonic lo...|[{Hongxin Ji, nul...|\n",
      "|3d deep attentive...|[{Yiyao Liu, null...|\n",
      "|3d human pose est...|[{Ce Zheng, null,...|\n",
      "|3d human texture ...|[{Xiangyu Xu, nul...|\n",
      "|3d medical point ...|[{Jianhui Yu, nul...|\n",
      "|3d object trackin...|[{Yubo Cui, null,...|\n",
      "|3d transformer-ga...|[{Yanmei Luo, nul...|\n",
      "|3d-anas v2: graft...|[{Xizhe Xue, null...|\n",
      "|3d-retr: end-to-e...|[{Zai Shi, null, ...|\n",
      "|3d-transformer: m...|[{Fang Wu, null, ...|\n",
      "|3dmet: 3d medical...|[{Sheng Wang, nul...|\n",
      "|3dvg-transformer:...|[{Lichen Zhao, nu...|\n",
      "|3m-transformers f...|[{Erick Skorupa P...|\n",
      "|6d-vit: category-...|[{Lu Zou, null, n...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_filt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ebbe0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer, Tokenizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b0dabbef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"features\")\n",
    "dblp_filt3 = tokenizer.transform(dblp_filt2)\n",
    "\n",
    "df_split = dblp_filt3.rdd.map(lambda x : (x.title,x.features)) \\\n",
    "          .toDF() \\\n",
    "          .withColumnRenamed(\"_1\",\"title\") \\\n",
    "          .withColumnRenamed(\"_2\",\"features\")\n",
    "\n",
    "htf = HashingTF(inputCol=\"features\", outputCol=\"tf\", numFeatures=262144)\n",
    "tf = htf.transform(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "917def14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tf: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b82e64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rdd to map to tf values\n",
    "res = tf.rdd.map(lambda x : (x.title,\n",
    "                            x.features,\n",
    "                            list((None if x.tf is None else float(y) for y in x.tf.values)),\n",
    "                              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4ffbe405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define schema of tf DF and transform rdd to DF\n",
    "resSchema = StructType([       \n",
    "    StructField('title', StringType(), True),\n",
    "    StructField('features', \n",
    "                ArrayType(\n",
    "                    StringType(),True\n",
    "                ), True),\n",
    "    StructField('tf', \n",
    "                ArrayType(\n",
    "                    FloatType(),True\n",
    "                ), True),\n",
    "])\n",
    "\n",
    "resDF = spark.createDataFrame(res, schema = resSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b5761754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               title|            features|                  tf|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|$\\mathcal{laja}{-...|[$\\mathcal{laja}{...|[1.0, 1.0, 1.0, 1...|\n",
      "|1d self-attention...|[1d, self-attenti...|[1.0, 1.0, 1.0, 1...|\n",
      "|26.5 a watt-level...|[26.5, a, watt-le...|[1.0, 1.0, 1.0, 1...|\n",
      "|270-to-300ghz dou...|[270-to-300ghz, d...|[1.0, 1.0, 1.0, 1...|\n",
      "|2d self-attention...|[2d, self-attenti...|[1.0, 1.0, 1.0, 1...|\n",
      "|2lspe: 2d learnab...|[2lspe:, 2d, lear...|[1.0, 1.0, 1.0, 1...|\n",
      "|3-d ultrasonic lo...|[3-d, ultrasonic,...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d deep attentive...|[3d, deep, attent...|[1.0, 2.0, 1.0, 1...|\n",
      "|3d human pose est...|[3d, human, pose,...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d human texture ...|[3d, human, textu...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d medical point ...|[3d, medical, poi...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d object trackin...|[3d, object, trac...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d transformer-ga...|[3d, transformer-...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d-anas v2: graft...|[3d-anas, v2:, gr...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d-retr: end-to-e...|[3d-retr:, end-to...|[1.0, 1.0, 1.0, 1...|\n",
      "|3d-transformer: m...|[3d-transformer:,...|[1.0, 1.0, 1.0, 1...|\n",
      "|3dmet: 3d medical...|[3dmet:, 3d, medi...|[1.0, 1.0, 1.0, 1...|\n",
      "|3dvg-transformer:...|[3dvg-transformer...|[1.0, 1.0, 1.0, 1...|\n",
      "|3m-transformers f...|[3m-transformers,...|[1.0, 1.0, 1.0, 1...|\n",
      "|6d-vit: category-...|[6d-vit:, categor...|[1.0, 1.0, 1.0, 1...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tf: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resDF.show()\n",
    "resDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c9860449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode features and tf values\n",
    "resDF_explode = resDF.withColumn(\"new\", arrays_zip(\"features\", \"tf\"))\\\n",
    "             .withColumn(\"new\", explode(\"new\"))\\\n",
    "             .select(\"title\", col(\"new.features\").alias(\"features\"), col(\"new.tf\").alias(\"tf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "561967e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---+\n",
      "|               title|           features| tf|\n",
      "+--------------------+-------------------+---+\n",
      "|$\\mathcal{laja}{-...|$\\mathcal{laja}{-}$|1.0|\n",
      "|$\\mathcal{laja}{-...|              label|1.0|\n",
      "|$\\mathcal{laja}{-...|          attention|1.0|\n",
      "|$\\mathcal{laja}{-...|        transformer|1.0|\n",
      "|$\\mathcal{laja}{-...|      architectures|1.0|\n",
      "|$\\mathcal{laja}{-...|                for|1.0|\n",
      "|$\\mathcal{laja}{-...|             icd-10|1.0|\n",
      "|$\\mathcal{laja}{-...|             coding|1.0|\n",
      "|$\\mathcal{laja}{-...|                 of|1.0|\n",
      "|$\\mathcal{laja}{-...|       unstructured|1.0|\n",
      "|$\\mathcal{laja}{-...|           clinical|1.0|\n",
      "|$\\mathcal{laja}{-...|              notes|1.0|\n",
      "|1d self-attention...|                 1d|1.0|\n",
      "|1d self-attention...|     self-attention|1.0|\n",
      "|1d self-attention...|            network|1.0|\n",
      "|1d self-attention...|                for|1.0|\n",
      "|1d self-attention...|              point|1.0|\n",
      "|1d self-attention...|              cloud|1.0|\n",
      "|1d self-attention...|           semantic|1.0|\n",
      "|1d self-attention...|       segmentation|1.0|\n",
      "+--------------------+-------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- features: string (nullable = true)\n",
      " |-- tf: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resDF_explode.show()\n",
    "resDF_explode.printSchema()\n",
    "resDF_explode.createOrReplaceTempView(\"resDF_explodev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "00aafa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- features: string (nullable = true)\n",
      " |-- tf: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter features for self-attention and transformer, then calculate the tf*idf value\n",
    "dblp_tfidf =  spark.sql(\"select title, features, tf \\\n",
    "                        from resDF_explodev \\\n",
    "                        where lower(features) = 'self-attention' \\\n",
    "                        or lower(features) = 'transformer' \")\n",
    "\n",
    "dblp_tfidf.printSchema()\n",
    "dblp_tfidf.createOrReplaceTempView(\"dblp_tfidfv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bd86af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_terms: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate number of terms in each document\n",
    "dblp_tfidf1 = spark.sql(\"select title, sum(tf) as total_terms\\\n",
    "                        from resDF_explodev \\\n",
    "                        group by title \")\n",
    "dblp_tfidf1.printSchema()\n",
    "dblp_tfidf1.createOrReplaceTempView(\"dblp_tfidf1v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c0846130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|total_terms|\n",
      "+--------------------+-----------+\n",
      "|a text autoencode...|       10.0|\n",
      "|combining cnns wi...|       11.0|\n",
      "|finetuning pretra...|        5.0|\n",
      "|improving multili...|        9.0|\n",
      "|knowledge graph c...|       10.0|\n",
      "|latte: lstm self-...|       10.0|\n",
      "|mt-transunet: med...|       12.0|\n",
      "|multi-domain tran...|        8.0|\n",
      "|ordering sentence...|       11.0|\n",
      "|point cloud trans...|        7.0|\n",
      "|r2d2: relational ...|        6.0|\n",
      "|recursive non-aut...|       10.0|\n",
      "|transformers and ...|       10.0|\n",
      "|transvg: end-to-e...|        6.0|\n",
      "|visual transforme...|        3.0|\n",
      "|a transformer-bas...|        7.0|\n",
      "|blind deinterleav...|       14.0|\n",
      "|dct-net: a deep c...|       10.0|\n",
      "|delving deep into...|       11.0|\n",
      "|diabetic retinopa...|       10.0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9693e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_sa_terms: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate number of self-attention in each document \n",
    "dblp_tfidf2 = spark.sql(\"select title, sum(tf) as total_sa_terms\\\n",
    "                        from resDF_explodev \\\n",
    "                        where lower(features) = 'self-attention' \\\n",
    "                        group by title \")\n",
    "dblp_tfidf2.printSchema()\n",
    "dblp_tfidf2.createOrReplaceTempView(\"dblp_tfidf2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c774f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|               title|total_sa_terms|\n",
      "+--------------------+--------------+\n",
      "|latte: lstm self-...|           1.0|\n",
      "|blind deinterleav...|           1.0|\n",
      "|predicting esopha...|           1.0|\n",
      "|scsa-net: present...|           1.0|\n",
      "|self-attention bi...|           1.0|\n",
      "|dapnet: a double ...|           1.0|\n",
      "|re-transformer: a...|           1.0|\n",
      "|spatial context-a...|           1.0|\n",
      "|dual-axial self-a...|           1.0|\n",
      "|generalizing rnn-...|           1.0|\n",
      "|local multi-head ...|           1.0|\n",
      "|mgsan: a multi-gr...|           1.0|\n",
      "|brain dynamics vi...|           1.0|\n",
      "|two-hand pose est...|           1.0|\n",
      "|a region descript...|           1.0|\n",
      "|exploring neural ...|           1.0|\n",
      "|multi-horizon ele...|           2.0|\n",
      "|human parity on c...|           1.0|\n",
      "|a korean named en...|           1.0|\n",
      "|a mixed-domain se...|           1.0|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e6fa19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countp: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate number of documents where self-attention appears in\n",
    "dblp_tfidf3 = spark.sql(\"select count(distinct title) as countp \\\n",
    "                        from resDF_explodev \\\n",
    "                        where lower(features) = 'self-attention' \")\n",
    "dblp_tfidf3.printSchema()\n",
    "dblp_tfidf3.createOrReplaceTempView(\"dblp_tfidf3v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8d2dc388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|countp|\n",
      "+------+\n",
      "|   386|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "66ac17c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_t_terms: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate number of transformer in each document \n",
    "dblp_tfidf4 = spark.sql(\"select title, sum(tf) as total_t_terms\\\n",
    "                        from resDF_explodev \\\n",
    "                        where lower(features) = 'transformer' \\\n",
    "                        group by title \")\n",
    "dblp_tfidf4.printSchema()\n",
    "dblp_tfidf4.createOrReplaceTempView(\"dblp_tfidf4v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f8fb9867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|               title|total_t_terms|\n",
      "+--------------------+-------------+\n",
      "|a text autoencode...|          1.0|\n",
      "|combining cnns wi...|          1.0|\n",
      "|improving multili...|          1.0|\n",
      "|knowledge graph c...|          1.0|\n",
      "|recursive non-aut...|          1.0|\n",
      "|visual transforme...|          1.0|\n",
      "|dct-net: a deep c...|          1.0|\n",
      "|diabetic retinopa...|          1.0|\n",
      "|knowledge-enhance...|          1.0|\n",
      "|mobilevit: light-...|          1.0|\n",
      "|probabilistic tra...|          1.0|\n",
      "|video summarizati...|          1.0|\n",
      "|vision transforme...|          1.0|\n",
      "|a differential rf...|          1.0|\n",
      "|context-aware and...|          1.0|\n",
      "|gaze estimation u...|          1.0|\n",
      "|joint localizatio...|          1.0|\n",
      "|on exploring atte...|          1.0|\n",
      "|ruite: refining u...|          1.0|\n",
      "|streaming simulta...|          1.0|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "76162723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countp: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate number of documents where transformer appears in\n",
    "dblp_tfidf5 = spark.sql(\"select count(distinct title) as countp \\\n",
    "                        from resDF_explodev \\\n",
    "                        where lower(features) = 'transformer' \")\n",
    "dblp_tfidf5.printSchema()\n",
    "dblp_tfidf5.createOrReplaceTempView(\"dblp_tfidf5v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6834f2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|countp|\n",
      "+------+\n",
      "|  1529|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e6597c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countp: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate total number of documents\n",
    "dblp_tfidf7 = spark.sql(\"select count(distinct title) as countp \\\n",
    "                        from dblp_filt2v \")\n",
    "dblp_tfidf7.printSchema()\n",
    "dblp_tfidf7.createOrReplaceTempView(\"dblp_tfidf7v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f9297fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|countp|\n",
      "+------+\n",
      "|  3292|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c9120ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_terms: double (nullable = true)\n",
      " |-- sa_count: double (nullable = false)\n",
      " |-- t_count: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate each term in each doc count\n",
    "dblp_tfidf6 = spark.sql(\"select d1.title, d1.total_terms, COALESCE(d2.total_sa_terms,0) as sa_count, COALESCE(d4.total_t_terms,0) as t_count  \\\n",
    "                        from dblp_tfidf1v d1 \\\n",
    "                        full outer join dblp_tfidf2v d2 \\\n",
    "                            on d1.title = d2.title \\\n",
    "                        full outer join dblp_tfidf4v d4 \\\n",
    "                            on d1.title = d4.title \")\n",
    "dblp_tfidf6.printSchema()\n",
    "dblp_tfidf6.createOrReplaceTempView(\"dblp_tfidf6v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ac939e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------+-------+\n",
      "|               title|total_terms|sa_count|t_count|\n",
      "+--------------------+-----------+--------+-------+\n",
      "|a text autoencode...|       10.0|     0.0|    1.0|\n",
      "|combining cnns wi...|       11.0|     0.0|    1.0|\n",
      "|finetuning pretra...|        5.0|     0.0|    0.0|\n",
      "|improving multili...|        9.0|     0.0|    1.0|\n",
      "|knowledge graph c...|       10.0|     0.0|    1.0|\n",
      "|latte: lstm self-...|       10.0|     1.0|    0.0|\n",
      "|mt-transunet: med...|       12.0|     0.0|    0.0|\n",
      "|multi-domain tran...|        8.0|     0.0|    0.0|\n",
      "|ordering sentence...|       11.0|     0.0|    0.0|\n",
      "|point cloud trans...|        7.0|     0.0|    0.0|\n",
      "|r2d2: relational ...|        6.0|     0.0|    0.0|\n",
      "|recursive non-aut...|       10.0|     0.0|    1.0|\n",
      "|transformers and ...|       10.0|     0.0|    0.0|\n",
      "|transvg: end-to-e...|        6.0|     0.0|    0.0|\n",
      "|visual transforme...|        3.0|     0.0|    1.0|\n",
      "|a transformer-bas...|        7.0|     0.0|    0.0|\n",
      "|blind deinterleav...|       14.0|     1.0|    0.0|\n",
      "|dct-net: a deep c...|       10.0|     0.0|    1.0|\n",
      "|delving deep into...|       11.0|     0.0|    0.0|\n",
      "|diabetic retinopa...|       10.0|     0.0|    1.0|\n",
      "+--------------------+-----------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49fb4e",
   "metadata": {},
   "source": [
    "### 4.4.2 - With RDD map reduce method <a name=\"4.4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f8ae402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"features\")\n",
    "dblp_filt3 = tokenizer.transform(dblp_filt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0ada5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(title, features)\n",
    "lines = dblp_filt3.rdd.map(lambda x : (x.title,x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6bae10f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   '$\\\\mathcal{laja}{-}$'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'label'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'architectures'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'for'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'icd-10'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'coding'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'of'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'unstructured'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'clinical'),\n",
       "  1),\n",
       " (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "   'notes'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   '1d'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'network'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'for'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'point'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'cloud'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'semantic'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'using'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'omnidirectional'),\n",
       "  1),\n",
       " (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "   'lidar'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   '26.5'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'watt-level'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'quadrature'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'switched/floated-capacitor'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'power'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'amplifier'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'back-off'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'efficiency'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'enhancement'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'in'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'complex'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'domain'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'using'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'reconfigurable'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'self-coupling'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'canceling'),\n",
       "  1),\n",
       " (('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   '270-to-300ghz'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'double-balanced'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'parametric'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'upconverter'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'using'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'asymmetric'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'mos'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'varactors'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'and'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'power-splitting-'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'hybrid'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   '65nm'),\n",
       "  1),\n",
       " (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   '2d'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'recurrent'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'network'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'offline'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'handwritten'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'text'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   '2lspe:'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   '2d'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'learnable'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'sinusoidal'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'positional'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'encoding'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'using'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'scene'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'text'),\n",
       "  1),\n",
       " (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   '3-d'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'ultrasonic'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'localization'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'of'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'patrol'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'robot'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'based'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'on'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'emd'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'and'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'phat-β'),\n",
       "  1),\n",
       " (('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "   'algorithms'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'attentive'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'u-net'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'with'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'for'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'breast'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'tumor'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'from'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'automated'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'breast'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'volume'),\n",
       "  1),\n",
       " (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "   'scanner'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers', '3d'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers', 'human'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers', 'pose'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers',\n",
       "   'estimation'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers', 'with'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers',\n",
       "   'spatial'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers', 'and'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers',\n",
       "   'temporal'),\n",
       "  1),\n",
       " (('3d human pose estimation with spatial and temporal transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers', '3d'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'human'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'texture'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'estimation'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'from'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers', 'a'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'single'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'image'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('3d human texture estimation from a single image with transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'medical'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'point'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'transformer:'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'introducing'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'convolution'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'to'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'for'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'medical'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'point'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'cloud'),\n",
       "  1),\n",
       " (('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "   'analysis'),\n",
       "  1),\n",
       " (('3d object tracking with transformer', '3d'), 1),\n",
       " (('3d object tracking with transformer', 'object'), 1),\n",
       " (('3d object tracking with transformer', 'tracking'), 1),\n",
       " (('3d object tracking with transformer', 'with'), 1),\n",
       " (('3d object tracking with transformer', 'transformer'), 1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction', '3d'), 1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction',\n",
       "   'transformer-gan'),\n",
       "  1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction', 'for'), 1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction', 'high-quality'),\n",
       "  1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction', 'pet'), 1),\n",
       " (('3d transformer-gan for high-quality pet reconstruction', 'reconstruction'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   '3d-anas'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'v2:'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'grafting'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'module'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'on'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'automatically'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'designed'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'convnet'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'for'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'hyperspectral'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'image'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   '3d-retr:'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'end-to-end'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'single'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'and'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'multi-view'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'reconstruction'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   '3d-transformer:'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'molecular'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'representation'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'with'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'in'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('3d-transformer: molecular representation with transformer in 3d space',\n",
       "   'space'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   '3dmet:'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'medical'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'image'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'for'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'knee'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'cartilage'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'defect'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'assessment'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   '3dvg-transformer:'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'relation'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'modeling'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'for'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'grounding'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'on'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'point'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'clouds'),\n",
       "  1),\n",
       " (('3m-transformers for event coding on organized crime domain',\n",
       "   '3m-transformers'),\n",
       "  1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'for'), 1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'event'), 1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'coding'), 1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'on'), 1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'organized'),\n",
       "  1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'crime'), 1),\n",
       " (('3m-transformers for event coding on organized crime domain', 'domain'), 1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   '6d-vit:'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'category-level'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   '6d'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'object'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'pose'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'estimation'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'via'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'instance'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'representation'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   '1.25w'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   '46.5%-peak-efficiency'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'transformer-in-package'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'isolated'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'dc-dc'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'converter'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'glass-based'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'fan-out'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'wafer-level'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'packaging'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'achieving'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   '50mw/mm2'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "   'density'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   '1.75db-nf'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   '25mw'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   '5ghz'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'noise-'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'cancelling'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'receiver'),\n",
       "  1),\n",
       " (('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "   'front-end'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   '196.2'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'dbc/hz'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'fomt'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   '16.8-to-21.6'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'ghz'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'class-f23'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'vco'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'optimal'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'q-factor'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'tank'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   '65-nm'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   '2-ghz'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'reconfigurable'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'transmitter'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'class-d'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'pa'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'multi-tapped'),\n",
       "  1),\n",
       " (('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   '21.6dbm'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'amplifier'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'compact'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'high-k'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'output'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'x-band'),\n",
       "  1),\n",
       " (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "   'application'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   '25.1'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'dbm'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   '25.9-db'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'gain'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   '25.4%'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'pae'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'x-band'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'amplifier'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'utilizing'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'voltage'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'combining'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   '65-nm'),\n",
       "  1),\n",
       " (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   '268-325'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'ghz'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   '5.2'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'dbm'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'psat'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'frequency'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'doubler'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'mode'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'separation'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'sige'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'bicmos'),\n",
       "  1),\n",
       " (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "   'technology'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   '28-ghz'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'doherty'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'amplifier'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'compact'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'quadrature'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'hybrid'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   '65-nm'),\n",
       "  1),\n",
       " (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   '30-36'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'ghz'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'passive'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'hybrid'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'phase'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'shifter'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'high-resolution'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'reflect-type'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'phase'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'shifting'),\n",
       "  1),\n",
       " (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "   'technique'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   '60ghz'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   '186.5dbc/hz'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'fom'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'quad-core'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'fundamental'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'vco'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'circular'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'triple-coupled'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'no'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'mode'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'ambiguity'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   '65nm'),\n",
       "  1),\n",
       " (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   '7.9-14.3ghz'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   '-243.3db'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'fomt'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'sub-sampling'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'pll'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'dual-mode'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'vco'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   '40nm'),\n",
       "  1),\n",
       " (('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'battle'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'structures:'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'an'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'empirical'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'cnn,'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'transformer,'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "   'mlp'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'alignment'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'unsupervised'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'word'),\n",
       "  1),\n",
       " (('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "   'alignment'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'bilingual,'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'openworld'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'text'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'dataset'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'end-to-end'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'text'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'spotter'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'bilingual,'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'openworld'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'text'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'dataset'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'end-to-end'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'text'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'spotter'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'broadband'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'tri-coil'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'design'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'mm-wave'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'cascode'),\n",
       "  1),\n",
       " (('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "   'amplifiers'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'case'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'capacitive'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'voltage'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   '(cvt)'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'behaviour'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'multiple'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'earthing'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'cvt'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'secondary'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'circuit'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   '400'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'kv'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'transmission'),\n",
       "  1),\n",
       " (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "   'line'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'charging'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'strategy'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'electric'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'vehicle'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'fast'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'charging'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'station'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'mitigate'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'distribution'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'aging'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'reduce'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'operation'),\n",
       "  1),\n",
       " (('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "   'cost'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'co-interactive'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'joint'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'slot'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'filling'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'intent'),\n",
       "  1),\n",
       " (('a co-interactive transformer for joint slot filling and intent detection',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'coarse-to-fine'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'facial'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'landmark'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'method'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'mechanism'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'combined'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'short'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'time'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'fourier'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'transform'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'image'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'rolling'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'element'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'bearings'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'fault'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'diagnosis'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'electric'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'motors'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'common'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'grounded'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'type'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'dual-mode'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'five-level'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'transformerless'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'inverter'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'photovoltaic'),\n",
       "  1),\n",
       " (('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "   'applications'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos', 'a'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'compact'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'fractional-n'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'adpll'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   '10-nm'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'finfet'),\n",
       "  1),\n",
       " (('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'comparative'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'language'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'question'),\n",
       "  1),\n",
       " (('a comparative study of language transformers for video question answering',\n",
       "   'answering'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'comparative'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'language'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'models'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'extractive'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'question'),\n",
       "  1),\n",
       " (('a comparative study of transformer-based language models on extractive question answering',\n",
       "   'answering'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'a'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'comparative'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'of'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'on'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'word'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'sense'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'disambiguation'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'a'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'comparative'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'of'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'on'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'word'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'sense'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation',\n",
       "   'disambiguation'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'comparison'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'anti-noise'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'robustness'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'methods'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'tiny'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'object'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'image'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'dataset:'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'from'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "   'performer'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'comparison'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'patch-level'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'methods'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'transparent'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'images:'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'from'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'comparison'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'methods'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'small-scale'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'image'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'data'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'set:'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'from'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'cross-modal'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'residual'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'structure'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'multimodal'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'emotion'),\n",
       "  1),\n",
       " (('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'pain'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'estimation'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'facial'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'expression'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'video'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'approach'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'robust'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'bots'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'twitter'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'bert'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'sentence'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'semantic'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'keyphrase'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'extraction'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'big'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'social'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'data'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'differential'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'rf'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'front-end'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'matching'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'ambient'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'rf'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'energy'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'harvesting'),\n",
       "  1),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'systems'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'discriminative'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'cycle'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'gan'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'face'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'super-resolution'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'doubly'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'grounded'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'transformerless'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'pv'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'grid-connected'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'inverter'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'without'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'shoot-through'),\n",
       "  1),\n",
       " (('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "   'problem'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'dual-band'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'transformer-coupled'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'notch'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'filter'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'mixer'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   '2.45-/5.2-ghz'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'wlan'),\n",
       "  1),\n",
       " (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "   'application'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'duality'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'quasi-steady-state'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'three-phase'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'five-limb'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'sen'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'dynamic'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'residual'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'lightweight'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'single'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'image'),\n",
       "  1),\n",
       " (('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "   'super-resolution'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'facial'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'expression'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'system'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'smart'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'yolo'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'vision'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'fast'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'method'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'polynomial'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'fitting'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'lane'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'module'),\n",
       "  1),\n",
       " (('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "   'added'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'fine-grained'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'method'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'siamese'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'free'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'lunch'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'from'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'vit:'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'adaptive'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'multi-scale'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'fine-grained'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'further'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'study'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'of'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'unsupervised'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'pretraining'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'speech'),\n",
       "  1),\n",
       " (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'fuzzy'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'logic'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'proposal'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'diagnosis'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'multiple'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'incipient'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'faults'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures', 'a'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'generative'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures', 'for'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures', 'raw'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'audio'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a generative model for raw audio using transformer architectures',\n",
       "   'architectures'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'graph'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'vae'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'graph'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'approach'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'generating'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'molecular'),\n",
       "  1),\n",
       " (('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "   'graphs'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'heat'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'dissipation'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'enhancement'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'measure'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'based'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'on'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'falling'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'film'),\n",
       "  1),\n",
       " (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "   'flow'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'hybrid'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'isolated'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'dc/dc'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'solid-state'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'dc'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'distribution'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'joint'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'model'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'aspect'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'category'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'e-commerce'),\n",
       "  1),\n",
       " (('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "   'reviews'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'k-band'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'high-gain'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'power'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'amplifier'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'slow-wave'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'transmission-line'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   '130-nm'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'rf'),\n",
       "  1),\n",
       " (('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'keypoint'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'discover'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'spine'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'structure'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'cobb'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'angle'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'estimation'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'korean'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'named'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'entity'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'method'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'using'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'bi-lstm-crf'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'masked'),\n",
       "  1),\n",
       " (('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'latent'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'disentangled'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'identity-preserving'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'face'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled and identity-preserving face editing',\n",
       "   'editing'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'latent'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'disentangled'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'face'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'editing'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'images'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'videos'),\n",
       "  1),\n",
       " (('a light transformer for speech-to-intent applications', 'a'), 1),\n",
       " (('a light transformer for speech-to-intent applications', 'light'), 1),\n",
       " (('a light transformer for speech-to-intent applications', 'transformer'), 1),\n",
       " (('a light transformer for speech-to-intent applications', 'for'), 1),\n",
       " (('a light transformer for speech-to-intent applications',\n",
       "   'speech-to-intent'),\n",
       "  1),\n",
       " (('a light transformer for speech-to-intent applications', 'applications'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'lightweight'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   '1-d'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'convolution'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'augmented'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'metric'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'hyperspectral'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'image'),\n",
       "  1),\n",
       " (('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'lightweight'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'graph'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'human'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'mesh'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'reconstruction'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'from'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   '2d'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'human'),\n",
       "  1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'pose'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'lightweight'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'multidimensional'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'fine-grained'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'action'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'a'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'method'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'for'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   \"fans'\"),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'potential'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'malfunction'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'detection'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'of'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'onaf'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'transformer'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'using'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'top-oil'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'temperature'),\n",
       "  1),\n",
       " ((\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "   'monitoring'),\n",
       "  1),\n",
       " (('a method of point cloud processing in transformer substation', 'a'), 1),\n",
       " ...]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(title,features),1]  : count of each feature per each title\n",
    "map1 = lines.flatMap(lambda x: [((x[0],i),1) for i in x[1]])\n",
    "map1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fa8d5b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   'dual-mode'),\n",
       "  1),\n",
       " (('a comparative study of transformers on word sense disambiguation', 'word'),\n",
       "  2),\n",
       " (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   'matching'),\n",
       "  1),\n",
       " (('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   'multiple'),\n",
       "  1),\n",
       " (('a modular multilevel converter (mmc) based solid-state transformer (sst) topology with simplified energy conversion process and magnetic integration',\n",
       "   'integration'),\n",
       "  1),\n",
       " (('a new model of transformer operation state evaluation based on analytic hierarchy process and association rule mining',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a note on learning rare events in molecular dynamics using lstm and transformer',\n",
       "   'rare'),\n",
       "  1),\n",
       " (('a pi+passivity-based control of a wind energy conversion system enabled with a solid-state transformer',\n",
       "   'system'),\n",
       "  1),\n",
       " (('a sample-based training method for distantly supervised relation extraction with pre-trained transformers',\n",
       "   'training'),\n",
       "  1),\n",
       " (('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   'natural'),\n",
       "  1),\n",
       " (('a task-oriented dialogue architecture via transformer neural language models and symbolic injection',\n",
       "   'injection'),\n",
       "  1),\n",
       " (('a transformer based sales prediction of smart container in new retail era',\n",
       "   'era'),\n",
       "  1),\n",
       " (('a transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain mri images',\n",
       "   'mri'),\n",
       "  1),\n",
       " (('adversarial attacks on kinship verification using transformer',\n",
       "   'verification'),\n",
       "  1),\n",
       " (('are transformers more robust than cnns?', 'more'), 1),\n",
       " (('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   'assessing'),\n",
       "  1),\n",
       " (('automated essay scoring using efficient transformer-based language models',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('automated tabulation of clinical trial results: a joint entity and relation extraction approach with transformer-based language representations',\n",
       "   'trial'),\n",
       "  1),\n",
       " (('automatic detection of rail components via a deep convolutional transformer network',\n",
       "   'rail'),\n",
       "  1),\n",
       " (('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   'ava:'),\n",
       "  1),\n",
       " (('avatr: one-shot speaker extraction with transformers', 'speaker'), 1),\n",
       " (('avatr: one-shot speaker extraction with transformers', 'extraction'), 1),\n",
       " (('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   'voltage'),\n",
       "  1),\n",
       " (('bert based transformers lead the way in extraction of health information from social media',\n",
       "   'bert'),\n",
       "  1),\n",
       " (('beyond self-attention: external attention using two linear layers for visual tasks',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('bidirectional encoder representations from transformers for the covid-19 vaccine stance classification',\n",
       "   'vaccine'),\n",
       "  1),\n",
       " (('billion-scale pretraining with vision transformers for multi-task visual representations',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('c5t5: controllable generation of organic molecules with transformers',\n",
       "   'controllable'),\n",
       "  1),\n",
       " (('cate: computation-aware neural architecture encoding with transformers',\n",
       "   'computation-aware'),\n",
       "  2),\n",
       " (('chord conditioned melody generation with transformer based decoders',\n",
       "   'melody'),\n",
       "  1),\n",
       " (('cmsaone@dravidian-codemix-fire2020: a meta embedding and transformer model for code-mixed sentiment analysis on social media text',\n",
       "   'a'),\n",
       "  1),\n",
       " (('combining transformer-based models with traditional machine learning approaches for sexism identification in social networks at exist 2021',\n",
       "   'sexism'),\n",
       "  1),\n",
       " (('consistent accelerated inference via confident adaptive transformers',\n",
       "   'accelerated'),\n",
       "  1),\n",
       " (('conversational agent embodying a historical figure using transformers',\n",
       "   'agent'),\n",
       "  1),\n",
       " (('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('deepfake detection scheme based on vision transformer and distillation',\n",
       "   'on'),\n",
       "  1),\n",
       " (('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   'deeplpc-mhanet:'),\n",
       "  1),\n",
       " (('defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions',\n",
       "   'method'),\n",
       "  1),\n",
       " (('detecting dementia from speech and transcripts using transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('detection of transformer winding axial displacement by kirchhoff and delay and sum radar imaging algorithms',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('developing real-time streaming transformer transducer for speech recognition on large-scale dataset',\n",
       "   'real-time'),\n",
       "  1),\n",
       " (('diagnosing transformers in task-oriented semantic parsing', 'semantic'),\n",
       "  1),\n",
       " (('discriminative and generative transformer-based models for situation entity classification',\n",
       "   'discriminative'),\n",
       "  1),\n",
       " (('dispensed transformer network for unsupervised domain adaptation',\n",
       "   'domain'),\n",
       "  1),\n",
       " (('dlsa: dual-learning based on self-attention for rating prediction', 'for'),\n",
       "  1),\n",
       " (('eeg classification with transformer-based models', 'classification'), 1),\n",
       " (('empirical analysis of training strategies of transformer-based japanese chit-chat systems',\n",
       "   'strategies'),\n",
       "  1),\n",
       " (('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   'spotting'),\n",
       "  1),\n",
       " (('evaluating transformers for lightweight action recognition',\n",
       "   'lightweight'),\n",
       "  1),\n",
       " (('evaluation of static synchronous compensator and rail power conditioner in electrified railway systems using v/v and scott power transformers',\n",
       "   'power'),\n",
       "  2),\n",
       " (('everything at once - multi-modal fusion transformer for video retrieval',\n",
       "   'at'),\n",
       "  1),\n",
       " (('explainable identification of dementia from transcripts using transformer networks',\n",
       "   'dementia'),\n",
       "  1),\n",
       " (('exploring and improving mobile level vision transformers', 'and'), 1),\n",
       " (('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   'via'),\n",
       "  1),\n",
       " (('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   'spaces'),\n",
       "  1),\n",
       " (('exploring the promises of transformer-based lms for the representation of normative claims in the legal domain',\n",
       "   'of'),\n",
       "  2),\n",
       " (('fast and precise certification of transformers', 'and'), 1),\n",
       " (('fast point transformer', 'point'), 1),\n",
       " (('fbert: a neural transformer for identifying offensive content', 'a'), 2),\n",
       " (('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   'fine-tuning'),\n",
       "  1),\n",
       " (('generative video transformer: can objects be the words?', 'can'), 1),\n",
       " (('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   'fast'),\n",
       "  1),\n",
       " (('high-fidelity pluralistic image completion with transformers', 'image'),\n",
       "  2),\n",
       " (('ice hockey player identification via transformers', 'ice'), 1),\n",
       " (('ice hockey player identification via transformers', 'via'), 1),\n",
       " (('iiitt@lt-edi-eacl2021-hope speech detection: there is always hope in transformers',\n",
       "   'hope'),\n",
       "  1),\n",
       " (('image captioning with transformer and knowledge graph', 'and'), 1),\n",
       " (('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   'via'),\n",
       "  1),\n",
       " (('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   'accelerator'),\n",
       "  1),\n",
       " (('incorporating transformer models for sentiment analysis and news classification in khmer',\n",
       "   'khmer'),\n",
       "  1),\n",
       " (('integration of patch features through self-supervised learning and transformer for survival analysis on whole slide images',\n",
       "   'self-supervised'),\n",
       "  1),\n",
       " ((\"interaction retardeacutee dans l'encodeur du transformer pour reacutepondre efficacement aux questions dans un domaine ouvert\",\n",
       "   'reacutepondre'),\n",
       "  1),\n",
       " (('karl-trans-ner: knowledge aware representation learning for named entity recognition using transformers',\n",
       "   'karl-trans-ner:'),\n",
       "  1),\n",
       " (('language modeling using lmus: 10x better data efficiency or improved scaling compared to transformers',\n",
       "   'to'),\n",
       "  1),\n",
       " (('large scale audio understanding without transformers/ convolutions/ berts/ mixers/ attention/ rnns or ...',\n",
       "   'audio'),\n",
       "  1),\n",
       " (('lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing',\n",
       "   'error'),\n",
       "  1),\n",
       " (('light field image super-resolution with transformers', 'super-resolution'),\n",
       "  1),\n",
       " (('local-to-global self-attention in vision transformers', 'vision'), 1),\n",
       " (('m2gan: a multi-stage self-attention network for image rain removal on autonomous vehicles',\n",
       "   'removal'),\n",
       "  1),\n",
       " (('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   'multi-attribute'),\n",
       "  1),\n",
       " (('malbert: using transformers for cybersecurity and malicious software detection',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('mate: multi-view attention for table transformer efficiency',\n",
       "   'efficiency'),\n",
       "  2),\n",
       " (('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   'and'),\n",
       "  2),\n",
       " (('meetsum: transforming meeting transcript summarization using transformers!',\n",
       "   'meeting'),\n",
       "  1),\n",
       " (('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   'active'),\n",
       "  1),\n",
       " (('modeling age of acquisition norms using transformer networks', 'age'), 1),\n",
       " (('modular graph transformer networks for multi-label image classification',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('multi-airport delay prediction with transformers', 'transformers'), 1),\n",
       " (('multi-head fusion attention for transformer-based end-to-end automatic speech recognition',\n",
       "   'automatic'),\n",
       "  1),\n",
       " (('multi-head self-attention via vision transformer for zero-shot learning',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('multi-input transformer-less four-wire microinverter with distributed mppt for pv systems',\n",
       "   'four-wire'),\n",
       "  1),\n",
       " ((\"multilingual speech translation with unified transformer: huawei noah's ark lab at iwslt 2021\",\n",
       "   'speech'),\n",
       "  1),\n",
       " (('multimodal graph-based transformer framework for biomedical relation extraction',\n",
       "   'framework'),\n",
       "  1),\n",
       " (('multimodal incremental transformer with visual grounding for visual dialogue generation',\n",
       "   'incremental'),\n",
       "  1),\n",
       " (('multimodal motion prediction with stacked transformers', 'motion'), 2),\n",
       " (('ncu-nlp at rocling-2021 shared task: using macbert transformers for dimensional sentiment analysis',\n",
       "   'using'),\n",
       "  1),\n",
       " (('nlp-iis@ut at semeval-2021 task 4: machine reading comprehension using the long document transformer',\n",
       "   'document'),\n",
       "  1),\n",
       " (('on the effectiveness of vision transformers for zero-shot face anti-spoofing',\n",
       "   'effectiveness'),\n",
       "  1),\n",
       " (('opinion extraction as a structured sentiment analysis using transformers',\n",
       "   'sentiment'),\n",
       "  1),\n",
       " (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   'reduce'),\n",
       "  1),\n",
       " (('optimizing domain specificity of transformer-based language models for extractive summarization of financial news articles in korean',\n",
       "   'models'),\n",
       "  1),\n",
       " (('optimizing inference performance of transformers on cpus', 'optimizing'),\n",
       "  1),\n",
       " (('paraphrasing academic text: a study of back-translating anatomy and physiology with transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('pedestrian trajectory prediction via spatial interaction transformer network',\n",
       "   'pedestrian'),\n",
       "  1),\n",
       " (('phylotransformer: a discriminative model for mutation prediction based on a multi-head self-attention mechanism',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('point cloud learning with transformer', 'cloud'), 1),\n",
       " (('power grid cascading failure prediction based on transformer', 'based'),\n",
       "  1),\n",
       " (('power transformer fault diagnosis with intrinsic time-scale decomposition and xgboost classifier',\n",
       "   'and'),\n",
       "  1),\n",
       " (('pq-transformer: jointly parsing 3d objects and layouts from point clouds',\n",
       "   'and'),\n",
       "  1),\n",
       " (('predicting discourse trees from transformer-based neural summarizers',\n",
       "   'summarizers'),\n",
       "  1),\n",
       " (('progressively normalized self-attention network for video polyp segmentation',\n",
       "   'normalized'),\n",
       "  2),\n",
       " (('ptq4vit: post-training quantization framework for vision transformers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('pushing the limits of rule reasoning in transformers through natural language satisfiability',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('real-time semantic segmentation with dual encoder and self-attention mechanism for autonomous driving',\n",
       "   'autonomous'),\n",
       "  1),\n",
       " (('reasoning with transformer-based models: deep learning, but shallow reasoning',\n",
       "   'learning,'),\n",
       "  1),\n",
       " (('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   'capac-itance'),\n",
       "  1),\n",
       " (('research on on-line detection method of transformer winding deformation based on vfto',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "   'and'),\n",
       "  1),\n",
       " (('retra: recurrent transformers for learning temporally contextualized knowledge graph embeddings',\n",
       "   'contextualized'),\n",
       "  1),\n",
       " (('scale efficiently: insights from pre-training and fine-tuning transformers',\n",
       "   'scale'),\n",
       "  1),\n",
       " (('scat: stride consistency with auto-regressive regressor and transformer for hand pose estimation',\n",
       "   'consistency'),\n",
       "  1),\n",
       " (('seizure prediction using convolutional neural networks and sequence transformer networks',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   'action'),\n",
       "  1),\n",
       " (('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   'atherosclerotic'),\n",
       "  1),\n",
       " (('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   'tissue'),\n",
       "  1),\n",
       " (('self-attention between datapoints: going beyond individual input-output pairs in deep learning',\n",
       "   'between'),\n",
       "  2),\n",
       " (('self-attention for audio super-resolution', 'super-resolution'), 1),\n",
       " (('self-attention generative adversarial networks for times series vhr multispectral image generation',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('self-attention presents low-dimensional knowledge graph embeddings for link prediction',\n",
       "   'graph'),\n",
       "  1),\n",
       " (('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   'for'),\n",
       "  1),\n",
       " (('self-attention-based temporary curiosity in reinforcement learning exploration',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('self-supervised pre-training of swin transformers for 3d medical image analysis',\n",
       "   'of'),\n",
       "  1),\n",
       " (('semi-supervised sound event detection using self-attention and multiple techniques of consistency training',\n",
       "   'using'),\n",
       "  1),\n",
       " (('sequence-to-sequence piano transcription with transformers',\n",
       "   'transcription'),\n",
       "  1),\n",
       " (('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('session-based recommendation with self-attention networks',\n",
       "   'session-based'),\n",
       "  1),\n",
       " (('short-circuited turn fault diagnosis in transformers by using vibration signals, statistical time features, and support vector machines on fpga',\n",
       "   'fpga'),\n",
       "  1),\n",
       " (('single-shot motion completion with transformer', 'with'), 1),\n",
       " (('spatial-temporal transformer for dynamic scene graph generation', 'graph'),\n",
       "  2),\n",
       " (('speaker-aware speech enhancement with self-attention', 'with'), 1),\n",
       " (('spelling correction with denoising transformer', 'spelling'), 1),\n",
       " (('ssn_dibertsity@lt-edi-eacl2021: hope speech detection on multilingual youtube comments via transformer based approach',\n",
       "   'comments'),\n",
       "  1),\n",
       " (('styleswin: transformer-based gan for high-resolution image generation',\n",
       "   'high-resolution'),\n",
       "  1),\n",
       " (('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('t3-vis: visual analytic for training and fine-tuning transformers in nlp',\n",
       "   't3-vis:'),\n",
       "  1),\n",
       " (('tackling italian university assessment tests with transformer-based language models',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('text-conditioned transformer for automatic pronunciation error detection',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('the cause of transformer zero sequence overcurrent protection act',\n",
       "   'overcurrent'),\n",
       "  1),\n",
       " (('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   'of'),\n",
       "  1),\n",
       " (('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   'router:'),\n",
       "  1),\n",
       " (('the transformer network for the traveling salesman problem',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('token pooling in vision transformers', 'token'), 1),\n",
       " (('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   'object'),\n",
       "  1),\n",
       " (('transmvsnet: global context-aware multi-view stereo network with transformers',\n",
       "   'network'),\n",
       "  1),\n",
       " (('trar: routing the attention spans in transformer for visual question answering',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('tuta: tree-based transformers for generally structured table pre-training',\n",
       "   'tuta:'),\n",
       "  1),\n",
       " (('u-shape transformer for underwater image enhancement', 'image'), 1),\n",
       " (('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   '2021:'),\n",
       "  1),\n",
       " (('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   'swisstext-2021:'),\n",
       "  1),\n",
       " (('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   'text'),\n",
       "  1),\n",
       " (('video relation detection via tracklet based visual transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('video super-resolution transformer', 'video'), 1),\n",
       " (('vision transformers are robust learners', 'transformers'), 1),\n",
       " (('visual composite set detection using part-and-sum transformers',\n",
       "   'part-and-sum'),\n",
       "  1),\n",
       " (('voltage dependence of the reference system in medium- and high-voltage current transformer calibrations',\n",
       "   'of'),\n",
       "  1),\n",
       " (('wind speed forecasting method based on deep learning strategy using long short term memory neural network and transformer model',\n",
       "   'speed'),\n",
       "  1),\n",
       " (('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'distribution'),\n",
       "  1),\n",
       " (('a modified simulation model for predicting the fds of transformer oil-paper insulation under nonuniform aging',\n",
       "   'oil-paper'),\n",
       "  1),\n",
       " (('a multi-modal transformer-based code summarization approach for smart contracts',\n",
       "   'contracts'),\n",
       "  2),\n",
       " (('a new state-of-the-art transformers-based load forecaster on the smart grid domain',\n",
       "   'grid'),\n",
       "  1),\n",
       " (('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   'interleaved'),\n",
       "  1),\n",
       " (('a transformer based approach for fighting covid-19 fake news', 'approach'),\n",
       "  1),\n",
       " (('a transformer-based framework for neutralizing and reversing the political polarity of news articles',\n",
       "   'reversing'),\n",
       "  1),\n",
       " (('accelerating framework of transformer by hardware design and model compression co-optimization',\n",
       "   'of'),\n",
       "  1),\n",
       " (('an approach to steady-state power transformer modeling considering direct current resistance test measurements',\n",
       "   'direct'),\n",
       "  1),\n",
       " (('an automatic data acquisition device for transformer oscillating switching impulse voltage tests',\n",
       "   'impulse'),\n",
       "  1),\n",
       " (('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   'vibration'),\n",
       "  1),\n",
       " (('augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer',\n",
       "   'items'),\n",
       "  1),\n",
       " (('beit: bert pre-training of image transformers', 'image'), 1),\n",
       " (('benchmarking detection transfer learning with vision transformers',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('bert busters: outlier dimensions that disrupt transformers', 'that'), 1),\n",
       " (('bilingual self-attention network: generating headlines for online linguistic questions',\n",
       "   'online'),\n",
       "  1),\n",
       " (('cac-emvt: efficient coronary artery calcium segmentation with multi-scale vision transformers',\n",
       "   'multi-scale'),\n",
       "  1),\n",
       " (('canonical segmentation using affix characters as a unit on transformer for javanese language',\n",
       "   'javanese'),\n",
       "  1),\n",
       " (('case relation transformer: a crossmodal language generation model for fetching instructions',\n",
       "   'language'),\n",
       "  2),\n",
       " (('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   'recursive'),\n",
       "  1),\n",
       " (('cdtrans: cross-domain transformer for unsupervised domain adaptation',\n",
       "   'domain'),\n",
       "  1),\n",
       " (('certified patch robustness via smoothed vision transformers', 'via'), 1),\n",
       " (('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   'answering'),\n",
       "  1),\n",
       " (('code prediction by feeding trees to transformers', 'code'), 1),\n",
       " (('combining efficientnet and vision transformers for video deepfake detection',\n",
       "   'video'),\n",
       "  1),\n",
       " (('comformer: code comment generation via transformer and fusion method-based hybrid code representation',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('comparison of machine learning algorithms for the prediction of mechanical stress in three-phase power transformer winding conductors',\n",
       "   'machine'),\n",
       "  1),\n",
       " (('component-level thermo-electromagnetic nonlinear transient finite element modeling of solid-state transformer for dc grid studies',\n",
       "   'component-level'),\n",
       "  1),\n",
       " (('contextual-semantic-aware linkable knowledge prediction in stack overflow via self-attention',\n",
       "   'linkable'),\n",
       "  1),\n",
       " (('convolutional neural network or vision transformer? benchmarking various machine learning models for distracted driver detection',\n",
       "   'transformer?'),\n",
       "  1),\n",
       " (('covid-net us: a tailored, highly efficient, self-attention deep convolutional neural network design for detection of covid-19 patient cases from point-of-care ultrasound imaging',\n",
       "   'from'),\n",
       "  1),\n",
       " (('cptr: full transformer network for image captioning', 'full'), 1),\n",
       " (('crossvit: cross-attention multi-scale vision transformer for image classification',\n",
       "   'transformer'),\n",
       "  2),\n",
       " (('cs-um6p at semeval-2021 task 1: a deep learning model-based pre-trained transformer encoder for lexical complexity',\n",
       "   'model-based'),\n",
       "  1),\n",
       " (('deep transformer networks for time series classification: the npp safety case',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('delving deep into the generalization of vision transformers under distribution shifts',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('demystifying local vision transformer: sparse connectivity, weight sharing, and dynamic weight',\n",
       "   'connectivity,'),\n",
       "  1),\n",
       " (('detection of abusive records by analyzing the tweets in urdu language exploring transformer based models',\n",
       "   'records'),\n",
       "  1),\n",
       " (('dg-trans: automatic code summarization via dynamic graph attention-based transformer',\n",
       "   'via'),\n",
       "  1),\n",
       " (('diformer: directional transformer for neural machine translation',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('discrete representations strengthen vision transformer robustness',\n",
       "   'discrete'),\n",
       "  1),\n",
       " (('disease classification on admission and on discharge with residual cnn-transformer',\n",
       "   'admission'),\n",
       "  1),\n",
       " (('dissolved gas analysis for transformer fault based on learning spiking neural p system with belief adaboost',\n",
       "   'based'),\n",
       "  1),\n",
       " (('do transformers really perform badly for graph representation?', 'graph'),\n",
       "  1),\n",
       " (('do we really need explicit position encodings for vision transformers?',\n",
       "   'explicit'),\n",
       "  1),\n",
       " (('doctr: document image transformer for geometric unwarping and illumination correction',\n",
       "   'unwarping'),\n",
       "  1),\n",
       " (('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   'multi-temporal'),\n",
       "  1),\n",
       " (('dpnet: dual-path network for efficient object detectioj with lightweight self-attention',\n",
       "   'with'),\n",
       "  1),\n",
       " (('dsgpt: domain-specific generative pre-training of transformers for text generation in e-commerce title and review summarization',\n",
       "   'title'),\n",
       "  1),\n",
       " (('dynamic transformer for efficient machine translation on embedded devices',\n",
       "   'on'),\n",
       "  1),\n",
       " (('effective ensembling of transformer based language models for acronyms identification',\n",
       "   'for'),\n",
       "  1),\n",
       " (('efficient-capsnet: capsule network with self-attention routing',\n",
       "   'network'),\n",
       "  1),\n",
       " (('embedding calibration for music semantic similarity using auto-regressive transformer',\n",
       "   'auto-regressive'),\n",
       "  1),\n",
       " (('empathetic robot with transformer-based dialogue agent', 'robot'), 1),\n",
       " (('english machine translation model based on an improved self-attention technology',\n",
       "   'machine'),\n",
       "  1),\n",
       " (('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   'structures'),\n",
       "  1),\n",
       " (('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('enriching the transformer with linguistic factors for low-resource machine translation',\n",
       "   'linguistic'),\n",
       "  1),\n",
       " (('erratum: rodrigo-mor et al. principles of charge estimation methods using high-frequency current transformer sensors in partial discharge measurements. sensors 2020, 20, 2520',\n",
       "   'principles'),\n",
       "  1),\n",
       " (('evolving transformer architecture for neural machine translation',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   'for'),\n",
       "  1),\n",
       " (('exploring sequence feature alignment for domain adaptive detection transformers',\n",
       "   'domain'),\n",
       "  1),\n",
       " (('exploring transformer based models to identify hate speech and offensive content in english and indo-aryan languages',\n",
       "   'content'),\n",
       "  1),\n",
       " (('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   'moisture'),\n",
       "  1),\n",
       " (('feature fusion vision transformer for fine-grained visual categorization',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('few-shot temporal action localization with query adaptive transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('fine-tuning of pre-trained transformers for hate, offensive, and profane content detection in english and marathi',\n",
       "   'for'),\n",
       "  1),\n",
       " ((\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   'microscopy'),\n",
       "  1),\n",
       " (('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   'llc'),\n",
       "  1),\n",
       " (('fu covid-19 ai agent built on attention algorithm using a combination of transformer, albert model, and rasa framework',\n",
       "   'algorithm'),\n",
       "  1),\n",
       " (('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   'abnormal'),\n",
       "  1),\n",
       " (('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   'in'),\n",
       "  1),\n",
       " (('geometry-contrastive transformer for generalized 3d pose transfer',\n",
       "   'geometry-contrastive'),\n",
       "  1),\n",
       " (('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('greenformers: improving computation and memory efficiency in transformer models via low-rank approximation',\n",
       "   'computation'),\n",
       "  1),\n",
       " (('hate speech and offensive content identification based on self-attention',\n",
       "   'and'),\n",
       "  1),\n",
       " (('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   'network'),\n",
       "  1),\n",
       " (('high-frequency current transformer design and implementation considerations for wideband partial discharge applications',\n",
       "   'current'),\n",
       "  1),\n",
       " (('how geometry affects sensitivity of a differential transformer for contactless characterization of liquids',\n",
       "   'differential'),\n",
       "  1),\n",
       " (('i2c2w: image-to-character-to-word transformers for accurate scene text recognition',\n",
       "   'i2c2w:'),\n",
       "  1),\n",
       " (('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   'high'),\n",
       "  1),\n",
       " (('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   'voltage'),\n",
       "  1),\n",
       " (('implicit transformer network for screen content image continuous super-resolution',\n",
       "   'implicit'),\n",
       "  1),\n",
       " (('improved few-shot learning method for transformer fault diagnosis based on approximation space and belief functions',\n",
       "   'approximation'),\n",
       "  1),\n",
       " (('incorporating relative position information in transformer-based sign language recognition and translation',\n",
       "   'translation'),\n",
       "  1),\n",
       " (('indt5: a text-to-text transformer for 10 indigenous languages', '10'), 1),\n",
       " (('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   'a'),\n",
       "  1),\n",
       " (('inversemv: composing piano scores with a convolutional video-music transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('keyword transformer: a self-attention model for keyword spotting',\n",
       "   'model'),\n",
       "  1),\n",
       " (('learning generalizable vision-tactile robotic grasping strategy for deformable objects via transformer',\n",
       "   'via'),\n",
       "  1),\n",
       " (('learning transformer features for image quality assessment', 'features'),\n",
       "  1),\n",
       " (('legoformer: transformers for block-by-block multi-view 3d reconstruction',\n",
       "   'multi-view'),\n",
       "  1),\n",
       " (('make a long image short: adaptive token length for vision transformers',\n",
       "   'adaptive'),\n",
       "  1),\n",
       " (('mgsan: a multi-granularity self-attention network for next poi recommendation',\n",
       "   'mgsan:'),\n",
       "  1),\n",
       " (('mixed transformer u-net for medical image segmentation', 'u-net'), 1),\n",
       " (('mldt: multi-task learning with denoising transformer for gait identity and emotion recognition',\n",
       "   'gait'),\n",
       "  1),\n",
       " (('modeling capacitive low-power voltage transformer behavior over temperature and frequency',\n",
       "   'frequency'),\n",
       "  1),\n",
       " (('modelling of high frequency coreless planar transformer with twr hexagonal winding',\n",
       "   'winding'),\n",
       "  1),\n",
       " (('modified deep transformers for gnss time series prediction', 'prediction'),\n",
       "  1),\n",
       " (('monte carlo denoising via auxiliary feature guided self-attention',\n",
       "   'auxiliary'),\n",
       "  1),\n",
       " (('morphmlp: a self-attention free, mlp-like backbone for image and video',\n",
       "   'video'),\n",
       "  1),\n",
       " (('multi-exit vision transformer for dynamic inference', 'dynamic'), 1),\n",
       " (('mutformer: a context-dependent transformer-based model to predict pathogenic missense mutations',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('ncuee-nlp at mediqa 2021: health question summarization using pegasus transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('noniterative design of litz-wire high-frequency gapped-transformer (lw-hfgt) for llc converters based on optimal core-geometry factor model (okgm)',\n",
       "   'model'),\n",
       "  1),\n",
       " (('on efficient transformer and image pre-training for low-level vision',\n",
       "   'efficient'),\n",
       "  1),\n",
       " (('on the impact of grid harmonics in transformers: a case study',\n",
       "   'transformers:'),\n",
       "  1),\n",
       " (('optimizing latency for online video captioningusing audio-visual transformers',\n",
       "   'audio-visual'),\n",
       "  1),\n",
       " (('pctma-net: point cloud transformer with morphing atlas-based point generation network for dense point cloud completion',\n",
       "   'completion'),\n",
       "  1),\n",
       " (('point-bert: pre-training 3d point cloud transformers with masked point modeling',\n",
       "   'cloud'),\n",
       "  1),\n",
       " (('portfolio optimization with 2d relative-attentional gated transformer',\n",
       "   'optimization'),\n",
       "  1),\n",
       " (('power transformer fault diagnosis system based on internet of things',\n",
       "   'of'),\n",
       "  1),\n",
       " (('predicting esophageal fistula risks using a multimodal self-attention network',\n",
       "   'fistula'),\n",
       "  1),\n",
       " (('predicting real-time scientific experiments using transformer models and reinforcement learning',\n",
       "   'scientific'),\n",
       "  1),\n",
       " (('probing inter-modality: visual parsing with self-attention for vision-and-language pre-training',\n",
       "   'vision-and-language'),\n",
       "  1),\n",
       " (('prostformer: pre-trained progressive space-time self-attention model for traffic flow forecasting',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('pyramid medical transformer for medical image segmentation', 'for'), 1),\n",
       " (('radiology report generation for rare diseases via few-shot transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('remote sensing image defogging networks based on dual self-attention boost residual octave convolution',\n",
       "   'on'),\n",
       "  1),\n",
       " (('research on hybrid feature selection method of power transformer based on fuzzy information entropy',\n",
       "   'feature'),\n",
       "  1),\n",
       " (('revamping cross-modal recipe retrieval with hierarchical transformers and self-supervised learning',\n",
       "   'with'),\n",
       "  1),\n",
       " (('risc-vtf: risc-v based extended instruction set for transformer', 'based'),\n",
       "  1),\n",
       " ((\"rnn's vs transformers: training language models on deficit datasets\",\n",
       "   'vs'),\n",
       "  1),\n",
       " (('running status diagnosis of onboard traction transformers based on kernel principal component analysis and fuzzy clustering',\n",
       "   'component'),\n",
       "  1),\n",
       " (('sa-capsgan: using capsule networks with embedded self-attention for generative adversarial network',\n",
       "   'adversarial'),\n",
       "  1),\n",
       " (('sa-matd3: self-attention-based multi-agent continuous control method in cooperative environments',\n",
       "   'cooperative'),\n",
       "  1),\n",
       " (('self-attention agreement among capsules', 'among'), 1),\n",
       " (('self-attention attribution: interpreting information interactions inside transformer',\n",
       "   'inside'),\n",
       "  1),\n",
       " (('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   'anchor'),\n",
       "  1),\n",
       " (('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   'proposal'),\n",
       "  1),\n",
       " (('self-attention graph residual convolutional networks for event detection with dependency relations',\n",
       "   'relations'),\n",
       "  1),\n",
       " (('self-attention in reconstruction bias u-net for semantic segmentation of building rooftops in optical remote sensing images',\n",
       "   'building'),\n",
       "  1),\n",
       " (('self-supervised video transformer', 'self-supervised'), 1),\n",
       " (('sentimentarcs: a novel method for self-supervised sentiment analysis of time series shows sota transformers can struggle finding narrative arcs',\n",
       "   'arcs'),\n",
       "  1),\n",
       " (('severity quantification and lesion localization of covid-19 on cxr using vision transformer',\n",
       "   'lesion'),\n",
       "  1),\n",
       " (('shallow convolution-augmented transformer with differentiable neural computer for low-complexity classification of variable-length acoustic scene',\n",
       "   'low-complexity'),\n",
       "  1),\n",
       " (('shuffle transformer with feature alignment for video face parsing',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   'image'),\n",
       "  1),\n",
       " (('skyformer: remodel self-attention with gaussian kernel and nystroumlm method',\n",
       "   'with'),\n",
       "  1),\n",
       " (('sparse spatial transformers for few-shot learning', 'learning'), 1),\n",
       " (('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('stformer: a noise-aware efficient spatio-temporal transformer architecture for traffic forecasting',\n",
       "   'traffic'),\n",
       "  1),\n",
       " (('stochastic attention head removal: a simple and effective method for improving transformer based asr models',\n",
       "   'stochastic'),\n",
       "  1),\n",
       " (('streaming transformer for hardware efficient voice trigger detection and false trigger mitigation',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('study on the sound radiation efficiency of a typical distribution transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('svt-net: a super light-weight network for large scale place recognition using sparse voxel transformers',\n",
       "   'voxel'),\n",
       "  1),\n",
       " (('tag: gradient attack on transformer-based language models', 'language'),\n",
       "  1),\n",
       " (('task adaptive pretraining of transformers for hostility detection',\n",
       "   'hostility'),\n",
       "  1),\n",
       " (('tcl: transformer-based dynamic graph modelling via contrastive learning',\n",
       "   'tcl:'),\n",
       "  1),\n",
       " (('test-time personalization with a transformer for human pose estimation',\n",
       "   'estimation'),\n",
       "  2),\n",
       " (('the development of precision 500/√3-kv two-stage voltage transformer with high-voltage excitation',\n",
       "   'the'),\n",
       "  1),\n",
       " (('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   'too'),\n",
       "  1),\n",
       " (('towards more efficient insertion transformer with fractional positional encoding',\n",
       "   'efficient'),\n",
       "  1),\n",
       " (('trans-svnet: accurate phase recognition from surgical videos via hybrid embedding aggregation transformer',\n",
       "   'phase'),\n",
       "  2),\n",
       " (('transcouplet: transformer based chinese couplet generation', 'couplet'),\n",
       "  1),\n",
       " (('transformer based end-to-end mispronunciation detection and diagnosis',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('transformer based neural network for fine-grained classification of vehicle color',\n",
       "   'based'),\n",
       "  1),\n",
       " (('transformer meets dcfam: a novel semantic segmentation scheme for fine-resolution remote sensing images',\n",
       "   'scheme'),\n",
       "  1),\n",
       " (('transformer reasoning network for personalized review summarization',\n",
       "   'for'),\n",
       "  1),\n",
       " (('transformer-based dual relation graph for multi-label image recognition',\n",
       "   'image'),\n",
       "  1),\n",
       " (('transformers and transfer learning for improving portuguese semantic role labeling',\n",
       "   'portuguese'),\n",
       "  1),\n",
       " (('transformers for headline selection for russian news clusters', 'russian'),\n",
       "  1),\n",
       " (('transforming fake news: robust generalisable news classification using transformers',\n",
       "   'fake'),\n",
       "  1),\n",
       " (('transhash: transformer-based hamming hashing for efficient image retrieval',\n",
       "   'efficient'),\n",
       "  1),\n",
       " (('translation transformers rediscover inherent data domains',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   'instance'),\n",
       "  1),\n",
       " (('tritransnet: rgb-d salient object detection with a triplet transformer embedding network',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('tsdae: using transformer-based sequential denoising auto-encoder for unsupervised sentence embedding learning',\n",
       "   'denoising'),\n",
       "  1),\n",
       " (('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   'tsdae:'),\n",
       "  1),\n",
       " (('twitter dataset and evaluation of transformers for turkish sentiment analysis',\n",
       "   'analysis'),\n",
       "  1),\n",
       " (('two-hand pose estimation from the non-cropped rgb image with self-attention based network',\n",
       "   'image'),\n",
       "  1),\n",
       " (('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('understanding and overcoming the challenges of efficient transformer quantization',\n",
       "   'overcoming'),\n",
       "  1),\n",
       " (('video joint modelling based on hierarchical transformer for co-summarization',\n",
       "   'based'),\n",
       "  1),\n",
       " (('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   'viesum:'),\n",
       "  1),\n",
       " (('vision and text transformer for predicting answerability on visual question answering',\n",
       "   'text'),\n",
       "  1),\n",
       " (('vision transformer for plant disease detection: plantvit', 'transformer'),\n",
       "  1),\n",
       " (('vision transformer for plant disease detection: plantvit', 'disease'), 1),\n",
       " (('vision transformer using low-level chest x-ray feature corpus for covid-19 diagnosis and severity quantification',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('visual grounding with transformers', 'grounding'), 1),\n",
       " (('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   'vitality:'),\n",
       "  1),\n",
       " (('what context features can transformer language models use?', 'use?'), 1),\n",
       " (('wide-band current transformers for traveling-waves-based protection applications',\n",
       "   'for'),\n",
       "  1),\n",
       " (('word representation learning in multimodal pre-trained transformers: an intrinsic evaluation',\n",
       "   'intrinsic'),\n",
       "  1),\n",
       " (('wrtre: weighted relative position transformer for joint entity and relation extraction',\n",
       "   'wrtre:'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   '16.8-to-21.6'),\n",
       "  1),\n",
       " (('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   'three-phase'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'fine-grained'),\n",
       "  1),\n",
       " (('a mm-wave gm-assisted transformer-based matching network 2x2 phased-array receiver for 5g communication and radar systems',\n",
       "   'communication'),\n",
       "  1),\n",
       " (('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "   'dc'),\n",
       "  1),\n",
       " (('a novel suppression method for grounding transformer against earth current from urban rail transit',\n",
       "   'novel'),\n",
       "  1),\n",
       " (('a pre-ln transformer network model with lexical features for fine-grained sentiment classification',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a serial-parallel self-attention network joint with multi-scale dilated convolution',\n",
       "   'dilated'),\n",
       "  1),\n",
       " (('a sketch-transformer network for face photo-sketch synthesis',\n",
       "   'synthesis'),\n",
       "  1),\n",
       " (('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a transformer-less voltage equalizer for energy storage cells based on double-tiered multi-stacked converters',\n",
       "   'cells'),\n",
       "  1),\n",
       " (('accommodating transformer onto fpga: coupling the balanced model compression and fpga-implementation optimization',\n",
       "   'fpga:'),\n",
       "  1),\n",
       " (('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   'an'),\n",
       "  1),\n",
       " (('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   'and'),\n",
       "  1),\n",
       " (('analysis and design of an integrated magnetics planar transformer for high power density llc resonant converter',\n",
       "   'llc'),\n",
       "  1),\n",
       " (('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   'of'),\n",
       "  1),\n",
       " (('asformer: transformer for action segmentation', 'transformer'), 1),\n",
       " (('assessment of effect of winding geometry on thermal performance of retrofilled transformers',\n",
       "   'winding'),\n",
       "  1),\n",
       " (('be specific, be clear: bridging machine and human captions by scene-guided transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('beamtransformer: microphone array-based overlapping speech detection',\n",
       "   'array-based'),\n",
       "  1),\n",
       " (('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   'mri'),\n",
       "  1),\n",
       " (('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   'perform'),\n",
       "  1),\n",
       " (('combining cnns with transformer for multimodal 3d mri brain tumor segmentation with self-supervised pretraining',\n",
       "   'for'),\n",
       "  1),\n",
       " (('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   'solid-state-transformers'),\n",
       "  1),\n",
       " (('constructing global coherence representations: identifying interpretability and coherences of transformer attention in time series data',\n",
       "   'constructing'),\n",
       "  1),\n",
       " (('contextual similarity aggregation with self-attention for visual re-ranking',\n",
       "   'aggregation'),\n",
       "  1),\n",
       " (('cotr: correspondence transformer for matching across images', 'matching'),\n",
       "  1),\n",
       " (('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   'models'),\n",
       "  1),\n",
       " (('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   'cyclegan-based'),\n",
       "  1),\n",
       " (('cyclic diffeomorphic transformer nets for contour alignment',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('deep transformer networks for time series classification: the npp safety case',\n",
       "   'for'),\n",
       "  1),\n",
       " (('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   'for'),\n",
       "  1),\n",
       " (('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   'ensemble'),\n",
       "  1),\n",
       " (('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   'low-loss'),\n",
       "  1),\n",
       " (('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   'ultra-wideband'),\n",
       "  1),\n",
       " (('discriminative and generative transformer-based models for situation entity classification',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('diverse image inpainting with bidirectional and autoregressive transformers',\n",
       "   'diverse'),\n",
       "  1),\n",
       " (('dropout regularization for self-supervised learning of transformer encoder speech representation',\n",
       "   'of'),\n",
       "  1),\n",
       " (('dynamic graph representation learning for video dialog via multi-modal shuffled transformers',\n",
       "   'multi-modal'),\n",
       "  1),\n",
       " (('effect of iron/titania-based nanomaterials on the dielectric properties of mineral oil, natural and synthetic esters as transformers insulating fluid',\n",
       "   'properties'),\n",
       "  1),\n",
       " (('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   'voltages'),\n",
       "  1),\n",
       " (('efficient video transformers with spatial-temporal token selection',\n",
       "   'with'),\n",
       "  1),\n",
       " (('electric transformer oil leakage visual detection as service based on lstm and genetic algorithm',\n",
       "   'and'),\n",
       "  1),\n",
       " (('emerging properties in self-supervised vision transformers', 'properties'),\n",
       "  1),\n",
       " (('end-to-end human object interaction detection with hoi transformer',\n",
       "   'end-to-end'),\n",
       "  1),\n",
       " (('end-to-end temporal action detection with transformer', 'end-to-end'), 1),\n",
       " (('enhancing lstm models with self-attention and stateful training',\n",
       "   'models'),\n",
       "  1),\n",
       " (('ernie-doc: a retrospective long-document modeling transformer', 'a'), 1),\n",
       " (('exploring low-cost transformer model compression for large-scale commercial reply suggestions',\n",
       "   'reply'),\n",
       "  1),\n",
       " (('gene transformer: transformers for the gene expression-based classification of cancer subtypes',\n",
       "   'subtypes'),\n",
       "  1),\n",
       " (('global structure-aware drum transcription based on self-attention mechanisms',\n",
       "   'drum'),\n",
       "  1),\n",
       " (('grid partitioned attention: efficient transformerapproximation with inductive bias for high resolution detail generation',\n",
       "   'attention:'),\n",
       "  1),\n",
       " (('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   'for'),\n",
       "  1),\n",
       " (('h9 and h10 transformer-less solar photovoltaic inverters for leakage current suppression and harmonic current reduction',\n",
       "   'current'),\n",
       "  2),\n",
       " (('hcit: deepfake video detection using a hybrid model of cnn features and vision transformer',\n",
       "   'features'),\n",
       "  1),\n",
       " (('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   'for'),\n",
       "  1),\n",
       " (('hierarchical transformer: unsupervised representation learning for skeleton-based human action recognition',\n",
       "   'unsupervised'),\n",
       "  1),\n",
       " (('how many layers and why? an analysis of the model depth in transformers',\n",
       "   'and'),\n",
       "  1),\n",
       " (('hsan: a hierarchical self-attention network for multi-turn dialogue generation',\n",
       "   'dialogue'),\n",
       "  1),\n",
       " (('hybrid cnn-gru framework with integrated pre-trained language transformer for sms phishing detection',\n",
       "   'sms'),\n",
       "  1),\n",
       " (('image captioning in hindi language using transformer networks', 'image'),\n",
       "  1),\n",
       " (('image captioning using multiple transformers for self-attention mechanism',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('interval fuzzy probability method for power transformer multiple fault diagnosis',\n",
       "   'probability'),\n",
       "  1),\n",
       " (('lbert: lexically-aware transformers based bidirectional encoder representation model for learning universal bio-entity relations',\n",
       "   'lexically-aware'),\n",
       "  1),\n",
       " (('learning a 3d-cnn and transformer prior for hyperspectral image super-resolution',\n",
       "   'hyperspectral'),\n",
       "  1),\n",
       " (('legal text classification and summarization using transformers and joint text features',\n",
       "   'features'),\n",
       "  1),\n",
       " (('lightweight causal transformer with local self-attention for real-time speech enhancement',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('locating inter-turn faults in transformer windings using isometric feature mapping of frequency response traces',\n",
       "   'in'),\n",
       "  1),\n",
       " (('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('mask-guided spectral-wise transformer for efficient hyperspectral image reconstruction',\n",
       "   'image'),\n",
       "  1),\n",
       " (('measurement of very fast transient overvoltages in current transformers at open air hv substations',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('mect: multi-metadata embedding based cross-transformer for chinese named entity recognition',\n",
       "   'cross-transformer'),\n",
       "  1),\n",
       " (('memory-efficient transformers via top-k attention', 'memory-efficient'),\n",
       "  1),\n",
       " (('mirtt: learning multimodal interaction representations from trilinear transformers for visual question answering',\n",
       "   'trilinear'),\n",
       "  1),\n",
       " (('modeling of cross-circulating currents in a mmc with parallel connected submodules in solid state transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('multi-compound transformer for accurate biomedical image segmentation',\n",
       "   'biomedical'),\n",
       "  1),\n",
       " (('multi-modal fusion transformer for end-to-end autonomous driving',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('multi-transformer: a new neural network-based architecture for forecasting sandp volatility',\n",
       "   'for'),\n",
       "  1),\n",
       " (('multilevel inverter with a new modulation method applied to solid-state transformer in pv applications',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   'for'),\n",
       "  1),\n",
       " (('new operation opportunities for the solid-state transformer in smart homes: a comprehensive analysis',\n",
       "   'smart'),\n",
       "  1),\n",
       " ((\"noisy text data: achilles' heel of popular transformer based nlp models\",\n",
       "   'nlp'),\n",
       "  1),\n",
       " (('non-local self-attention mechanism for real-time context embedding deep shadow removal network',\n",
       "   'removal'),\n",
       "  1),\n",
       " (('noninvasive self-attention for side information fusion in sequential recommendation',\n",
       "   'in'),\n",
       "  1),\n",
       " (('offline pre-trained multi-agent decision transformer: one big sequence model tackles all smac tasks',\n",
       "   'multi-agent'),\n",
       "  1),\n",
       " (('on exploring attention-based explanation for transformer models in text classification',\n",
       "   'attention-based'),\n",
       "  1),\n",
       " (('on improving adversarial transferability of vision transformers',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('on-device streaming transformer-based end-to-end speech recognition',\n",
       "   'speech'),\n",
       "  1),\n",
       " (('person re-identification with a locally aware transformer',\n",
       "   're-identification'),\n",
       "  1),\n",
       " (('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   'position-informed'),\n",
       "  1),\n",
       " (('poat-net: parallel offset-attention assisted transformer for 3d object detection for autonomous driving',\n",
       "   'poat-net:'),\n",
       "  1),\n",
       " (('power transformer faults diagnosis using undestructive methods (roger and iec) and artificial neural network for dissolved gas analysis applied on the functional transformer in the algerian north-eastern: a comparative study',\n",
       "   '(roger'),\n",
       "  1),\n",
       " (('pre-training transformers for domain adaptation', 'domain'), 1),\n",
       " (('rams-trans: recurrent attention multi-scale transformer for fine-grained image recognition',\n",
       "   'image'),\n",
       "  1),\n",
       " (('real-time prediction of ocean observation data based on transformer model',\n",
       "   'real-time'),\n",
       "  1),\n",
       " (('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   'sensing'),\n",
       "  1),\n",
       " (('representation learning for neural population activity with neural data transformers',\n",
       "   'representation'),\n",
       "  1),\n",
       " (('rethinking skip connection with layer normalization in transformers and resnets',\n",
       "   'and'),\n",
       "  1),\n",
       " (('robustness evaluation of transformer-based form field extractors via form attacks',\n",
       "   'field'),\n",
       "  1),\n",
       " (('rpt: relational pre-trained transformer is almost all you need towards democratizing data preparation',\n",
       "   'rpt:'),\n",
       "  1),\n",
       " (('s2s-ft: fine-tuning pretrained transformer encoders for sequence-to-sequence learning',\n",
       "   'sequence-to-sequence'),\n",
       "  1),\n",
       " (('security requirements classification into groups using nlp transformers',\n",
       "   'using'),\n",
       "  1),\n",
       " (('self-adaptive neural module transformer for visual question answering',\n",
       "   'visual'),\n",
       "  1),\n",
       " (('semi-supervised graph instance transformer for mental health inference',\n",
       "   'for'),\n",
       "  1),\n",
       " (('soft sensing transformer: hundreds of sensors are worth a single word',\n",
       "   'are'),\n",
       "  2),\n",
       " (('spatio-temporal self-attention network for video saliency prediction',\n",
       "   'network'),\n",
       "  1),\n",
       " (('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   'spectr:'),\n",
       "  1),\n",
       " (('speech emotion recognition using recurrent neural networks with directional self-attention',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('stabilizing deep q-learning with convnets and vision transformers under data augmentation',\n",
       "   'data'),\n",
       "  1),\n",
       " (('study on operation parameter characteristics of induction filter distribution transformer in low-voltage distribution network',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('switch transformers: scaling to trillion parameter models with simple and efficient sparsity',\n",
       "   'trillion'),\n",
       "  1),\n",
       " (('target-specified sequence labeling with multi-head self-attention for target-oriented opinion words extraction',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('tbn-vit: temporal bilateral network with vision transformer for video scene parsing',\n",
       "   'with'),\n",
       "  1),\n",
       " (('tcs_witm_2021 @finsim-2: transformer based models for automatic classification of financial terms',\n",
       "   '@finsim-2:'),\n",
       "  1),\n",
       " (('template filling with generative transformers', 'template'), 1),\n",
       " (('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('the layout generation algorithm of graphic design based on transformer-cvae',\n",
       "   'algorithm'),\n",
       "  1),\n",
       " (('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('token labeling: training a 85.4% top-1 accuracy vision transformer with 56m parameters on imagenet',\n",
       "   'accuracy'),\n",
       "  1),\n",
       " (('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   'language'),\n",
       "  1),\n",
       " (('towards a comprehensive understanding and accurate evaluation of societal biases in pre-trained transformers',\n",
       "   'comprehensive'),\n",
       "  1),\n",
       " (('towards end-to-end image compression and analysis with transformers',\n",
       "   'image'),\n",
       "  1),\n",
       " (('towards explainable end-to-end prostate cancer relapse prediction from hande images combining self-attention multiple instance learning with a recurrent neural network',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('trading with the momentum transformer: an intelligent and interpretable architecture',\n",
       "   'transformer:'),\n",
       "  1),\n",
       " (('traisformer-a generative transformer for ais trajectory prediction',\n",
       "   'ais'),\n",
       "  1),\n",
       " (('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   'trans4trans:'),\n",
       "  1),\n",
       " (('transformation of transient overvoltages by inductive voltage transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('transformer ensemble system for detection of offensive content in dravidian languages',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('transformer-based approaches for personality detection using the mbti model',\n",
       "   'for'),\n",
       "  1),\n",
       " (('transformer-based korean pretrained language models: a survey on three years of progress',\n",
       "   'language'),\n",
       "  1),\n",
       " (('transformer-based long-term viewport prediction in 360° video: scanpath is all you need',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('transformer-based named entity recognition for parsing clinical trial eligibility criteria',\n",
       "   'eligibility'),\n",
       "  1),\n",
       " (('transmorph: transformer for unsupervised medical image registration',\n",
       "   'for'),\n",
       "  1),\n",
       " (('trufm: a transformer-guided framework for fine-grained urban flow inference',\n",
       "   'flow'),\n",
       "  1),\n",
       " (('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('tunet: a block-online bandwidth extension model based on transformers and self-supervised pretraining',\n",
       "   'block-online'),\n",
       "  1),\n",
       " (('turkish text classification: from lexicon analysis to bidirectional transformer',\n",
       "   'to'),\n",
       "  1),\n",
       " (('ufo: a unified transformer for vision-language representation learning',\n",
       "   'vision-language'),\n",
       "  1),\n",
       " (('umuteam at exist 2021: sexist language identification based on linguistic features and transformers in spanish and english',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('understanding transformers for bot detection in twitter', 'bot'), 1),\n",
       " (('unsupervised cross-domain person re-identification with self-attention and joint-flexible optimization',\n",
       "   'joint-flexible'),\n",
       "  1),\n",
       " (('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   'production'),\n",
       "  1),\n",
       " (('using recurrent neural network structure with enhanced multi-head self-attention for sentiment analysis',\n",
       "   'analysis'),\n",
       "  1),\n",
       " (('video background music generation with controllable music transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('vivit: a video vision transformer', 'vision'), 1),\n",
       " (('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   'image'),\n",
       "  1),\n",
       " (('w-core transformer model for chinese word segmentation', 'word'), 1),\n",
       " (('what helps transformers recognize conversational structure? importance of context, punctuation, and labels in dialog act recognition',\n",
       "   'importance'),\n",
       "  2),\n",
       " (('wifimod: transformer-based indoor human mobility modeling using passive sensing',\n",
       "   'sensing'),\n",
       "  2),\n",
       " (('word2pix: word to pixel cross attention transformer in visual grounding',\n",
       "   'pixel'),\n",
       "  1),\n",
       " (('x-volution: on the unification of convolution and self-attention', 'on'),\n",
       "  1),\n",
       " (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   'text'),\n",
       "  1),\n",
       " (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   'with'),\n",
       "  1),\n",
       " (('a new method for transformer fault prediction based on multifeature enhancement and refined long short-term memory',\n",
       "   'new'),\n",
       "  1),\n",
       " (('a new method of wave parameter retrieve based on transformer', 'wave'), 1),\n",
       " (('a transformer architecture based on bert and 2d convolutional neural network to identify dna enhancers from sequence information',\n",
       "   '2d'),\n",
       "  1),\n",
       " (('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   'high'),\n",
       "  1),\n",
       " (('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   'differential'),\n",
       "  1),\n",
       " (('adversarial attacks on kinship verification using transformer',\n",
       "   'adversarial'),\n",
       "  1),\n",
       " (('all bark and no bite: rogue dimensions in transformer language models obscure representational quality',\n",
       "   'obscure'),\n",
       "  1),\n",
       " (('an explainable transformer-based deep learning model for the prediction of incident heart failure',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('analyzing covid-19 tweets with transformer-based language models', 'with'),\n",
       "  1),\n",
       " (('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   'microorganism'),\n",
       "  1),\n",
       " (('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   'multilayer'),\n",
       "  1),\n",
       " (('ask2transformers: zero-shot domain labelling with pretrained language models',\n",
       "   'zero-shot'),\n",
       "  1),\n",
       " (('attendaffectnet-emotion prediction of movie viewers using multimodal fusion with self-attention',\n",
       "   'prediction'),\n",
       "  1),\n",
       " (('attention distillation for detection transformers: application to real-time video object detection in ultrasound',\n",
       "   'video'),\n",
       "  1),\n",
       " (('autotrans: automating transformer design via reinforced architecture search',\n",
       "   'design'),\n",
       "  1),\n",
       " (('bert meets shapley: extending shap explanations to transformer-based classifiers',\n",
       "   'shap'),\n",
       "  1),\n",
       " (('bert transformer model for detecting arabic gpt2 auto-generated tweets',\n",
       "   'arabic'),\n",
       "  1),\n",
       " (('black-hole optimization applied to the parametric estimation in distribution transformers considering voltage and current measures',\n",
       "   'distribution'),\n",
       "  1),\n",
       " (('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   'signals'),\n",
       "  1),\n",
       " (('bornon: bengali image captioning with transformer-based deep learning approach',\n",
       "   'with'),\n",
       "  1),\n",
       " (('calculation of error of multi-winding voltage transformer under arbitrary secondary load by determinant method',\n",
       "   'multi-winding'),\n",
       "  1),\n",
       " (('can the transformer be used as a drop-in replacement for rnns in text-generating gans?',\n",
       "   'can'),\n",
       "  1),\n",
       " (('combining rnn with transformer for modeling multi-leg trips', 'modeling'),\n",
       "  1),\n",
       " (('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   'converter'),\n",
       "  1),\n",
       " (('considering nested tree structure in sentence extractive summarization with pre-trained transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('constrained transformer network for ecg signal processing and arrhythmia classification',\n",
       "   'processing'),\n",
       "  1),\n",
       " (('context matters: self-attention for sign language recognition', 'sign'),\n",
       "  1),\n",
       " (('contnet: why not use convolution and transformer at the same time?',\n",
       "   'convolution'),\n",
       "  1),\n",
       " (('controllable sentence simplification with a unified text-to-text transfer transformer',\n",
       "   'controllable'),\n",
       "  1),\n",
       " (('convdysat: deep neural representation learning on dynamic graphs via self-attention and convolutional neural networks',\n",
       "   'convdysat:'),\n",
       "  1),\n",
       " (('conversational question answering over knowledge graphs with transformer and graph attention networks',\n",
       "   'graphs'),\n",
       "  1),\n",
       " (('cotr: correspondence transformer for matching across images', 'for'), 1),\n",
       " (('cross-lingual hate speech detection using transformer models',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('cvt: introducing convolutions to vision transformers', 'transformers'), 1),\n",
       " (('dapnet: a double self-attention convolutional network for point cloud semantic labeling',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('dct: dynamic compressive transformer for modeling unbounded sequence',\n",
       "   'dct:'),\n",
       "  1),\n",
       " (('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   'method'),\n",
       "  1),\n",
       " (('design and performance study of a temperature compensated ±1100-kv uhvdc all fiber current transformer',\n",
       "   'current'),\n",
       "  1),\n",
       " (('diagnosing transformers in task-oriented semantic parsing',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('directional graph transformer-based control flow embedding for malware classification',\n",
       "   'for'),\n",
       "  1),\n",
       " ((\"don't shoot butterfly with rifles: multi-channel continuous speech separation with early exit transformer\",\n",
       "   \"don't\"),\n",
       "  1),\n",
       " (('dual self-attention with co-attention networks for visual question answering',\n",
       "   'answering'),\n",
       "  1),\n",
       " (('dual transformer for point cloud analysis', 'transformer'), 1),\n",
       " (('dualformer: local-global stratified transformer for efficient video recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('eeg-convtransformer for single-trial eeg based visual stimuli classification',\n",
       "   'eeg'),\n",
       "  1),\n",
       " (('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   'high'),\n",
       "  1),\n",
       " (('efficient transformer based method for remote sensing image change detection',\n",
       "   'based'),\n",
       "  1),\n",
       " (('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   'and'),\n",
       "  2),\n",
       " (('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   'insensitive'),\n",
       "  1),\n",
       " (('end-to-end spoken language understanding using transformer networks and self-supervised pre-trained features',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('enhancing transformer with horizontal and vertical guiding mechanisms for neural language modeling',\n",
       "   'language'),\n",
       "  1),\n",
       " (('enhancing transformers with gradient boosted decision trees for nli fine-tuning',\n",
       "   'with'),\n",
       "  1),\n",
       " (('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   'the'),\n",
       "  1),\n",
       " (('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   'inter-resonance'),\n",
       "  1),\n",
       " (('evaluation of the transformer architecture for univariate time series forecasting',\n",
       "   'univariate'),\n",
       "  1),\n",
       " (('experimental validation of a method of drying cellulose insulation in distribution transformers using circulating synthetic ester',\n",
       "   'synthetic'),\n",
       "  1),\n",
       " (('exploring a unified sequence-to-sequence transformer for medical product safety monitoring in social media',\n",
       "   'a'),\n",
       "  1),\n",
       " (('exploring multi-task multi-lingual learning of transformer models for hate speech and offensive speech identification in social media',\n",
       "   'learning'),\n",
       "  2),\n",
       " (('facial attribute transformers for precise and robust makeup transfer',\n",
       "   'makeup'),\n",
       "  1),\n",
       " (('fad-bert: improved prediction of fad binding sites using pre-training of deep bidirectional transformers',\n",
       "   'using'),\n",
       "  1),\n",
       " (('fault diagnosis of oil-immersed power transformer based on difference-mutation brain storm optimized catboost model',\n",
       "   'catboost'),\n",
       "  1),\n",
       " (('feature combination meets attention: baidu soccer embeddings and transformer based temporal detection',\n",
       "   'combination'),\n",
       "  1),\n",
       " (('federal learning based covid-19 fake news detection with deep self-attention network',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('fine-tuning vision transformers for the prediction of state variables in ising models',\n",
       "   'of'),\n",
       "  1),\n",
       " (('fnr: a similarity and transformer-based approach to detect multi-modal fake news in social media',\n",
       "   'social'),\n",
       "  1),\n",
       " (('focal attention for long-range interactions in vision transformers',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('geometric transformers for protein interface contact prediction',\n",
       "   'protein'),\n",
       "  1),\n",
       " (('global voxel transformer networks for augmented microscopy', 'microscopy'),\n",
       "  1),\n",
       " (('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   'model'),\n",
       "  1),\n",
       " (('guiding query position and performing similar attention for transformer-based detection heads',\n",
       "   'guiding'),\n",
       "  1),\n",
       " (('hi-behrt: hierarchical transformer-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records',\n",
       "   'accurate'),\n",
       "  1),\n",
       " (('identify hate speech spreaders on twitter using transformer embeddings features and automl classifiers',\n",
       "   'and'),\n",
       "  1),\n",
       " (('improved transformer net for hyperspectral image classification',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('incorporating sentimental trend into gated mechanism based transformer network for story ending generation',\n",
       "   'mechanism'),\n",
       "  1),\n",
       " (('incorporating transformer and lstm to kalman filter with em algorithm for state estimation',\n",
       "   'state'),\n",
       "  1),\n",
       " (('induced local attention for transformer models in speech recognition',\n",
       "   'induced'),\n",
       "  1),\n",
       " (('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   'for'),\n",
       "  1),\n",
       " (('integrate yolov3 with a self-attention mechanism for underwater object detection based on forward-looking sonar images',\n",
       "   'yolov3'),\n",
       "  1),\n",
       " (('introducing attention mechanism for eeg signals: emotion recognition with vision transformers',\n",
       "   'signals:'),\n",
       "  1),\n",
       " (('irene-viz: visualizing energy consumption of transformer models',\n",
       "   'energy'),\n",
       "  1),\n",
       " (('korean grammatical error correction based on transformer with copying mechanisms and grammatical noise implantation methods',\n",
       "   'with'),\n",
       "  1),\n",
       " (('learning attributed graph representation with communicative message passing transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "   'loss'),\n",
       "  1),\n",
       " (('learning dynamic and hierarchical traffic spatiotemporal features with transformer',\n",
       "   'traffic'),\n",
       "  1),\n",
       " (('light field image super-resolution with transformers', 'field'), 1),\n",
       " (('locformer: enabling transformers to perform temporal moment localization on long untrimmed videos with a feature sampling approach',\n",
       "   'moment'),\n",
       "  1),\n",
       " (('long-short transformer: efficient transformers for language and vision',\n",
       "   'vision'),\n",
       "  1),\n",
       " (('looking beyond two frames: end-to-end multi-object tracking using spatial and temporal transformers',\n",
       "   'two'),\n",
       "  1),\n",
       " (('low-dimensional depth local dual-view features embedded transformer for electrocardiogram signal quality assessment',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('match-ignition: plugging pagerank into transformer for long-form text matching',\n",
       "   'text'),\n",
       "  2),\n",
       " (('measuring harmonics with inductive voltage transformers in presence of subharmonics',\n",
       "   'of'),\n",
       "  1),\n",
       " (('multimodal video summarization via time-aware transformers', 'video'), 1),\n",
       " (('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   'on'),\n",
       "  1),\n",
       " (('named entity recognition and relation extraction for covid-19: explainable active learning with word2vec embeddings and transformer-based bert models',\n",
       "   'entity'),\n",
       "  1),\n",
       " (('neural transfer learning with transformers for social science text analysis',\n",
       "   'text'),\n",
       "  1),\n",
       " (('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "   'model'),\n",
       "  1),\n",
       " (('non-invasive self-attention for side information fusion in sequential recommendation',\n",
       "   'sequential'),\n",
       "  1),\n",
       " (('oriented target detection algorithm based on transformer', 'based'), 1),\n",
       " (('pipetransformer: automated elastic pipelining for distributed training of transformers',\n",
       "   'distributed'),\n",
       "  1),\n",
       " (('pose transformers (potr): human motion prediction with non-autoregressive transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   'recurrent'),\n",
       "  1),\n",
       " (('pruning attention heads of transformer models using a* search: a novel approach to compress big nlp architectures',\n",
       "   'nlp'),\n",
       "  1),\n",
       " (('pyramid medical transformer for medical image segmentation',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('pyramid medical transformer for medical image segmentation',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('quantitative analysis and simple monitoring for partial discharge from transformer',\n",
       "   'quantitative'),\n",
       "  1),\n",
       " (('question classification using universal sentence encoder and deep contextualized transformer',\n",
       "   'contextualized'),\n",
       "  1),\n",
       " (('retrieval-augmented transformer-xl for close-domain dialog generation',\n",
       "   'retrieval-augmented'),\n",
       "  1),\n",
       " (('reveal of vision transformers robustness against adversarial attacks',\n",
       "   'robustness'),\n",
       "  1),\n",
       " (('roma at semeval-2021 task 7: a transformer-based approach for detecting and rating humor and offense',\n",
       "   'and'),\n",
       "  2),\n",
       " (('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   'text-to-image'),\n",
       "  1),\n",
       " (('self-attention networks can process bounded hierarchical languages',\n",
       "   'languages'),\n",
       "  1),\n",
       " (('short and long range relation based spatio-temporal transformer for micro-expression recognition',\n",
       "   'and'),\n",
       "  1),\n",
       " (('siamese transformer pyramid networks for real-time uav tracking',\n",
       "   'siamese'),\n",
       "  1),\n",
       " (('simpler is better: few-shot semantic segmentation with classifier weight transformer',\n",
       "   'with'),\n",
       "  1),\n",
       " (('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   'spam'),\n",
       "  1),\n",
       " (('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   'on'),\n",
       "  1),\n",
       " (('soft: softmax-free transformer with linear complexity', 'complexity'), 1),\n",
       " (('starnet: joint action-space prediction with star graphs and implicit global frame self-attention',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('structure-aware parameter-free group query via heterogeneous information network transformer',\n",
       "   'query'),\n",
       "  1),\n",
       " (('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   'tightly-coupled'),\n",
       "  1),\n",
       " (('teach me how to label: labeling functions from natural language with text-to-text transformers',\n",
       "   'how'),\n",
       "  1),\n",
       " (('temporal attention augmented transformer hawkes process', 'temporal'), 1),\n",
       " (('temporal convolutional networks and transformers for classifying the sleep stage in awake or asleep using pulse oximetry signals',\n",
       "   'awake'),\n",
       "  1),\n",
       " (('tfix: learning to fix coding errors with a text-to-text transformer',\n",
       "   'to'),\n",
       "  1),\n",
       " (('the joy of dressing is an art: outfit generation using self-attention bi-lstm',\n",
       "   'the'),\n",
       "  1),\n",
       " (('trankit: a light-weight transformer-based toolkit for multilingual natural language processing',\n",
       "   'a'),\n",
       "  1),\n",
       " (('transattunet: multi-level attention-guided u-net with transformer for medical image segmentation',\n",
       "   'u-net'),\n",
       "  1),\n",
       " (('transfer: learning relation-aware facial expression representations with transformers',\n",
       "   'transfer:'),\n",
       "  1),\n",
       " (('transformer meets convolution: a bilateral awareness net-work for semantic segmentation of very fine resolution ur-ban scene images',\n",
       "   'awareness'),\n",
       "  1),\n",
       " (('transformer-based behavioral representation learning enables transfer learning for mobile sensing in small datasets',\n",
       "   'for'),\n",
       "  1),\n",
       " (('transformer-based deep image matching for generalizable person re-identification',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('transformer-based extractive social media question answering on tweetqa',\n",
       "   'media'),\n",
       "  1),\n",
       " (('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   'for'),\n",
       "  1),\n",
       " (('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   'transformer-style'),\n",
       "  1),\n",
       " (('transformers pipeline for offensiveness detection in mexican spanish social media',\n",
       "   'for'),\n",
       "  1),\n",
       " (('transmask: a compact and fast speech separation model based on transformer',\n",
       "   'compact'),\n",
       "  2),\n",
       " (('transzero++: cross attribute-guided transformer for zero-shot learning',\n",
       "   'attribute-guided'),\n",
       "  1),\n",
       " (('trar: routing the attention spans in transformer for visual question answering',\n",
       "   'in'),\n",
       "  1),\n",
       " (('uformer: a general u-shaped transformer for image restoration', 'for'), 1),\n",
       " (('unified transformer multi-task learning for intent classification with entity recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('unleashing transformers: parallel token prediction with discrete absorbing diffusion for fast high-resolution image generation from vector-quantized codes',\n",
       "   'high-resolution'),\n",
       "  1),\n",
       " (('vidface: a full-transformer solver for video facehallucination with unaligned tiny snapshots',\n",
       "   'unaligned'),\n",
       "  1),\n",
       " (('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   'are'),\n",
       "  1),\n",
       " (('vision transformer for covid-19 cxr diagnosis using chest x-ray feature corpus',\n",
       "   'feature'),\n",
       "  1),\n",
       " (('vision transformers are robust learners', 'vision'), 1),\n",
       " (('vortx: volumetric 3d reconstruction with transformers for voxelwise view selection and fusion',\n",
       "   'vortx:'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   '3d-anas'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'grounding'),\n",
       "  1),\n",
       " (('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   'mechanism'),\n",
       "  1),\n",
       " (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   'fault'),\n",
       "  1),\n",
       " (('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   'transformerless'),\n",
       "  1),\n",
       " (('a novel self-attention deep subspace clustering', 'clustering'), 1),\n",
       " (('a self-attention-based ensemble convolution neural network approach for sleep stage classification with merged spectrogram',\n",
       "   'spectrogram'),\n",
       "  1),\n",
       " (('a simple single-scale vision transformer for object localization and instance segmentation',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a transformer model-based approach to bearing fault diagnosis',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a transformer-based math language model for handwritten math expression recognition',\n",
       "   'handwritten'),\n",
       "  1),\n",
       " (('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   'frequency'),\n",
       "  1),\n",
       " (('accuracy improvement of power transformer faults diagnostic using knn classifier with decision tree principle',\n",
       "   'principle'),\n",
       "  1),\n",
       " (('ai-upv at iberlef-2021 detoxis task: toxicity detection in immigration-related web news comments using transformers and statistical models',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('an emd-based method for the detection of power transformer faults with a hierarchical ensemble classifier',\n",
       "   'hierarchical'),\n",
       "  1),\n",
       " (('an end-to-end speech accent recognition method based on hybrid ctc/attention transformer asr',\n",
       "   'an'),\n",
       "  1),\n",
       " (('an ultrawide output range ${llc}$ resonant converter based on adjustable turns ratio transformer and reconfigurable bridge',\n",
       "   'on'),\n",
       "  1),\n",
       " (('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   'analysis'),\n",
       "  1),\n",
       " (('are transformers a modern version of eliza? observations on french object verb agreement',\n",
       "   'agreement'),\n",
       "  1),\n",
       " (('ast-transformer: encoding abstract syntax trees efficiently for code summarization',\n",
       "   'efficiently'),\n",
       "  1),\n",
       " (('augmented transformer with adaptive graph for temporal action proposal generation',\n",
       "   'adaptive'),\n",
       "  1),\n",
       " (('automatic fake news detection in urdu language using transformers', 'in'),\n",
       "  1),\n",
       " (('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   'medium'),\n",
       "  1),\n",
       " (('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   'deinterleaving'),\n",
       "  1),\n",
       " (('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('boosting salient object detection with transformer-based asymmetric bilateral u-net',\n",
       "   'object'),\n",
       "  1),\n",
       " (('building extraction from remote sensing images with sparse token transformers',\n",
       "   'sparse'),\n",
       "  1),\n",
       " (('cae-transformer: transformer-based model to predict invasiveness of lung adenocarcinoma subsolid nodules from non-thin section 3d ct scans',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('can pre-trained transformers be used in detecting complex sensitive sentences? - a monsanto case study',\n",
       "   'pre-trained'),\n",
       "  1),\n",
       " (('can the transformer learn nested recursion with symbol masking?', 'with'),\n",
       "  1),\n",
       " (('candidate point selection using a self-attention mechanism for generating a smooth volatility surface under the sabr model',\n",
       "   'point'),\n",
       "  1),\n",
       " (('context-aware positional representation for self-attention networks',\n",
       "   'for'),\n",
       "  1),\n",
       " (('cross-view gait recognition using pairwise spatial transformer networks',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('crowd counting method based on the self-attention residual network',\n",
       "   'counting'),\n",
       "  1),\n",
       " (('ct-cad: context-aware transformers for end-to-end chest abnormality detection on x-rays',\n",
       "   'x-rays'),\n",
       "  1),\n",
       " (('data transformer for anomalous trajectory detection', 'transformer'), 1),\n",
       " (('deep features fusion with mutual attention transformer for skin lesion diagnosis',\n",
       "   'features'),\n",
       "  1),\n",
       " (('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('dementia detection using transformer-based deep learning and natural language processing models',\n",
       "   'natural'),\n",
       "  1),\n",
       " (('detecting covid-19 conspiracy theories with transformers and tf-idf',\n",
       "   'with'),\n",
       "  1),\n",
       " (('disturbance rejection and harmonic mitigation for solid state transformer through passivity based control',\n",
       "   'disturbance'),\n",
       "  1),\n",
       " (('dsamt: dual-source aligned multimodal transformers for textcaps',\n",
       "   'multimodal'),\n",
       "  1),\n",
       " (('dual-axial self-attention network for text classification',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('e-dssr: efficient dynamic surgical scene reconstruction with transformer-based stereoscopic depth perception',\n",
       "   'efficient'),\n",
       "  1),\n",
       " (('eeg-transformer: self-attention from transformer architecture for decoding eeg of imagined speech',\n",
       "   'from'),\n",
       "  1),\n",
       " (('efficient dialogue state tracking by masked hierarchical transformer',\n",
       "   'tracking'),\n",
       "  1),\n",
       " (('efficient transformer based method for remote sensing image change detection',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('erratum to: evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   'for'),\n",
       "  1),\n",
       " (('evaluating transformer based semantic segmentation networks for pathological image segmentation',\n",
       "   'for'),\n",
       "  1),\n",
       " (('exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra',\n",
       "   'a'),\n",
       "  1),\n",
       " (('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   'oil-paper'),\n",
       "  1),\n",
       " ((\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   'augmented'),\n",
       "  1),\n",
       " ((\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   'a'),\n",
       "  1),\n",
       " (('from multimodal to unimodal attention in transformers using knowledge distillation',\n",
       "   'multimodal'),\n",
       "  1),\n",
       " (('glit: neural architecture search for global and local image transformer',\n",
       "   'local'),\n",
       "  1),\n",
       " (('global context and geometric priors for effective non-local self-attention',\n",
       "   'priors'),\n",
       "  1),\n",
       " (('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('greedy layer pruning: decreasing inference time of transformer models',\n",
       "   'decreasing'),\n",
       "  1),\n",
       " (('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('gtn-ed: event detection using graph transformer networks', 'using'), 1),\n",
       " (('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   'a'),\n",
       "  1),\n",
       " (('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   'with'),\n",
       "  1),\n",
       " (('improved biomedical word embeddings in the transformer era', 'improved'),\n",
       "  1),\n",
       " (('improving the efficiency of transformers for resource-constrained devices',\n",
       "   'for'),\n",
       "  1),\n",
       " (('instance-based vision transformer for subtyping of papillary renal cell carcinoma in histopathological image',\n",
       "   'instance-based'),\n",
       "  2),\n",
       " (('ipe transformer for depth completion with input-aware positional embeddings',\n",
       "   'ipe'),\n",
       "  1),\n",
       " (('joint intention and trajectory prediction based on transformer', 'and'),\n",
       "  1),\n",
       " (('last query transformer rnn for knowledge tracing', 'rnn'), 1),\n",
       " (('layer-wise pruning of transformer attention heads for efficient language modeling',\n",
       "   'modeling'),\n",
       "  1),\n",
       " (('learning multi-scene absolute pose regression with transformers',\n",
       "   'absolute'),\n",
       "  1),\n",
       " (('lightweight url-based phishing detection using natural language processing transformers for mobile devices',\n",
       "   'devices'),\n",
       "  1),\n",
       " (('lightxml: transformer with dynamic negative sampling for high-performance extreme multi-label text classification',\n",
       "   'lightxml:'),\n",
       "  1),\n",
       " (('load balancing optimization for transformer in distributed environment',\n",
       "   'environment'),\n",
       "  1),\n",
       " (('long-span dependencies in transformer-based summarization systems',\n",
       "   'long-span'),\n",
       "  1),\n",
       " (('malbert: malware detection using bidirectional encoder representations from transformers',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   'augmented'),\n",
       "  1),\n",
       " (('meta-context transformers for domain-specific response generation', 'for'),\n",
       "  1),\n",
       " (('mhformer: multi-hypothesis transformer for 3d human pose estimation',\n",
       "   'for'),\n",
       "  1),\n",
       " (('modeling age of acquisition norms using transformer networks',\n",
       "   'acquisition'),\n",
       "  1),\n",
       " (('monte carlo denoising via auxiliary feature guided self-attention',\n",
       "   'feature'),\n",
       "  1),\n",
       " (('mst: masked self-supervised transformer for visual representation',\n",
       "   'masked'),\n",
       "  1),\n",
       " (('multi-level convolutional transformer with adaptive ranking for semi-supervised crowd counting',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('multi-stage aggregated transformer network for temporal language localization in videos',\n",
       "   'in'),\n",
       "  1),\n",
       " (('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   'nn'),\n",
       "  1),\n",
       " (('noise robust acoustic modeling for single-channel speech recognition based on a stream-wise transformer architecture',\n",
       "   'single-channel'),\n",
       "  1),\n",
       " (('non-autoregressive transformer with unified bidirectional decoder for automatic speech recognition',\n",
       "   'speech'),\n",
       "  1),\n",
       " (('nystroumlmformer: a nystroumlm-based algorithm for approximating self-attention',\n",
       "   'a'),\n",
       "  1),\n",
       " (('optimized active power management in solar pv-fed transformerless grid-connected system for rural electrified microgrid',\n",
       "   'microgrid'),\n",
       "  1),\n",
       " (('pasta: synthesizing object state transformers for dynamic software updates',\n",
       "   'software'),\n",
       "  1),\n",
       " (('paying attention to astronomical transients: photometric classification with the time-series transformer',\n",
       "   'to'),\n",
       "  1),\n",
       " (('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   'vision'),\n",
       "  1),\n",
       " (('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   'convolution'),\n",
       "  1),\n",
       " (('pixeltransformer: sample conditioned signal generation', 'sample'), 1),\n",
       " (('point cloud learning with transformer', 'point'), 1),\n",
       " (('pre-training transformer-based framework on large-scale pediatric claims data for downstream population-specific tasks',\n",
       "   'for'),\n",
       "  1),\n",
       " (('probing word translations in the transformer and trading decoder for encoder layers',\n",
       "   'encoder'),\n",
       "  1),\n",
       " (('programmable integrated microwave photonic filter using a modulation transformer and a double-injection ring resonator',\n",
       "   'microwave'),\n",
       "  1),\n",
       " (('pvtv2: improved baselines with pyramid vision transformer', 'baselines'),\n",
       "  1),\n",
       " (('r2d2: recursive transformer based on differentiable tree for interpretable hierarchical language modeling',\n",
       "   'recursive'),\n",
       "  1),\n",
       " (('ranked list fusion and re-ranking with pre-trained transformers for arqmath lab',\n",
       "   'fusion'),\n",
       "  1),\n",
       " (('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   'principle'),\n",
       "  1),\n",
       " (('research on residual flux density measurement for single-phase transformer core based on energy changes',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   'based'),\n",
       "  1),\n",
       " (('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   'algorithm'),\n",
       "  1),\n",
       " (('risk assessment algorithm for power transformer fleets based on condition and strategic importance',\n",
       "   'for'),\n",
       "  1),\n",
       " (('self-attention channel combinator frontend for end-to-end multichannel far-field speech recognition',\n",
       "   'frontend'),\n",
       "  1),\n",
       " (('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   'with'),\n",
       "  1),\n",
       " (('self-attention-based deep feature fusion for remote sensing scene classification',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   'sequential'),\n",
       "  1),\n",
       " (('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   'multi-frame'),\n",
       "  1),\n",
       " (('simulating reading mistakes for child speech transformer-based phone recognition',\n",
       "   'speech'),\n",
       "  1),\n",
       " (('single-read reconstruction for dna data storage using transformers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('skyformer: remodel self-attention with gaussian kernel and nystr\\\\\"om method',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('sparse self-attention aggregation networks for neural sequence slice interpolation',\n",
       "   'aggregation'),\n",
       "  1),\n",
       " (('sparta: efficient open-domain question answering via sparse transformer matching retrieval',\n",
       "   'sparta:'),\n",
       "  1),\n",
       " (('spatial context-aware self-attention model for multi-organ segmentation',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('spatio-temporal action detector with self-attention', 'self-attention'),\n",
       "  1),\n",
       " (('spectral transform forms scalable transformer', 'transformer'), 1),\n",
       " (('spiking transformer networks: a rate coded approach for processing sequential data',\n",
       "   'data'),\n",
       "  1),\n",
       " (('sting: self-attention based time-series imputation networks using gan',\n",
       "   'sting:'),\n",
       "  1),\n",
       " (('synchronization of low voltage grids fed by smart and conventional transformers',\n",
       "   'low'),\n",
       "  1),\n",
       " (('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   'automated'),\n",
       "  1),\n",
       " (('tabular transformers for modeling multivariate time series',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('tanet: a new paradigm for global face super-resolution via transformer-cnn aggregation network',\n",
       "   'face'),\n",
       "  1),\n",
       " (('the image local autoregressive transformer', 'transformer'), 2),\n",
       " (('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   'of'),\n",
       "  2),\n",
       " (('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   'decoupling'),\n",
       "  1),\n",
       " (('towards a question answering assistant for software development using a transformer-based language model',\n",
       "   'answering'),\n",
       "  1),\n",
       " (('transformer based refinement network for accurate crack detection', 'for'),\n",
       "  1),\n",
       " (('transformer with peak suppression and knowledge guidance for fine-grained image recognition',\n",
       "   'image'),\n",
       "  1),\n",
       " (('transformer-based approach towards music emotion recognition from lyrics',\n",
       "   'recognition'),\n",
       "  2),\n",
       " (('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   'at'),\n",
       "  1),\n",
       " (('transfusion: cross-view fusion with transformer for 3d human pose estimation',\n",
       "   '3d'),\n",
       "  1),\n",
       " (('translating classical chinese poetry into modern chinese with transformer',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('transweather: transformer-based restoration of images degraded by adverse weather conditions',\n",
       "   'weather'),\n",
       "  1),\n",
       " (('trocr: transformer-based optical character recognition with pre-trained models',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   'reverberant'),\n",
       "  1),\n",
       " (('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   'separation'),\n",
       "  1),\n",
       " (('uncertainty-based query strategies for active learning with transformers',\n",
       "   'for'),\n",
       "  1),\n",
       " (('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('video super-resolution based on spatial-temporal transformer',\n",
       "   'super-resolution'),\n",
       "  1),\n",
       " (('vidtr: video transformer without convolutions', 'convolutions'), 2),\n",
       " (('visualsparta: sparse transformer fragment-level matching for large-scale text-to-image search',\n",
       "   'for'),\n",
       "  1),\n",
       " (('vit-p: classification of genitourinary syndrome of menopause from oct images based on vision transformer models',\n",
       "   'from'),\n",
       "  1),\n",
       " (('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'dbc/hz'),\n",
       "  1),\n",
       " (('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   'smart'),\n",
       "  1),\n",
       " (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   'to'),\n",
       "  1),\n",
       " (('a latent transformer for disentangled face editing in images and videos',\n",
       "   'and'),\n",
       "  1),\n",
       " (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   'segmentation'),\n",
       "  1),\n",
       " (('a new gastric histopathology subsize image database (gashissdb) for classification algorithm test: from linear regression to visual transformer',\n",
       "   'linear'),\n",
       "  1),\n",
       " (('a new method of hybrid time window embedding with transformer-based traffic data classification in iot-networked environment',\n",
       "   'traffic'),\n",
       "  1),\n",
       " (('a novel leakage-current-based online insulation monitoring strategy for converter transformers using common-mode and differential-mode harmonics in vsc system',\n",
       "   'converter'),\n",
       "  1),\n",
       " (('a unified transformer-based framework for duplex text normalization', 'a'),\n",
       "  1),\n",
       " (('action segmentation on representations of skeleton sequences using transformer networks',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('adaptive fourier neural operators: efficient token mixers for transformers',\n",
       "   'fourier'),\n",
       "  1),\n",
       " (('all you can embed: natural language based vehicle retrieval with spatio-temporal transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('an efficient approach with application of linear and nonlinear models for evaluation of power transformer health index',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('an empirical study on the usage of transformer models for code completion',\n",
       "   'usage'),\n",
       "  1),\n",
       " (('an image change detection algorithm based on multi-feature self-attention fusion mechanism unet network',\n",
       "   'mechanism'),\n",
       "  1),\n",
       " (('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   'voltage'),\n",
       "  2),\n",
       " (('analytical calculation of magnetic field in fractional-slot windings linear phase-shifting transformer based on exact subdomain model',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('anchor detr: query design for transformer-based detector',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('arabictransformer: efficient large arabic language model with funnel transformer and electra objective',\n",
       "   'large'),\n",
       "  1),\n",
       " (('are convolutional neural networks or transformers more like human vision?',\n",
       "   'human'),\n",
       "  1),\n",
       " (('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   'entity'),\n",
       "  1),\n",
       " (('atiss: autoregressive transformers for indoor scene synthesis', 'scene'),\n",
       "  1),\n",
       " (('ats: adaptive token sampling for efficient vision transformers',\n",
       "   'sampling'),\n",
       "  1),\n",
       " (('autogtco: graph and tensor co-optimize for image recognition with transformers on gpu',\n",
       "   'with'),\n",
       "  1),\n",
       " (('automatic sexism detection with multilingual transformer models ait fhstp@exist2021',\n",
       "   'models'),\n",
       "  1),\n",
       " (('beyond nystroumlmformer - approximation of self-attention by spectral shifting',\n",
       "   'by'),\n",
       "  1),\n",
       " (('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   'mechanism'),\n",
       "  1),\n",
       " (('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   'correction'),\n",
       "  1),\n",
       " (('boosting inertial-based human activity recognition with transformers',\n",
       "   'with'),\n",
       "  1),\n",
       " (('breadth-first search leakage tolerant commutation method for matrix converters in three-phase solid state transformers',\n",
       "   'matrix'),\n",
       "  1),\n",
       " (('classmates enhanced diversity-self-attention network for dropout prediction in moocs',\n",
       "   'classmates'),\n",
       "  1),\n",
       " (('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   'for'),\n",
       "  1),\n",
       " (('code prediction by feeding trees to transformers', 'transformers'), 1),\n",
       " (('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   'of'),\n",
       "  1),\n",
       " (('continuous-time sequential recommendation with temporal graph collaborative transformer',\n",
       "   'graph'),\n",
       "  1),\n",
       " (('convolutions and self-attention: re-interpreting relative positions in pre-trained language models',\n",
       "   'language'),\n",
       "  1),\n",
       " (('crisis domain adaptation using sequence-to-sequence transformers',\n",
       "   'sequence-to-sequence'),\n",
       "  1),\n",
       " (('cross-modal retrieval with dual multi-angle self-attention', 'dual'), 1),\n",
       " (('cvt-assd: convolutional vision-transformer based attentive single shot multibox detector',\n",
       "   'multibox'),\n",
       "  2),\n",
       " (('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   'model'),\n",
       "  1),\n",
       " (('deep self-attention for sequential recommendation (s)', 'sequential'), 1),\n",
       " (('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   'intelligent'),\n",
       "  1),\n",
       " (('design and optimization of 3-kw inductive power transfer charging system with compact asymmetric loosely coupled transformer for special applications',\n",
       "   'inductive'),\n",
       "  1),\n",
       " (('design and research of transformer fault diagnosis method based on data-driven',\n",
       "   'design'),\n",
       "  1),\n",
       " (('df-conformer: integrated architecture of conv-tasnet and conformer using linear complexity self-attention for speech enhancement',\n",
       "   'speech'),\n",
       "  1),\n",
       " (('diverse single image generation with controllable global structure through self-attention',\n",
       "   'controllable'),\n",
       "  1),\n",
       " (('dnabert: pre-trained bidirectional encoder representations from transformers model for dna-language in genome',\n",
       "   'for'),\n",
       "  1),\n",
       " (('do syntax trees help pre-trained transformers extract information?',\n",
       "   'information?'),\n",
       "  1),\n",
       " (('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   'sentinel-2'),\n",
       "  1),\n",
       " (('ds-transunet: dual swin transformer u-net for medical image segmentation',\n",
       "   'u-net'),\n",
       "  1),\n",
       " (('dynamic graph transformer for implicit tag recognition', 'graph'), 1),\n",
       " (('efficient large-scale image retrieval with deep feature orthogonality and hybrid-swin-transformers',\n",
       "   'image'),\n",
       "  1),\n",
       " (('efficientnets and vision transformers for snake species identification using image and location information',\n",
       "   'and'),\n",
       "  2),\n",
       " (('embodied bert: a transformer model for embodied, language-guided visual task completion',\n",
       "   'for'),\n",
       "  1),\n",
       " (('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   'detection'),\n",
       "  1),\n",
       " (('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   'with'),\n",
       "  1),\n",
       " (('encoding-decoding network with pyramid self-attention module for retinal vessel segmentation',\n",
       "   'vessel'),\n",
       "  1),\n",
       " (('end-to-end speaker diarization with transformer', 'transformer'), 1),\n",
       " (('end-to-end speaker-attributed asr with transformer', 'speaker-attributed'),\n",
       "  1),\n",
       " (('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   'location-guided'),\n",
       "  1),\n",
       " (('enhancing transformer for video understanding using gated multi-level attention and temporal adversarial training',\n",
       "   'video'),\n",
       "  1),\n",
       " (('enjoy the salience: towards better transformer-based faithful explanations with word salience',\n",
       "   'better'),\n",
       "  1),\n",
       " (('evaluating pretrained transformer models for entity linking in task-oriented dialog',\n",
       "   'entity'),\n",
       "  1),\n",
       " (('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   'local'),\n",
       "  1),\n",
       " (('exploring transformers in natural language generation: gpt, bert, and xlnet',\n",
       "   'gpt,'),\n",
       "  1),\n",
       " (('fine-grained learning performance prediction via adaptive sparse self-attention networks',\n",
       "   'networks'),\n",
       "  1),\n",
       " (('fine-tuning pre-trained transformer based model for hate speech and offensive content identification in english indo-aryan and code-mixed (english-hindi) languages',\n",
       "   '(english-hindi)'),\n",
       "  1),\n",
       " (('geo-spatial market segmentation and characterization exploiting user generated text through transformers and density-based clustering',\n",
       "   'density-based'),\n",
       "  1),\n",
       " (('groupformer: group activity recognition with clustered spatial-temporal transformer',\n",
       "   'clustered'),\n",
       "  1),\n",
       " (('hierarchical rnns-based transformers maddpg for mixed cooperative-competitive environments',\n",
       "   'environments'),\n",
       "  1),\n",
       " (('image captioning based on an improved transformer with iou position encoding',\n",
       "   'iou'),\n",
       "  1),\n",
       " (('image-text alignment using adaptive cross-attention with transformer encoder for scene graphs',\n",
       "   'for'),\n",
       "  1),\n",
       " (('improving power losses and thermal management in switch mode power converters using multiple transformers',\n",
       "   'thermal'),\n",
       "  1),\n",
       " (('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   'in-memory'),\n",
       "  1),\n",
       " (('integrated crossing pooling of representation learning for vision transformer',\n",
       "   'for'),\n",
       "  1),\n",
       " (('kat: a knowledge augmented transformer for vision-and-language',\n",
       "   'augmented'),\n",
       "  1),\n",
       " (('layouttransformer: scene layout generation with conceptual and spatial diversity',\n",
       "   'layout'),\n",
       "  1),\n",
       " (('learning defense transformers for counterattacking adversarial examples',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('learning defense transformers for counterattacking adversarial examples',\n",
       "   'counterattacking'),\n",
       "  1),\n",
       " (('learning light-weight translation models from deep transformer', 'deep'),\n",
       "  1),\n",
       " (('learning tracking representations via dual-branch fully transformer networks',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('line segment detection using transformers without edges', 'line'), 1),\n",
       " (('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   'with'),\n",
       "  1),\n",
       " (('millimeter-wave sige radiometer front end with transformer-based dicke switch and on-chip calibration noise source',\n",
       "   'switch'),\n",
       "  1),\n",
       " (('miti-detr: object detection based on transformers with mitigatory self-attention convergence',\n",
       "   'with'),\n",
       "  1),\n",
       " (('modulation and control of a dc-ac converter with high-frequency link transformer for grid-connected applications',\n",
       "   'control'),\n",
       "  1),\n",
       " (('motion planning transformers: one model to plan them all', 'one'), 1),\n",
       " (('mt-transunet: mediating multi-task tokens in transformers for skin lesion segmentation and classification',\n",
       "   'multi-task'),\n",
       "  1),\n",
       " (('mt5: a massively multilingual pre-trained text-to-text transformer',\n",
       "   'multilingual'),\n",
       "  1),\n",
       " (('multi-aspect controlled response generation in a multimodal dialogue system using hierarchical transformer network',\n",
       "   'in'),\n",
       "  1),\n",
       " (('multi-modal fusion using fine-tuned self-attention and transfer learning for veracity analysis of web information',\n",
       "   'for'),\n",
       "  1),\n",
       " (('multiview detection with shadow transformer (and view-coherent data augmentation)',\n",
       "   'with'),\n",
       "  1),\n",
       " (('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   'multi-scale'),\n",
       "  1),\n",
       " (('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('nlpbk at vlsp-2020 shared task: compose transformer pretrained models for reliable intelligence identification on social network',\n",
       "   'nlpbk'),\n",
       "  1),\n",
       " (('online detection of inter-turn winding faults in single-phase distribution transformers using smart meter data',\n",
       "   'single-phase'),\n",
       "  1),\n",
       " (('online monitoring technology of power transformer based on vibration analysis',\n",
       "   'vibration'),\n",
       "  1),\n",
       " (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   'impacts'),\n",
       "  1),\n",
       " (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   'on'),\n",
       "  1),\n",
       " (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   'with'),\n",
       "  1),\n",
       " (('optimizing inference performance of transformers on cpus', 'of'), 1),\n",
       " (('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   'for'),\n",
       "  1),\n",
       " (('pg-tfnet: transformer-based fusion network integrating pathological images and genomic data for cancer survival analysis',\n",
       "   'cancer'),\n",
       "  1),\n",
       " (('plate: visually-grounded planning with transformers in procedural tasks',\n",
       "   'tasks'),\n",
       "  1),\n",
       " (('polyu-cbs at the finsim-2 task: combining distributional, string-based and transformers-based features for hypernymy detection in the financial domain',\n",
       "   'financial'),\n",
       "  1),\n",
       " (('power law graph transformer for machine translation and representation learning',\n",
       "   'learning'),\n",
       "  1),\n",
       " (('power transformer fault diagnosis based on dga using a convolutional neural network with noise in measurements',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('pre-trained transformer-based approach for arabic question answering : a comparative study',\n",
       "   'pre-trained'),\n",
       "  1),\n",
       " (('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   'self-attention'),\n",
       "  1),\n",
       " (('pretrained transformers as universal computation engines', 'universal'),\n",
       "  1),\n",
       " (('profiling hate speech spreaders on twitter: transformers and mixed pooling',\n",
       "   'and'),\n",
       "  1),\n",
       " (('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   'for'),\n",
       "  2),\n",
       " (('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   'object'),\n",
       "  2),\n",
       " (('remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit',\n",
       "   'via'),\n",
       "  1),\n",
       " (('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   'supporting'),\n",
       "  1),\n",
       " (('searching effective transformer for seq2seq keyphrase generation',\n",
       "   'keyphrase'),\n",
       "  1),\n",
       " (('searching for efficient transformers for language modeling', 'language'),\n",
       "  1),\n",
       " (('searching for trionet: combining convolution with local and global self-attention',\n",
       "   'convolution'),\n",
       "  1),\n",
       " (('security threat modeling for power transformers in cyber-physical environments',\n",
       "   'power'),\n",
       "  1),\n",
       " (('simple online unmanned aerial vehicle tracking with transformer',\n",
       "   'online'),\n",
       "  1),\n",
       " (('swinbert: end-to-end transformers with sparse attention for video captioning',\n",
       "   'attention'),\n",
       "  1),\n",
       " (('syntax-aware transformers for neural machine translation: the case of text to sign gloss translation',\n",
       "   'neural'),\n",
       "  1),\n",
       " (('tag: transformer attack from gradient', 'attack'), 1),\n",
       " (('tb-net: a tailored, self-attention deep convolutional neural network design for detection of tuberculosis cases from chest x-ray images',\n",
       "   'deep'),\n",
       "  1),\n",
       " (('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   'convolutional'),\n",
       "  1),\n",
       " (('temgnet: deep transformer-based decoding of upperlimb semg for hand gestures recognition',\n",
       "   'for'),\n",
       "  1),\n",
       " (('temporal transformer networks with self-supervision for action recognition',\n",
       "   'self-supervision'),\n",
       "  1),\n",
       " (('token pooling in vision transformers', 'in'), 1),\n",
       " (('transformer based network for open information extraction', 'network'), 1),\n",
       " (('transformer based unsupervised pre-training for acoustic representation learning',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('transformer encoder with multi-modal multi-head attention for continuous affect recognition',\n",
       "   'recognition'),\n",
       "  1),\n",
       " (('transformer fault prognosis using deep recurrent neural network over vibration signals',\n",
       "   'signals'),\n",
       "  1),\n",
       " (('transformer guided geometry model for flow-based unsupervised visual odometry',\n",
       "   'odometry'),\n",
       "  1),\n",
       " (('transformer models for enhancing attngan based text to image generation',\n",
       "   'attngan'),\n",
       "  1),\n",
       " (('transformer models for text coherence assessment', 'assessment'), 1),\n",
       " (('transformer winding faults detection based on time series analysis',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('transformer-based language models for semantic search and mobile applications retrieval',\n",
       "   'mobile'),\n",
       "  1),\n",
       " (('transformer-s2a: robust and efficient speech-to-animation',\n",
       "   'transformer-s2a:'),\n",
       "  1),\n",
       " (('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   'dynamic'),\n",
       "  1),\n",
       " (('transforming fake news: robust generalisable news classification using transformers',\n",
       "   'news'),\n",
       "  1),\n",
       " (('transfuse: fusing transformers and cnns for medical image segmentation',\n",
       "   'transformers'),\n",
       "  1),\n",
       " (('transgan: two pure transformers can make one strong gan, and that can scale up',\n",
       "   'gan,'),\n",
       "  1),\n",
       " (('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   'correlated'),\n",
       "  1),\n",
       " ((\"trees in transformers: a theoretical analysis of the transformer's ability to represent trees\",\n",
       "   \"transformer's\"),\n",
       "  1),\n",
       " (('tt2inet: text to photo-realistic image synthesis with transformer as text encoder',\n",
       "   'as'),\n",
       "  1),\n",
       " (('using multimodal transformers in affective computing', 'multimodal'), 1),\n",
       " (('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   'punctuation'),\n",
       "  1),\n",
       " (('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   'promoting'),\n",
       "  1),\n",
       " (('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   'for'),\n",
       "  1),\n",
       " (('vtnet: visual transformer network for object goal navigation', 'network'),\n",
       "  1),\n",
       " (('ynu-hpcc at semeval-2021 task 10: using a transformer-based source-free domain adaptation model for semantic processing',\n",
       "   'using'),\n",
       "  1),\n",
       " (('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   'modeling'),\n",
       "  1),\n",
       " (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   'transformer-based'),\n",
       "  1),\n",
       " (('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a fine-grained classification method based on self-attention siamese network',\n",
       "   'a'),\n",
       "  1),\n",
       " (('a light transformer for speech-to-intent applications', 'transformer'), 1),\n",
       " (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   'network'),\n",
       "  1),\n",
       " (('a simple approach to image tilt correction with self-attention mobilenet for smartphones',\n",
       "   'for'),\n",
       "  1),\n",
       " (('a unified pruning framework for vision transformers', 'a'), 1),\n",
       " (('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   'cmos'),\n",
       "  1),\n",
       " (('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   'in'),\n",
       "  1),\n",
       " (('adaptive image transformer for one-shot object detection', 'for'), 1),\n",
       " (('aimh at semeval-2021 task 6: multimodal classification using an ensemble of transformer models',\n",
       "   'classification'),\n",
       "  1),\n",
       " (('all tokens matter: token labeling for training better vision transformers',\n",
       "   'matter:'),\n",
       "  1),\n",
       " (('ammu - a survey of transformer-based biomedical pretrained language models',\n",
       "   'models'),\n",
       "  1),\n",
       " (('an empirical study of training self-supervised vision transformers',\n",
       "   'empirical'),\n",
       "  1),\n",
       " (('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   'for'),\n",
       "  1),\n",
       " (('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   'transformer'),\n",
       "  1),\n",
       " (('analysis of a transformer short-circuit fault in near zone', 'a'), 1),\n",
       " (('audio transformers: transformer architectures for large scale audio understanding. adieu convolutions',\n",
       "   'architectures'),\n",
       "  1),\n",
       " (('augmented convolutional neural networks with transformer for wireless interference identification',\n",
       "   'with'),\n",
       "  1),\n",
       " (('automated question generation and question answering from turkish texts using text-to-text transformers',\n",
       "   'using'),\n",
       "  1),\n",
       " (('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   'bidirectional'),\n",
       "  1),\n",
       " (('benchmarking a transformer-free model for ad-hoc retrieval', 'for'), 1),\n",
       " (('bert-based transformers for early detection of mental health illnesses',\n",
       "   'mental'),\n",
       "  1),\n",
       " ((\"bloomnet: a robust transformer based model for bloom's learning outcome classification\",\n",
       "   'based'),\n",
       "  1),\n",
       " (('bootstrapping vits: towards liberating vision transformers from pre-training',\n",
       "   'vision'),\n",
       "  1),\n",
       " (('bossnas: exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search',\n",
       "   'neural'),\n",
       "  2),\n",
       " (('boxer: box-attention for 2d and 3d transformers', 'box-attention'), 1),\n",
       " (('can transformer language models predict psychometric properties?',\n",
       "   'properties?'),\n",
       "  1),\n",
       " (('child face age progression and regression using self-attention multi-scale patch gan',\n",
       "   'using'),\n",
       "  1),\n",
       " (('co-evolution transformer for protein contact prediction', 'transformer'),\n",
       "  1),\n",
       " (('combining a parallel 2d cnn with a self-attention dilated residual network for ctc-based discrete speech emotion recognition',\n",
       "   'emotion'),\n",
       "  1),\n",
       " (('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   'comparison'),\n",
       "  1),\n",
       " (('convolutional neural network (cnn) vs visual transformer (vit) for digital holography',\n",
       "   'network'),\n",
       "  1),\n",
       " (('dance with self-attention: a new look of conditional random fields on anomaly detection in videos',\n",
       "   'videos'),\n",
       "  1),\n",
       " (('diagnosis of inter-turn shorts of loaded transformer under various load currents and power factors; impulse voltage-based frequency response approach',\n",
       "   'under'),\n",
       "  1),\n",
       " (('discodvt: generating long text with discourse-aware discrete variational transformer',\n",
       "   'long'),\n",
       "  1),\n",
       " ...]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(title,features),1] -> [(title, features), TF:(1+1+1...)]  : sum of count of each feature by each title (group by title and feature)\n",
    "reduce=map1.reduceByKey(lambda x,y:x+y)\n",
    "reduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "80b8a5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dual-mode',\n",
       "  ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   1)),\n",
       " ('word',\n",
       "  ('a comparative study of transformers on word sense disambiguation', 2)),\n",
       " ('matching',\n",
       "  ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   1)),\n",
       " ('multiple',\n",
       "  ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   1)),\n",
       " ('integration',\n",
       "  ('a modular multilevel converter (mmc) based solid-state transformer (sst) topology with simplified energy conversion process and magnetic integration',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('a new model of transformer operation state evaluation based on analytic hierarchy process and association rule mining',\n",
       "   1)),\n",
       " ('rare',\n",
       "  ('a note on learning rare events in molecular dynamics using lstm and transformer',\n",
       "   1)),\n",
       " ('system',\n",
       "  ('a pi+passivity-based control of a wind energy conversion system enabled with a solid-state transformer',\n",
       "   1)),\n",
       " ('training',\n",
       "  ('a sample-based training method for distantly supervised relation extraction with pre-trained transformers',\n",
       "   1)),\n",
       " ('natural',\n",
       "  ('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   1)),\n",
       " ('injection',\n",
       "  ('a task-oriented dialogue architecture via transformer neural language models and symbolic injection',\n",
       "   1)),\n",
       " ('era',\n",
       "  ('a transformer based sales prediction of smart container in new retail era',\n",
       "   1)),\n",
       " ('mri',\n",
       "  ('a transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain mri images',\n",
       "   1)),\n",
       " ('verification',\n",
       "  ('adversarial attacks on kinship verification using transformer', 1)),\n",
       " ('more', ('are transformers more robust than cnns?', 1)),\n",
       " ('assessing',\n",
       "  ('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('automated essay scoring using efficient transformer-based language models',\n",
       "   1)),\n",
       " ('trial',\n",
       "  ('automated tabulation of clinical trial results: a joint entity and relation extraction approach with transformer-based language representations',\n",
       "   1)),\n",
       " ('rail',\n",
       "  ('automatic detection of rail components via a deep convolutional transformer network',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "   1)),\n",
       " ('ava:',\n",
       "  ('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   1)),\n",
       " ('speaker', ('avatr: one-shot speaker extraction with transformers', 1)),\n",
       " ('extraction', ('avatr: one-shot speaker extraction with transformers', 1)),\n",
       " ('voltage',\n",
       "  ('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   1)),\n",
       " ('bert',\n",
       "  ('bert based transformers lead the way in extraction of health information from social media',\n",
       "   1)),\n",
       " ('visual',\n",
       "  ('beyond self-attention: external attention using two linear layers for visual tasks',\n",
       "   1)),\n",
       " ('vaccine',\n",
       "  ('bidirectional encoder representations from transformers for the covid-19 vaccine stance classification',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('billion-scale pretraining with vision transformers for multi-task visual representations',\n",
       "   1)),\n",
       " ('controllable',\n",
       "  ('c5t5: controllable generation of organic molecules with transformers', 1)),\n",
       " ('computation-aware',\n",
       "  ('cate: computation-aware neural architecture encoding with transformers',\n",
       "   2)),\n",
       " ('melody',\n",
       "  ('chord conditioned melody generation with transformer based decoders', 1)),\n",
       " ('a',\n",
       "  ('cmsaone@dravidian-codemix-fire2020: a meta embedding and transformer model for code-mixed sentiment analysis on social media text',\n",
       "   1)),\n",
       " ('sexism',\n",
       "  ('combining transformer-based models with traditional machine learning approaches for sexism identification in social networks at exist 2021',\n",
       "   1)),\n",
       " ('accelerated',\n",
       "  ('consistent accelerated inference via confident adaptive transformers', 1)),\n",
       " ('agent',\n",
       "  ('conversational agent embodying a historical figure using transformers',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('deepfake detection scheme based on vision transformer and distillation',\n",
       "   1)),\n",
       " ('deeplpc-mhanet:',\n",
       "  ('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   1)),\n",
       " ('method',\n",
       "  ('defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('detecting dementia from speech and transcripts using transformers', 1)),\n",
       " ('transformer',\n",
       "  ('detection of transformer winding axial displacement by kirchhoff and delay and sum radar imaging algorithms',\n",
       "   1)),\n",
       " ('real-time',\n",
       "  ('developing real-time streaming transformer transducer for speech recognition on large-scale dataset',\n",
       "   1)),\n",
       " ('semantic',\n",
       "  ('diagnosing transformers in task-oriented semantic parsing', 1)),\n",
       " ('discriminative',\n",
       "  ('discriminative and generative transformer-based models for situation entity classification',\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('dispensed transformer network for unsupervised domain adaptation', 1)),\n",
       " ('for',\n",
       "  ('dlsa: dual-learning based on self-attention for rating prediction', 1)),\n",
       " ('classification', ('eeg classification with transformer-based models', 1)),\n",
       " ('strategies',\n",
       "  ('empirical analysis of training strategies of transformer-based japanese chit-chat systems',\n",
       "   1)),\n",
       " ('spotting',\n",
       "  ('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   1)),\n",
       " ('lightweight',\n",
       "  ('evaluating transformers for lightweight action recognition', 1)),\n",
       " ('power',\n",
       "  ('evaluation of static synchronous compensator and rail power conditioner in electrified railway systems using v/v and scott power transformers',\n",
       "   2)),\n",
       " ('at',\n",
       "  ('everything at once - multi-modal fusion transformer for video retrieval',\n",
       "   1)),\n",
       " ('dementia',\n",
       "  ('explainable identification of dementia from transcripts using transformer networks',\n",
       "   1)),\n",
       " ('and', ('exploring and improving mobile level vision transformers', 1)),\n",
       " ('via',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1)),\n",
       " ('spaces',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('exploring the promises of transformer-based lms for the representation of normative claims in the legal domain',\n",
       "   2)),\n",
       " ('and', ('fast and precise certification of transformers', 1)),\n",
       " ('point', ('fast point transformer', 1)),\n",
       " ('a', ('fbert: a neural transformer for identifying offensive content', 2)),\n",
       " ('fine-tuning',\n",
       "  ('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   1)),\n",
       " ('can', ('generative video transformer: can objects be the words?', 1)),\n",
       " ('fast',\n",
       "  ('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   1)),\n",
       " ('image',\n",
       "  ('high-fidelity pluralistic image completion with transformers', 2)),\n",
       " ('ice', ('ice hockey player identification via transformers', 1)),\n",
       " ('via', ('ice hockey player identification via transformers', 1)),\n",
       " ('hope',\n",
       "  ('iiitt@lt-edi-eacl2021-hope speech detection: there is always hope in transformers',\n",
       "   1)),\n",
       " ('and', ('image captioning with transformer and knowledge graph', 1)),\n",
       " ('via',\n",
       "  ('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   1)),\n",
       " ('accelerator',\n",
       "  ('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   1)),\n",
       " ('khmer',\n",
       "  ('incorporating transformer models for sentiment analysis and news classification in khmer',\n",
       "   1)),\n",
       " ('self-supervised',\n",
       "  ('integration of patch features through self-supervised learning and transformer for survival analysis on whole slide images',\n",
       "   1)),\n",
       " ('reacutepondre',\n",
       "  (\"interaction retardeacutee dans l'encodeur du transformer pour reacutepondre efficacement aux questions dans un domaine ouvert\",\n",
       "   1)),\n",
       " ('karl-trans-ner:',\n",
       "  ('karl-trans-ner: knowledge aware representation learning for named entity recognition using transformers',\n",
       "   1)),\n",
       " ('to',\n",
       "  ('language modeling using lmus: 10x better data efficiency or improved scaling compared to transformers',\n",
       "   1)),\n",
       " ('audio',\n",
       "  ('large scale audio understanding without transformers/ convolutions/ berts/ mixers/ attention/ rnns or ...',\n",
       "   1)),\n",
       " ('error',\n",
       "  ('lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing',\n",
       "   1)),\n",
       " ('super-resolution',\n",
       "  ('light field image super-resolution with transformers', 1)),\n",
       " ('vision', ('local-to-global self-attention in vision transformers', 1)),\n",
       " ('removal',\n",
       "  ('m2gan: a multi-stage self-attention network for image rain removal on autonomous vehicles',\n",
       "   1)),\n",
       " ('multi-attribute',\n",
       "  ('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('malbert: using transformers for cybersecurity and malicious software detection',\n",
       "   1)),\n",
       " ('efficiency',\n",
       "  ('mate: multi-view attention for table transformer efficiency', 2)),\n",
       " ('and',\n",
       "  ('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   2)),\n",
       " ('meeting',\n",
       "  ('meetsum: transforming meeting transcript summarization using transformers!',\n",
       "   1)),\n",
       " ('active',\n",
       "  ('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   1)),\n",
       " ('age', ('modeling age of acquisition norms using transformer networks', 1)),\n",
       " ('networks',\n",
       "  ('modular graph transformer networks for multi-label image classification',\n",
       "   1)),\n",
       " ('transformers', ('multi-airport delay prediction with transformers', 1)),\n",
       " ('automatic',\n",
       "  ('multi-head fusion attention for transformer-based end-to-end automatic speech recognition',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('multi-head self-attention via vision transformer for zero-shot learning',\n",
       "   1)),\n",
       " ('four-wire',\n",
       "  ('multi-input transformer-less four-wire microinverter with distributed mppt for pv systems',\n",
       "   1)),\n",
       " ('speech',\n",
       "  (\"multilingual speech translation with unified transformer: huawei noah's ark lab at iwslt 2021\",\n",
       "   1)),\n",
       " ('framework',\n",
       "  ('multimodal graph-based transformer framework for biomedical relation extraction',\n",
       "   1)),\n",
       " ('incremental',\n",
       "  ('multimodal incremental transformer with visual grounding for visual dialogue generation',\n",
       "   1)),\n",
       " ('motion', ('multimodal motion prediction with stacked transformers', 2)),\n",
       " ('using',\n",
       "  ('ncu-nlp at rocling-2021 shared task: using macbert transformers for dimensional sentiment analysis',\n",
       "   1)),\n",
       " ('document',\n",
       "  ('nlp-iis@ut at semeval-2021 task 4: machine reading comprehension using the long document transformer',\n",
       "   1)),\n",
       " ('effectiveness',\n",
       "  ('on the effectiveness of vision transformers for zero-shot face anti-spoofing',\n",
       "   1)),\n",
       " ('sentiment',\n",
       "  ('opinion extraction as a structured sentiment analysis using transformers',\n",
       "   1)),\n",
       " ('reduce',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1)),\n",
       " ('models',\n",
       "  ('optimizing domain specificity of transformer-based language models for extractive summarization of financial news articles in korean',\n",
       "   1)),\n",
       " ('optimizing',\n",
       "  ('optimizing inference performance of transformers on cpus', 1)),\n",
       " ('with',\n",
       "  ('paraphrasing academic text: a study of back-translating anatomy and physiology with transformers',\n",
       "   1)),\n",
       " ('pedestrian',\n",
       "  ('pedestrian trajectory prediction via spatial interaction transformer network',\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('phylotransformer: a discriminative model for mutation prediction based on a multi-head self-attention mechanism',\n",
       "   1)),\n",
       " ('cloud', ('point cloud learning with transformer', 1)),\n",
       " ('based',\n",
       "  ('power grid cascading failure prediction based on transformer', 1)),\n",
       " ('and',\n",
       "  ('power transformer fault diagnosis with intrinsic time-scale decomposition and xgboost classifier',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('pq-transformer: jointly parsing 3d objects and layouts from point clouds',\n",
       "   1)),\n",
       " ('summarizers',\n",
       "  ('predicting discourse trees from transformer-based neural summarizers', 1)),\n",
       " ('normalized',\n",
       "  ('progressively normalized self-attention network for video polyp segmentation',\n",
       "   2)),\n",
       " ('for',\n",
       "  ('ptq4vit: post-training quantization framework for vision transformers',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('pushing the limits of rule reasoning in transformers through natural language satisfiability',\n",
       "   1)),\n",
       " ('autonomous',\n",
       "  ('real-time semantic segmentation with dual encoder and self-attention mechanism for autonomous driving',\n",
       "   1)),\n",
       " ('learning,',\n",
       "  ('reasoning with transformer-based models: deep learning, but shallow reasoning',\n",
       "   1)),\n",
       " ('capac-itance',\n",
       "  ('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('research on on-line detection method of transformer winding deformation based on vfto',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "   1)),\n",
       " ('contextualized',\n",
       "  ('retra: recurrent transformers for learning temporally contextualized knowledge graph embeddings',\n",
       "   1)),\n",
       " ('scale',\n",
       "  ('scale efficiently: insights from pre-training and fine-tuning transformers',\n",
       "   1)),\n",
       " ('consistency',\n",
       "  ('scat: stride consistency with auto-regressive regressor and transformer for hand pose estimation',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('seizure prediction using convolutional neural networks and sequence transformer networks',\n",
       "   1)),\n",
       " ('action',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1)),\n",
       " ('atherosclerotic',\n",
       "  ('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   1)),\n",
       " ('tissue',\n",
       "  ('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   1)),\n",
       " ('between',\n",
       "  ('self-attention between datapoints: going beyond individual input-output pairs in deep learning',\n",
       "   2)),\n",
       " ('super-resolution', ('self-attention for audio super-resolution', 1)),\n",
       " ('networks',\n",
       "  ('self-attention generative adversarial networks for times series vhr multispectral image generation',\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('self-attention presents low-dimensional knowledge graph embeddings for link prediction',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('self-attention-based temporary curiosity in reinforcement learning exploration',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('self-supervised pre-training of swin transformers for 3d medical image analysis',\n",
       "   1)),\n",
       " ('using',\n",
       "  ('semi-supervised sound event detection using self-attention and multiple techniques of consistency training',\n",
       "   1)),\n",
       " ('transcription',\n",
       "  ('sequence-to-sequence piano transcription with transformers', 1)),\n",
       " ('bidirectional',\n",
       "  ('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   1)),\n",
       " ('session-based',\n",
       "  ('session-based recommendation with self-attention networks', 1)),\n",
       " ('fpga',\n",
       "  ('short-circuited turn fault diagnosis in transformers by using vibration signals, statistical time features, and support vector machines on fpga',\n",
       "   1)),\n",
       " ('with', ('single-shot motion completion with transformer', 1)),\n",
       " ('graph',\n",
       "  ('spatial-temporal transformer for dynamic scene graph generation', 2)),\n",
       " ('with', ('speaker-aware speech enhancement with self-attention', 1)),\n",
       " ('spelling', ('spelling correction with denoising transformer', 1)),\n",
       " ('comments',\n",
       "  ('ssn_dibertsity@lt-edi-eacl2021: hope speech detection on multilingual youtube comments via transformer based approach',\n",
       "   1)),\n",
       " ('high-resolution',\n",
       "  ('styleswin: transformer-based gan for high-resolution image generation',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   1)),\n",
       " ('t3-vis:',\n",
       "  ('t3-vis: visual analytic for training and fine-tuning transformers in nlp',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('tackling italian university assessment tests with transformer-based language models',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('text-conditioned transformer for automatic pronunciation error detection',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents',\n",
       "   1)),\n",
       " ('overcurrent',\n",
       "  ('the cause of transformer zero sequence overcurrent protection act', 1)),\n",
       " ('of',\n",
       "  ('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   1)),\n",
       " ('router:',\n",
       "  ('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('the transformer network for the traveling salesman problem', 1)),\n",
       " ('token', ('token pooling in vision transformers', 1)),\n",
       " ('object',\n",
       "  ('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('transmvsnet: global context-aware multi-view stereo network with transformers',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('trar: routing the attention spans in transformer for visual question answering',\n",
       "   1)),\n",
       " ('tuta:',\n",
       "  ('tuta: tree-based transformers for generally structured table pre-training',\n",
       "   1)),\n",
       " ('image', ('u-shape transformer for underwater image enhancement', 1)),\n",
       " ('2021:',\n",
       "  ('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   1)),\n",
       " ('swisstext-2021:',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1)),\n",
       " ('text',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('video relation detection via tracklet based visual transformer', 1)),\n",
       " ('video', ('video super-resolution transformer', 1)),\n",
       " ('transformers', ('vision transformers are robust learners', 1)),\n",
       " ('part-and-sum',\n",
       "  ('visual composite set detection using part-and-sum transformers', 1)),\n",
       " ('of',\n",
       "  ('voltage dependence of the reference system in medium- and high-voltage current transformer calibrations',\n",
       "   1)),\n",
       " ('speed',\n",
       "  ('wind speed forecasting method based on deep learning strategy using long short term memory neural network and transformer model',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   1)),\n",
       " ('attention',\n",
       "  ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   1)),\n",
       " ('distribution',\n",
       "  ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   1)),\n",
       " ('oil-paper',\n",
       "  ('a modified simulation model for predicting the fds of transformer oil-paper insulation under nonuniform aging',\n",
       "   1)),\n",
       " ('contracts',\n",
       "  ('a multi-modal transformer-based code summarization approach for smart contracts',\n",
       "   2)),\n",
       " ('grid',\n",
       "  ('a new state-of-the-art transformers-based load forecaster on the smart grid domain',\n",
       "   1)),\n",
       " ('interleaved',\n",
       "  ('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   1)),\n",
       " ('approach',\n",
       "  ('a transformer based approach for fighting covid-19 fake news', 1)),\n",
       " ('reversing',\n",
       "  ('a transformer-based framework for neutralizing and reversing the political polarity of news articles',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('accelerating framework of transformer by hardware design and model compression co-optimization',\n",
       "   1)),\n",
       " ('direct',\n",
       "  ('an approach to steady-state power transformer modeling considering direct current resistance test measurements',\n",
       "   1)),\n",
       " ('impulse',\n",
       "  ('an automatic data acquisition device for transformer oscillating switching impulse voltage tests',\n",
       "   1)),\n",
       " ('vibration',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1)),\n",
       " ('items',\n",
       "  ('augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer',\n",
       "   1)),\n",
       " ('image', ('beit: bert pre-training of image transformers', 1)),\n",
       " ('detection',\n",
       "  ('benchmarking detection transfer learning with vision transformers', 1)),\n",
       " ('that', ('bert busters: outlier dimensions that disrupt transformers', 1)),\n",
       " ('online',\n",
       "  ('bilingual self-attention network: generating headlines for online linguistic questions',\n",
       "   1)),\n",
       " ('multi-scale',\n",
       "  ('cac-emvt: efficient coronary artery calcium segmentation with multi-scale vision transformers',\n",
       "   1)),\n",
       " ('javanese',\n",
       "  ('canonical segmentation using affix characters as a unit on transformer for javanese language',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('case relation transformer: a crossmodal language generation model for fetching instructions',\n",
       "   2)),\n",
       " ('recursive',\n",
       "  ('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('cdtrans: cross-domain transformer for unsupervised domain adaptation', 1)),\n",
       " ('via', ('certified patch robustness via smoothed vision transformers', 1)),\n",
       " ('answering',\n",
       "  ('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   1)),\n",
       " ('code', ('code prediction by feeding trees to transformers', 1)),\n",
       " ('video',\n",
       "  ('combining efficientnet and vision transformers for video deepfake detection',\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('comformer: code comment generation via transformer and fusion method-based hybrid code representation',\n",
       "   1)),\n",
       " ('machine',\n",
       "  ('comparison of machine learning algorithms for the prediction of mechanical stress in three-phase power transformer winding conductors',\n",
       "   1)),\n",
       " ('component-level',\n",
       "  ('component-level thermo-electromagnetic nonlinear transient finite element modeling of solid-state transformer for dc grid studies',\n",
       "   1)),\n",
       " ('linkable',\n",
       "  ('contextual-semantic-aware linkable knowledge prediction in stack overflow via self-attention',\n",
       "   1)),\n",
       " ('transformer?',\n",
       "  ('convolutional neural network or vision transformer? benchmarking various machine learning models for distracted driver detection',\n",
       "   1)),\n",
       " ('from',\n",
       "  ('covid-net us: a tailored, highly efficient, self-attention deep convolutional neural network design for detection of covid-19 patient cases from point-of-care ultrasound imaging',\n",
       "   1)),\n",
       " ('full', ('cptr: full transformer network for image captioning', 1)),\n",
       " ('transformer',\n",
       "  ('crossvit: cross-attention multi-scale vision transformer for image classification',\n",
       "   2)),\n",
       " ('model-based',\n",
       "  ('cs-um6p at semeval-2021 task 1: a deep learning model-based pre-trained transformer encoder for lexical complexity',\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('deep transformer networks for time series classification: the npp safety case',\n",
       "   1)),\n",
       " ('deep',\n",
       "  ('delving deep into the generalization of vision transformers under distribution shifts',\n",
       "   1)),\n",
       " ('connectivity,',\n",
       "  ('demystifying local vision transformer: sparse connectivity, weight sharing, and dynamic weight',\n",
       "   1)),\n",
       " ('records',\n",
       "  ('detection of abusive records by analyzing the tweets in urdu language exploring transformer based models',\n",
       "   1)),\n",
       " ('via',\n",
       "  ('dg-trans: automatic code summarization via dynamic graph attention-based transformer',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('diformer: directional transformer for neural machine translation', 1)),\n",
       " ('discrete',\n",
       "  ('discrete representations strengthen vision transformer robustness', 1)),\n",
       " ('admission',\n",
       "  ('disease classification on admission and on discharge with residual cnn-transformer',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('dissolved gas analysis for transformer fault based on learning spiking neural p system with belief adaboost',\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('do transformers really perform badly for graph representation?', 1)),\n",
       " ('explicit',\n",
       "  ('do we really need explicit position encodings for vision transformers?',\n",
       "   1)),\n",
       " ('unwarping',\n",
       "  ('doctr: document image transformer for geometric unwarping and illumination correction',\n",
       "   1)),\n",
       " ('multi-temporal',\n",
       "  ('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('dpnet: dual-path network for efficient object detectioj with lightweight self-attention',\n",
       "   1)),\n",
       " ('title',\n",
       "  ('dsgpt: domain-specific generative pre-training of transformers for text generation in e-commerce title and review summarization',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('dynamic transformer for efficient machine translation on embedded devices',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('effective ensembling of transformer based language models for acronyms identification',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('efficient-capsnet: capsule network with self-attention routing', 1)),\n",
       " ('auto-regressive',\n",
       "  ('embedding calibration for music semantic similarity using auto-regressive transformer',\n",
       "   1)),\n",
       " ('robot', ('empathetic robot with transformer-based dialogue agent', 1)),\n",
       " ('machine',\n",
       "  ('english machine translation model based on an improved self-attention technology',\n",
       "   1)),\n",
       " ('structures',\n",
       "  ('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   1)),\n",
       " ('linguistic',\n",
       "  ('enriching the transformer with linguistic factors for low-resource machine translation',\n",
       "   1)),\n",
       " ('principles',\n",
       "  ('erratum: rodrigo-mor et al. principles of charge estimation methods using high-frequency current transformer sensors in partial discharge measurements. sensors 2020, 20, 2520',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('evolving transformer architecture for neural machine translation', 1)),\n",
       " ('for',\n",
       "  ('evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('exploring sequence feature alignment for domain adaptive detection transformers',\n",
       "   1)),\n",
       " ('content',\n",
       "  ('exploring transformer based models to identify hate speech and offensive content in english and indo-aryan languages',\n",
       "   1)),\n",
       " ('moisture',\n",
       "  ('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('feature fusion vision transformer for fine-grained visual categorization',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('few-shot temporal action localization with query adaptive transformer',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('fine-tuning of pre-trained transformers for hate, offensive, and profane content detection in english and marathi',\n",
       "   1)),\n",
       " ('microscopy',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1)),\n",
       " ('llc',\n",
       "  ('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('fu covid-19 ai agent built on attention algorithm using a combination of transformer, albert model, and rasa framework',\n",
       "   1)),\n",
       " ('abnormal',\n",
       "  ('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   1)),\n",
       " ('geometry-contrastive',\n",
       "  ('geometry-contrastive transformer for generalized 3d pose transfer', 1)),\n",
       " ('self-attention',\n",
       "  ('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   1)),\n",
       " ('computation',\n",
       "  ('greenformers: improving computation and memory efficiency in transformer models via low-rank approximation',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('hate speech and offensive content identification based on self-attention',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1)),\n",
       " ('current',\n",
       "  ('high-frequency current transformer design and implementation considerations for wideband partial discharge applications',\n",
       "   1)),\n",
       " ('differential',\n",
       "  ('how geometry affects sensitivity of a differential transformer for contactless characterization of liquids',\n",
       "   1)),\n",
       " ('i2c2w:',\n",
       "  ('i2c2w: image-to-character-to-word transformers for accurate scene text recognition',\n",
       "   1)),\n",
       " ('high',\n",
       "  ('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   1)),\n",
       " ('voltage',\n",
       "  ('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   1)),\n",
       " ('implicit',\n",
       "  ('implicit transformer network for screen content image continuous super-resolution',\n",
       "   1)),\n",
       " ('approximation',\n",
       "  ('improved few-shot learning method for transformer fault diagnosis based on approximation space and belief functions',\n",
       "   1)),\n",
       " ('translation',\n",
       "  ('incorporating relative position information in transformer-based sign language recognition and translation',\n",
       "   1)),\n",
       " ('10', ('indt5: a text-to-text transformer for 10 indigenous languages', 1)),\n",
       " ('a',\n",
       "  ('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('inversemv: composing piano scores with a convolutional video-music transformer',\n",
       "   1)),\n",
       " ('model',\n",
       "  ('keyword transformer: a self-attention model for keyword spotting', 1)),\n",
       " ('via',\n",
       "  ('learning generalizable vision-tactile robotic grasping strategy for deformable objects via transformer',\n",
       "   1)),\n",
       " ('features',\n",
       "  ('learning transformer features for image quality assessment', 1)),\n",
       " ('multi-view',\n",
       "  ('legoformer: transformers for block-by-block multi-view 3d reconstruction',\n",
       "   1)),\n",
       " ('adaptive',\n",
       "  ('make a long image short: adaptive token length for vision transformers',\n",
       "   1)),\n",
       " ('mgsan:',\n",
       "  ('mgsan: a multi-granularity self-attention network for next poi recommendation',\n",
       "   1)),\n",
       " ('u-net', ('mixed transformer u-net for medical image segmentation', 1)),\n",
       " ('gait',\n",
       "  ('mldt: multi-task learning with denoising transformer for gait identity and emotion recognition',\n",
       "   1)),\n",
       " ('frequency',\n",
       "  ('modeling capacitive low-power voltage transformer behavior over temperature and frequency',\n",
       "   1)),\n",
       " ('winding',\n",
       "  ('modelling of high frequency coreless planar transformer with twr hexagonal winding',\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('modified deep transformers for gnss time series prediction', 1)),\n",
       " ('auxiliary',\n",
       "  ('monte carlo denoising via auxiliary feature guided self-attention', 1)),\n",
       " ('video',\n",
       "  ('morphmlp: a self-attention free, mlp-like backbone for image and video',\n",
       "   1)),\n",
       " ('dynamic', ('multi-exit vision transformer for dynamic inference', 1)),\n",
       " ('transformer-based',\n",
       "  ('mutformer: a context-dependent transformer-based model to predict pathogenic missense mutations',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('ncuee-nlp at mediqa 2021: health question summarization using pegasus transformers',\n",
       "   1)),\n",
       " ('model',\n",
       "  ('noniterative design of litz-wire high-frequency gapped-transformer (lw-hfgt) for llc converters based on optimal core-geometry factor model (okgm)',\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('on efficient transformer and image pre-training for low-level vision', 1)),\n",
       " ('transformers:',\n",
       "  ('on the impact of grid harmonics in transformers: a case study', 1)),\n",
       " ('audio-visual',\n",
       "  ('optimizing latency for online video captioningusing audio-visual transformers',\n",
       "   1)),\n",
       " ('completion',\n",
       "  ('pctma-net: point cloud transformer with morphing atlas-based point generation network for dense point cloud completion',\n",
       "   1)),\n",
       " ('cloud',\n",
       "  ('point-bert: pre-training 3d point cloud transformers with masked point modeling',\n",
       "   1)),\n",
       " ('optimization',\n",
       "  ('portfolio optimization with 2d relative-attentional gated transformer',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('power transformer fault diagnosis system based on internet of things', 1)),\n",
       " ('fistula',\n",
       "  ('predicting esophageal fistula risks using a multimodal self-attention network',\n",
       "   1)),\n",
       " ('scientific',\n",
       "  ('predicting real-time scientific experiments using transformer models and reinforcement learning',\n",
       "   1)),\n",
       " ('vision-and-language',\n",
       "  ('probing inter-modality: visual parsing with self-attention for vision-and-language pre-training',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('prostformer: pre-trained progressive space-time self-attention model for traffic flow forecasting',\n",
       "   1)),\n",
       " ('for', ('pyramid medical transformer for medical image segmentation', 1)),\n",
       " ('transformer',\n",
       "  ('radiology report generation for rare diseases via few-shot transformer',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('remote sensing image defogging networks based on dual self-attention boost residual octave convolution',\n",
       "   1)),\n",
       " ('feature',\n",
       "  ('research on hybrid feature selection method of power transformer based on fuzzy information entropy',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('revamping cross-modal recipe retrieval with hierarchical transformers and self-supervised learning',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('risc-vtf: risc-v based extended instruction set for transformer', 1)),\n",
       " ('vs',\n",
       "  (\"rnn's vs transformers: training language models on deficit datasets\", 1)),\n",
       " ('component',\n",
       "  ('running status diagnosis of onboard traction transformers based on kernel principal component analysis and fuzzy clustering',\n",
       "   1)),\n",
       " ('adversarial',\n",
       "  ('sa-capsgan: using capsule networks with embedded self-attention for generative adversarial network',\n",
       "   1)),\n",
       " ('cooperative',\n",
       "  ('sa-matd3: self-attention-based multi-agent continuous control method in cooperative environments',\n",
       "   1)),\n",
       " ('among', ('self-attention agreement among capsules', 1)),\n",
       " ('inside',\n",
       "  ('self-attention attribution: interpreting information interactions inside transformer',\n",
       "   1)),\n",
       " ('anchor',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1)),\n",
       " ('proposal',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1)),\n",
       " ('relations',\n",
       "  ('self-attention graph residual convolutional networks for event detection with dependency relations',\n",
       "   1)),\n",
       " ('building',\n",
       "  ('self-attention in reconstruction bias u-net for semantic segmentation of building rooftops in optical remote sensing images',\n",
       "   1)),\n",
       " ('self-supervised', ('self-supervised video transformer', 1)),\n",
       " ('arcs',\n",
       "  ('sentimentarcs: a novel method for self-supervised sentiment analysis of time series shows sota transformers can struggle finding narrative arcs',\n",
       "   1)),\n",
       " ('lesion',\n",
       "  ('severity quantification and lesion localization of covid-19 on cxr using vision transformer',\n",
       "   1)),\n",
       " ('low-complexity',\n",
       "  ('shallow convolution-augmented transformer with differentiable neural computer for low-complexity classification of variable-length acoustic scene',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('shuffle transformer with feature alignment for video face parsing', 1)),\n",
       " ('image',\n",
       "  ('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('skyformer: remodel self-attention with gaussian kernel and nystroumlm method',\n",
       "   1)),\n",
       " ('learning', ('sparse spatial transformers for few-shot learning', 1)),\n",
       " ('segmentation',\n",
       "  ('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('stformer: a noise-aware efficient spatio-temporal transformer architecture for traffic forecasting',\n",
       "   1)),\n",
       " ('stochastic',\n",
       "  ('stochastic attention head removal: a simple and effective method for improving transformer based asr models',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('streaming transformer for hardware efficient voice trigger detection and false trigger mitigation',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('study on the sound radiation efficiency of a typical distribution transformer',\n",
       "   1)),\n",
       " ('voxel',\n",
       "  ('svt-net: a super light-weight network for large scale place recognition using sparse voxel transformers',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('tag: gradient attack on transformer-based language models', 1)),\n",
       " ('hostility',\n",
       "  ('task adaptive pretraining of transformers for hostility detection', 1)),\n",
       " ('tcl:',\n",
       "  ('tcl: transformer-based dynamic graph modelling via contrastive learning',\n",
       "   1)),\n",
       " ('estimation',\n",
       "  ('test-time personalization with a transformer for human pose estimation',\n",
       "   2)),\n",
       " ('the',\n",
       "  ('the development of precision 500/√3-kv two-stage voltage transformer with high-voltage excitation',\n",
       "   1)),\n",
       " ('too',\n",
       "  ('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('towards more efficient insertion transformer with fractional positional encoding',\n",
       "   1)),\n",
       " ('phase',\n",
       "  ('trans-svnet: accurate phase recognition from surgical videos via hybrid embedding aggregation transformer',\n",
       "   2)),\n",
       " ('couplet',\n",
       "  ('transcouplet: transformer based chinese couplet generation', 1)),\n",
       " ('transformer',\n",
       "  ('transformer based end-to-end mispronunciation detection and diagnosis',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('transformer based neural network for fine-grained classification of vehicle color',\n",
       "   1)),\n",
       " ('scheme',\n",
       "  ('transformer meets dcfam: a novel semantic segmentation scheme for fine-resolution remote sensing images',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer reasoning network for personalized review summarization', 1)),\n",
       " ('image',\n",
       "  ('transformer-based dual relation graph for multi-label image recognition',\n",
       "   1)),\n",
       " ('portuguese',\n",
       "  ('transformers and transfer learning for improving portuguese semantic role labeling',\n",
       "   1)),\n",
       " ('russian',\n",
       "  ('transformers for headline selection for russian news clusters', 1)),\n",
       " ('fake',\n",
       "  ('transforming fake news: robust generalisable news classification using transformers',\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('transhash: transformer-based hamming hashing for efficient image retrieval',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('translation transformers rediscover inherent data domains', 1)),\n",
       " ('transformer',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1)),\n",
       " ('instance',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('tritransnet: rgb-d salient object detection with a triplet transformer embedding network',\n",
       "   1)),\n",
       " ('denoising',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoder for unsupervised sentence embedding learning',\n",
       "   1)),\n",
       " ('tsdae:',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('twitter dataset and evaluation of transformers for turkish sentiment analysis',\n",
       "   1)),\n",
       " ('image',\n",
       "  ('two-hand pose estimation from the non-cropped rgb image with self-attention based network',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   1)),\n",
       " ('overcoming',\n",
       "  ('understanding and overcoming the challenges of efficient transformer quantization',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('video joint modelling based on hierarchical transformer for co-summarization',\n",
       "   1)),\n",
       " ('viesum:',\n",
       "  ('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   1)),\n",
       " ('text',\n",
       "  ('vision and text transformer for predicting answerability on visual question answering',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('vision transformer for plant disease detection: plantvit', 1)),\n",
       " ('disease', ('vision transformer for plant disease detection: plantvit', 1)),\n",
       " ('transformer',\n",
       "  ('vision transformer using low-level chest x-ray feature corpus for covid-19 diagnosis and severity quantification',\n",
       "   1)),\n",
       " ('grounding', ('visual grounding with transformers', 1)),\n",
       " ('vitality:',\n",
       "  ('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   1)),\n",
       " ('use?', ('what context features can transformer language models use?', 1)),\n",
       " ('for',\n",
       "  ('wide-band current transformers for traveling-waves-based protection applications',\n",
       "   1)),\n",
       " ('intrinsic',\n",
       "  ('word representation learning in multimodal pre-trained transformers: an intrinsic evaluation',\n",
       "   1)),\n",
       " ('wrtre:',\n",
       "  ('wrtre: weighted relative position transformer for joint entity and relation extraction',\n",
       "   1)),\n",
       " ('16.8-to-21.6',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1)),\n",
       " ('three-phase',\n",
       "  ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   1)),\n",
       " ('fine-grained',\n",
       "  ('a fine-grained classification method based on self-attention siamese network',\n",
       "   1)),\n",
       " ('communication',\n",
       "  ('a mm-wave gm-assisted transformer-based matching network 2x2 phased-array receiver for 5g communication and radar systems',\n",
       "   1)),\n",
       " ('dc',\n",
       "  ('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "   1)),\n",
       " ('novel',\n",
       "  ('a novel suppression method for grounding transformer against earth current from urban rail transit',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a pre-ln transformer network model with lexical features for fine-grained sentiment classification',\n",
       "   1)),\n",
       " ('dilated',\n",
       "  ('a serial-parallel self-attention network joint with multi-scale dilated convolution',\n",
       "   1)),\n",
       " ('synthesis',\n",
       "  ('a sketch-transformer network for face photo-sketch synthesis', 1)),\n",
       " ('and',\n",
       "  ('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   1)),\n",
       " ('cells',\n",
       "  ('a transformer-less voltage equalizer for energy storage cells based on double-tiered multi-stacked converters',\n",
       "   1)),\n",
       " ('fpga:',\n",
       "  ('accommodating transformer onto fpga: coupling the balanced model compression and fpga-implementation optimization',\n",
       "   1)),\n",
       " ('an',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1)),\n",
       " ('llc',\n",
       "  ('analysis and design of an integrated magnetics planar transformer for high power density llc resonant converter',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1)),\n",
       " ('transformer', ('asformer: transformer for action segmentation', 1)),\n",
       " ('winding',\n",
       "  ('assessment of effect of winding geometry on thermal performance of retrofilled transformers',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('be specific, be clear: bridging machine and human captions by scene-guided transformer',\n",
       "   1)),\n",
       " ('array-based',\n",
       "  ('beamtransformer: microphone array-based overlapping speech detection', 1)),\n",
       " ('mri',\n",
       "  ('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   1)),\n",
       " ('perform',\n",
       "  ('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('combining cnns with transformer for multimodal 3d mri brain tumor segmentation with self-supervised pretraining',\n",
       "   1)),\n",
       " ('solid-state-transformers',\n",
       "  ('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   1)),\n",
       " ('constructing',\n",
       "  ('constructing global coherence representations: identifying interpretability and coherences of transformer attention in time series data',\n",
       "   1)),\n",
       " ('aggregation',\n",
       "  ('contextual similarity aggregation with self-attention for visual re-ranking',\n",
       "   1)),\n",
       " ('matching',\n",
       "  ('cotr: correspondence transformer for matching across images', 1)),\n",
       " ('models',\n",
       "  ('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   1)),\n",
       " ('cyclegan-based',\n",
       "  ('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('cyclic diffeomorphic transformer nets for contour alignment', 1)),\n",
       " ('for',\n",
       "  ('deep transformer networks for time series classification: the npp safety case',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   1)),\n",
       " ('ensemble',\n",
       "  ('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   1)),\n",
       " ('low-loss',\n",
       "  ('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   1)),\n",
       " ('ultra-wideband',\n",
       "  ('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('discriminative and generative transformer-based models for situation entity classification',\n",
       "   1)),\n",
       " ('diverse',\n",
       "  ('diverse image inpainting with bidirectional and autoregressive transformers',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('dropout regularization for self-supervised learning of transformer encoder speech representation',\n",
       "   1)),\n",
       " ('multi-modal',\n",
       "  ('dynamic graph representation learning for video dialog via multi-modal shuffled transformers',\n",
       "   1)),\n",
       " ('properties',\n",
       "  ('effect of iron/titania-based nanomaterials on the dielectric properties of mineral oil, natural and synthetic esters as transformers insulating fluid',\n",
       "   1)),\n",
       " ('voltages',\n",
       "  ('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('efficient video transformers with spatial-temporal token selection', 1)),\n",
       " ('and',\n",
       "  ('electric transformer oil leakage visual detection as service based on lstm and genetic algorithm',\n",
       "   1)),\n",
       " ('properties',\n",
       "  ('emerging properties in self-supervised vision transformers', 1)),\n",
       " ('end-to-end',\n",
       "  ('end-to-end human object interaction detection with hoi transformer', 1)),\n",
       " ('end-to-end', ('end-to-end temporal action detection with transformer', 1)),\n",
       " ('models',\n",
       "  ('enhancing lstm models with self-attention and stateful training', 1)),\n",
       " ('a', ('ernie-doc: a retrospective long-document modeling transformer', 1)),\n",
       " ('reply',\n",
       "  ('exploring low-cost transformer model compression for large-scale commercial reply suggestions',\n",
       "   1)),\n",
       " ('subtypes',\n",
       "  ('gene transformer: transformers for the gene expression-based classification of cancer subtypes',\n",
       "   1)),\n",
       " ('drum',\n",
       "  ('global structure-aware drum transcription based on self-attention mechanisms',\n",
       "   1)),\n",
       " ('attention:',\n",
       "  ('grid partitioned attention: efficient transformerapproximation with inductive bias for high resolution detail generation',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   1)),\n",
       " ('current',\n",
       "  ('h9 and h10 transformer-less solar photovoltaic inverters for leakage current suppression and harmonic current reduction',\n",
       "   2)),\n",
       " ('features',\n",
       "  ('hcit: deepfake video detection using a hybrid model of cnn features and vision transformer',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   1)),\n",
       " ('unsupervised',\n",
       "  ('hierarchical transformer: unsupervised representation learning for skeleton-based human action recognition',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('how many layers and why? an analysis of the model depth in transformers',\n",
       "   1)),\n",
       " ('dialogue',\n",
       "  ('hsan: a hierarchical self-attention network for multi-turn dialogue generation',\n",
       "   1)),\n",
       " ('sms',\n",
       "  ('hybrid cnn-gru framework with integrated pre-trained language transformer for sms phishing detection',\n",
       "   1)),\n",
       " ('image',\n",
       "  ('image captioning in hindi language using transformer networks', 1)),\n",
       " ('transformers',\n",
       "  ('image captioning using multiple transformers for self-attention mechanism',\n",
       "   1)),\n",
       " ('probability',\n",
       "  ('interval fuzzy probability method for power transformer multiple fault diagnosis',\n",
       "   1)),\n",
       " ('lexically-aware',\n",
       "  ('lbert: lexically-aware transformers based bidirectional encoder representation model for learning universal bio-entity relations',\n",
       "   1)),\n",
       " ('hyperspectral',\n",
       "  ('learning a 3d-cnn and transformer prior for hyperspectral image super-resolution',\n",
       "   1)),\n",
       " ('features',\n",
       "  ('legal text classification and summarization using transformers and joint text features',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('lightweight causal transformer with local self-attention for real-time speech enhancement',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('locating inter-turn faults in transformer windings using isometric feature mapping of frequency response traces',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   1)),\n",
       " ('image',\n",
       "  ('mask-guided spectral-wise transformer for efficient hyperspectral image reconstruction',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('measurement of very fast transient overvoltages in current transformers at open air hv substations',\n",
       "   1)),\n",
       " ('cross-transformer',\n",
       "  ('mect: multi-metadata embedding based cross-transformer for chinese named entity recognition',\n",
       "   1)),\n",
       " ('memory-efficient',\n",
       "  ('memory-efficient transformers via top-k attention', 1)),\n",
       " ('trilinear',\n",
       "  ('mirtt: learning multimodal interaction representations from trilinear transformers for visual question answering',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('modeling of cross-circulating currents in a mmc with parallel connected submodules in solid state transformers',\n",
       "   1)),\n",
       " ('biomedical',\n",
       "  ('multi-compound transformer for accurate biomedical image segmentation',\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('multi-modal fusion transformer for end-to-end autonomous driving', 1)),\n",
       " ('for',\n",
       "  ('multi-transformer: a new neural network-based architecture for forecasting sandp volatility',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('multilevel inverter with a new modulation method applied to solid-state transformer in pv applications',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   1)),\n",
       " ('smart',\n",
       "  ('new operation opportunities for the solid-state transformer in smart homes: a comprehensive analysis',\n",
       "   1)),\n",
       " ('nlp',\n",
       "  (\"noisy text data: achilles' heel of popular transformer based nlp models\",\n",
       "   1)),\n",
       " ('removal',\n",
       "  ('non-local self-attention mechanism for real-time context embedding deep shadow removal network',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('noninvasive self-attention for side information fusion in sequential recommendation',\n",
       "   1)),\n",
       " ('multi-agent',\n",
       "  ('offline pre-trained multi-agent decision transformer: one big sequence model tackles all smac tasks',\n",
       "   1)),\n",
       " ('attention-based',\n",
       "  ('on exploring attention-based explanation for transformer models in text classification',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('on improving adversarial transferability of vision transformers', 1)),\n",
       " ('speech',\n",
       "  ('on-device streaming transformer-based end-to-end speech recognition', 1)),\n",
       " ('re-identification',\n",
       "  ('person re-identification with a locally aware transformer', 1)),\n",
       " ('position-informed',\n",
       "  ('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   1)),\n",
       " ('poat-net:',\n",
       "  ('poat-net: parallel offset-attention assisted transformer for 3d object detection for autonomous driving',\n",
       "   1)),\n",
       " ('(roger',\n",
       "  ('power transformer faults diagnosis using undestructive methods (roger and iec) and artificial neural network for dissolved gas analysis applied on the functional transformer in the algerian north-eastern: a comparative study',\n",
       "   1)),\n",
       " ('domain', ('pre-training transformers for domain adaptation', 1)),\n",
       " ('image',\n",
       "  ('rams-trans: recurrent attention multi-scale transformer for fine-grained image recognition',\n",
       "   1)),\n",
       " ('real-time',\n",
       "  ('real-time prediction of ocean observation data based on transformer model',\n",
       "   1)),\n",
       " ('sensing',\n",
       "  ('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   1)),\n",
       " ('representation',\n",
       "  ('representation learning for neural population activity with neural data transformers',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('rethinking skip connection with layer normalization in transformers and resnets',\n",
       "   1)),\n",
       " ('field',\n",
       "  ('robustness evaluation of transformer-based form field extractors via form attacks',\n",
       "   1)),\n",
       " ('rpt:',\n",
       "  ('rpt: relational pre-trained transformer is almost all you need towards democratizing data preparation',\n",
       "   1)),\n",
       " ('sequence-to-sequence',\n",
       "  ('s2s-ft: fine-tuning pretrained transformer encoders for sequence-to-sequence learning',\n",
       "   1)),\n",
       " ('using',\n",
       "  ('security requirements classification into groups using nlp transformers',\n",
       "   1)),\n",
       " ('visual',\n",
       "  ('self-adaptive neural module transformer for visual question answering',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('semi-supervised graph instance transformer for mental health inference',\n",
       "   1)),\n",
       " ('are',\n",
       "  ('soft sensing transformer: hundreds of sensors are worth a single word',\n",
       "   2)),\n",
       " ('network',\n",
       "  ('spatio-temporal self-attention network for video saliency prediction', 1)),\n",
       " ('spectr:',\n",
       "  ('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('speech emotion recognition using recurrent neural networks with directional self-attention',\n",
       "   1)),\n",
       " ('data',\n",
       "  ('stabilizing deep q-learning with convnets and vision transformers under data augmentation',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('study on operation parameter characteristics of induction filter distribution transformer in low-voltage distribution network',\n",
       "   1)),\n",
       " ('trillion',\n",
       "  ('switch transformers: scaling to trillion parameter models with simple and efficient sparsity',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('target-specified sequence labeling with multi-head self-attention for target-oriented opinion words extraction',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('tbn-vit: temporal bilateral network with vision transformer for video scene parsing',\n",
       "   1)),\n",
       " ('@finsim-2:',\n",
       "  ('tcs_witm_2021 @finsim-2: transformer based models for automatic classification of financial terms',\n",
       "   1)),\n",
       " ('template', ('template filling with generative transformers', 1)),\n",
       " ('prediction',\n",
       "  ('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('the layout generation algorithm of graphic design based on transformer-cvae',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   1)),\n",
       " ('accuracy',\n",
       "  ('token labeling: training a 85.4% top-1 accuracy vision transformer with 56m parameters on imagenet',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   1)),\n",
       " ('comprehensive',\n",
       "  ('towards a comprehensive understanding and accurate evaluation of societal biases in pre-trained transformers',\n",
       "   1)),\n",
       " ('image',\n",
       "  ('towards end-to-end image compression and analysis with transformers', 1)),\n",
       " ('prediction',\n",
       "  ('towards explainable end-to-end prostate cancer relapse prediction from hande images combining self-attention multiple instance learning with a recurrent neural network',\n",
       "   1)),\n",
       " ('transformer:',\n",
       "  ('trading with the momentum transformer: an intelligent and interpretable architecture',\n",
       "   1)),\n",
       " ('ais',\n",
       "  ('traisformer-a generative transformer for ais trajectory prediction', 1)),\n",
       " ('trans4trans:',\n",
       "  ('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('transformation of transient overvoltages by inductive voltage transformers',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('transformer ensemble system for detection of offensive content in dravidian languages',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based approaches for personality detection using the mbti model',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('transformer-based korean pretrained language models: a survey on three years of progress',\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('transformer-based long-term viewport prediction in 360° video: scanpath is all you need',\n",
       "   1)),\n",
       " ('eligibility',\n",
       "  ('transformer-based named entity recognition for parsing clinical trial eligibility criteria',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transmorph: transformer for unsupervised medical image registration', 1)),\n",
       " ('flow',\n",
       "  ('trufm: a transformer-guided framework for fine-grained urban flow inference',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   1)),\n",
       " ('block-online',\n",
       "  ('tunet: a block-online bandwidth extension model based on transformers and self-supervised pretraining',\n",
       "   1)),\n",
       " ('to',\n",
       "  ('turkish text classification: from lexicon analysis to bidirectional transformer',\n",
       "   1)),\n",
       " ('vision-language',\n",
       "  ('ufo: a unified transformer for vision-language representation learning',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('umuteam at exist 2021: sexist language identification based on linguistic features and transformers in spanish and english',\n",
       "   1)),\n",
       " ('bot', ('understanding transformers for bot detection in twitter', 1)),\n",
       " ('joint-flexible',\n",
       "  ('unsupervised cross-domain person re-identification with self-attention and joint-flexible optimization',\n",
       "   1)),\n",
       " ('production',\n",
       "  ('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('using recurrent neural network structure with enhanced multi-head self-attention for sentiment analysis',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('video background music generation with controllable music transformer',\n",
       "   1)),\n",
       " ('vision', ('vivit: a video vision transformer', 1)),\n",
       " ('image',\n",
       "  ('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   1)),\n",
       " ('word', ('w-core transformer model for chinese word segmentation', 1)),\n",
       " ('importance',\n",
       "  ('what helps transformers recognize conversational structure? importance of context, punctuation, and labels in dialog act recognition',\n",
       "   2)),\n",
       " ('sensing',\n",
       "  ('wifimod: transformer-based indoor human mobility modeling using passive sensing',\n",
       "   2)),\n",
       " ('pixel',\n",
       "  ('word2pix: word to pixel cross attention transformer in visual grounding',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('x-volution: on the unification of convolution and self-attention', 1)),\n",
       " ('text',\n",
       "  ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   1)),\n",
       " ('new',\n",
       "  ('a new method for transformer fault prediction based on multifeature enhancement and refined long short-term memory',\n",
       "   1)),\n",
       " ('wave', ('a new method of wave parameter retrieve based on transformer', 1)),\n",
       " ('2d',\n",
       "  ('a transformer architecture based on bert and 2d convolutional neural network to identify dna enhancers from sequence information',\n",
       "   1)),\n",
       " ('high',\n",
       "  ('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   1)),\n",
       " ('differential',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1)),\n",
       " ('adversarial',\n",
       "  ('adversarial attacks on kinship verification using transformer', 1)),\n",
       " ('obscure',\n",
       "  ('all bark and no bite: rogue dimensions in transformer language models obscure representational quality',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('an explainable transformer-based deep learning model for the prediction of incident heart failure',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('analyzing covid-19 tweets with transformer-based language models', 1)),\n",
       " ('microorganism',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1)),\n",
       " ('multilayer',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1)),\n",
       " ('zero-shot',\n",
       "  ('ask2transformers: zero-shot domain labelling with pretrained language models',\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('attendaffectnet-emotion prediction of movie viewers using multimodal fusion with self-attention',\n",
       "   1)),\n",
       " ('video',\n",
       "  ('attention distillation for detection transformers: application to real-time video object detection in ultrasound',\n",
       "   1)),\n",
       " ('design',\n",
       "  ('autotrans: automating transformer design via reinforced architecture search',\n",
       "   1)),\n",
       " ('shap',\n",
       "  ('bert meets shapley: extending shap explanations to transformer-based classifiers',\n",
       "   1)),\n",
       " ('arabic',\n",
       "  ('bert transformer model for detecting arabic gpt2 auto-generated tweets',\n",
       "   1)),\n",
       " ('distribution',\n",
       "  ('black-hole optimization applied to the parametric estimation in distribution transformers considering voltage and current measures',\n",
       "   1)),\n",
       " ('signals',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('bornon: bengali image captioning with transformer-based deep learning approach',\n",
       "   1)),\n",
       " ('multi-winding',\n",
       "  ('calculation of error of multi-winding voltage transformer under arbitrary secondary load by determinant method',\n",
       "   1)),\n",
       " ('can',\n",
       "  ('can the transformer be used as a drop-in replacement for rnns in text-generating gans?',\n",
       "   1)),\n",
       " ('modeling',\n",
       "  ('combining rnn with transformer for modeling multi-leg trips', 1)),\n",
       " ('converter',\n",
       "  ('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('considering nested tree structure in sentence extractive summarization with pre-trained transformer',\n",
       "   1)),\n",
       " ('processing',\n",
       "  ('constrained transformer network for ecg signal processing and arrhythmia classification',\n",
       "   1)),\n",
       " ('sign',\n",
       "  ('context matters: self-attention for sign language recognition', 1)),\n",
       " ('convolution',\n",
       "  ('contnet: why not use convolution and transformer at the same time?', 1)),\n",
       " ('controllable',\n",
       "  ('controllable sentence simplification with a unified text-to-text transfer transformer',\n",
       "   1)),\n",
       " ('convdysat:',\n",
       "  ('convdysat: deep neural representation learning on dynamic graphs via self-attention and convolutional neural networks',\n",
       "   1)),\n",
       " ('graphs',\n",
       "  ('conversational question answering over knowledge graphs with transformer and graph attention networks',\n",
       "   1)),\n",
       " ('for', ('cotr: correspondence transformer for matching across images', 1)),\n",
       " ('transformer',\n",
       "  ('cross-lingual hate speech detection using transformer models', 1)),\n",
       " ('transformers', ('cvt: introducing convolutions to vision transformers', 1)),\n",
       " ('convolutional',\n",
       "  ('dapnet: a double self-attention convolutional network for point cloud semantic labeling',\n",
       "   1)),\n",
       " ('dct:',\n",
       "  ('dct: dynamic compressive transformer for modeling unbounded sequence', 1)),\n",
       " ('method',\n",
       "  ('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   1)),\n",
       " ('current',\n",
       "  ('design and performance study of a temperature compensated ±1100-kv uhvdc all fiber current transformer',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('diagnosing transformers in task-oriented semantic parsing', 1)),\n",
       " ('for',\n",
       "  ('directional graph transformer-based control flow embedding for malware classification',\n",
       "   1)),\n",
       " (\"don't\",\n",
       "  (\"don't shoot butterfly with rifles: multi-channel continuous speech separation with early exit transformer\",\n",
       "   1)),\n",
       " ('answering',\n",
       "  ('dual self-attention with co-attention networks for visual question answering',\n",
       "   1)),\n",
       " ('transformer', ('dual transformer for point cloud analysis', 1)),\n",
       " ('recognition',\n",
       "  ('dualformer: local-global stratified transformer for efficient video recognition',\n",
       "   1)),\n",
       " ('eeg',\n",
       "  ('eeg-convtransformer for single-trial eeg based visual stimuli classification',\n",
       "   1)),\n",
       " ('high',\n",
       "  ('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('efficient transformer based method for remote sensing image change detection',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   2)),\n",
       " ('insensitive',\n",
       "  ('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('end-to-end spoken language understanding using transformer networks and self-supervised pre-trained features',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('enhancing transformer with horizontal and vertical guiding mechanisms for neural language modeling',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('enhancing transformers with gradient boosted decision trees for nli fine-tuning',\n",
       "   1)),\n",
       " ('the',\n",
       "  ('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   1)),\n",
       " ('inter-resonance',\n",
       "  ('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   1)),\n",
       " ('univariate',\n",
       "  ('evaluation of the transformer architecture for univariate time series forecasting',\n",
       "   1)),\n",
       " ('synthetic',\n",
       "  ('experimental validation of a method of drying cellulose insulation in distribution transformers using circulating synthetic ester',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('exploring a unified sequence-to-sequence transformer for medical product safety monitoring in social media',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('exploring multi-task multi-lingual learning of transformer models for hate speech and offensive speech identification in social media',\n",
       "   2)),\n",
       " ('makeup',\n",
       "  ('facial attribute transformers for precise and robust makeup transfer', 1)),\n",
       " ('using',\n",
       "  ('fad-bert: improved prediction of fad binding sites using pre-training of deep bidirectional transformers',\n",
       "   1)),\n",
       " ('catboost',\n",
       "  ('fault diagnosis of oil-immersed power transformer based on difference-mutation brain storm optimized catboost model',\n",
       "   1)),\n",
       " ('combination',\n",
       "  ('feature combination meets attention: baidu soccer embeddings and transformer based temporal detection',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('federal learning based covid-19 fake news detection with deep self-attention network',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   1)),\n",
       " ('of',\n",
       "  ('fine-tuning vision transformers for the prediction of state variables in ising models',\n",
       "   1)),\n",
       " ('social',\n",
       "  ('fnr: a similarity and transformer-based approach to detect multi-modal fake news in social media',\n",
       "   1)),\n",
       " ('attention',\n",
       "  ('focal attention for long-range interactions in vision transformers', 1)),\n",
       " ('bidirectional',\n",
       "  ('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   1)),\n",
       " ('protein',\n",
       "  ('geometric transformers for protein interface contact prediction', 1)),\n",
       " ('microscopy',\n",
       "  ('global voxel transformer networks for augmented microscopy', 1)),\n",
       " ('model',\n",
       "  ('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   1)),\n",
       " ('guiding',\n",
       "  ('guiding query position and performing similar attention for transformer-based detection heads',\n",
       "   1)),\n",
       " ('accurate',\n",
       "  ('hi-behrt: hierarchical transformer-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('identify hate speech spreaders on twitter using transformer embeddings features and automl classifiers',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('improved transformer net for hyperspectral image classification', 1)),\n",
       " ('mechanism',\n",
       "  ('incorporating sentimental trend into gated mechanism based transformer network for story ending generation',\n",
       "   1)),\n",
       " ('state',\n",
       "  ('incorporating transformer and lstm to kalman filter with em algorithm for state estimation',\n",
       "   1)),\n",
       " ('induced',\n",
       "  ('induced local attention for transformer models in speech recognition', 1)),\n",
       " ('for',\n",
       "  ('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   1)),\n",
       " ('yolov3',\n",
       "  ('integrate yolov3 with a self-attention mechanism for underwater object detection based on forward-looking sonar images',\n",
       "   1)),\n",
       " ('signals:',\n",
       "  ('introducing attention mechanism for eeg signals: emotion recognition with vision transformers',\n",
       "   1)),\n",
       " ('energy',\n",
       "  ('irene-viz: visualizing energy consumption of transformer models', 1)),\n",
       " ('with',\n",
       "  ('korean grammatical error correction based on transformer with copying mechanisms and grammatical noise implantation methods',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('learning attributed graph representation with communicative message passing transformer',\n",
       "   1)),\n",
       " ('loss',\n",
       "  ('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('learning dynamic and hierarchical traffic spatiotemporal features with transformer',\n",
       "   1)),\n",
       " ('field', ('light field image super-resolution with transformers', 1)),\n",
       " ('moment',\n",
       "  ('locformer: enabling transformers to perform temporal moment localization on long untrimmed videos with a feature sampling approach',\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('long-short transformer: efficient transformers for language and vision',\n",
       "   1)),\n",
       " ('two',\n",
       "  ('looking beyond two frames: end-to-end multi-object tracking using spatial and temporal transformers',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('low-dimensional depth local dual-view features embedded transformer for electrocardiogram signal quality assessment',\n",
       "   1)),\n",
       " ('text',\n",
       "  ('match-ignition: plugging pagerank into transformer for long-form text matching',\n",
       "   2)),\n",
       " ('of',\n",
       "  ('measuring harmonics with inductive voltage transformers in presence of subharmonics',\n",
       "   1)),\n",
       " ('video', ('multimodal video summarization via time-aware transformers', 1)),\n",
       " ('on',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('named entity recognition and relation extraction for covid-19: explainable active learning with word2vec embeddings and transformer-based bert models',\n",
       "   1)),\n",
       " ('text',\n",
       "  ('neural transfer learning with transformers for social science text analysis',\n",
       "   1)),\n",
       " ('model',\n",
       "  ('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "   1)),\n",
       " ('sequential',\n",
       "  ('non-invasive self-attention for side information fusion in sequential recommendation',\n",
       "   1)),\n",
       " ('based', ('oriented target detection algorithm based on transformer', 1)),\n",
       " ('distributed',\n",
       "  ('pipetransformer: automated elastic pipelining for distributed training of transformers',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('pose transformers (potr): human motion prediction with non-autoregressive transformers',\n",
       "   1)),\n",
       " ('recurrent',\n",
       "  ('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   1)),\n",
       " ('nlp',\n",
       "  ('pruning attention heads of transformer models using a* search: a novel approach to compress big nlp architectures',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('pyramid medical transformer for medical image segmentation', 1)),\n",
       " ('segmentation',\n",
       "  ('pyramid medical transformer for medical image segmentation', 1)),\n",
       " ('quantitative',\n",
       "  ('quantitative analysis and simple monitoring for partial discharge from transformer',\n",
       "   1)),\n",
       " ('contextualized',\n",
       "  ('question classification using universal sentence encoder and deep contextualized transformer',\n",
       "   1)),\n",
       " ('retrieval-augmented',\n",
       "  ('retrieval-augmented transformer-xl for close-domain dialog generation',\n",
       "   1)),\n",
       " ('robustness',\n",
       "  ('reveal of vision transformers robustness against adversarial attacks', 1)),\n",
       " ('and',\n",
       "  ('roma at semeval-2021 task 7: a transformer-based approach for detecting and rating humor and offense',\n",
       "   2)),\n",
       " ('text-to-image',\n",
       "  ('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   1)),\n",
       " ('languages',\n",
       "  ('self-attention networks can process bounded hierarchical languages', 1)),\n",
       " ('and',\n",
       "  ('short and long range relation based spatio-temporal transformer for micro-expression recognition',\n",
       "   1)),\n",
       " ('siamese',\n",
       "  ('siamese transformer pyramid networks for real-time uav tracking', 1)),\n",
       " ('with',\n",
       "  ('simpler is better: few-shot semantic segmentation with classifier weight transformer',\n",
       "   1)),\n",
       " ('spam',\n",
       "  ('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   1)),\n",
       " ('complexity', ('soft: softmax-free transformer with linear complexity', 1)),\n",
       " ('self-attention',\n",
       "  ('starnet: joint action-space prediction with star graphs and implicit global frame self-attention',\n",
       "   1)),\n",
       " ('query',\n",
       "  ('structure-aware parameter-free group query via heterogeneous information network transformer',\n",
       "   1)),\n",
       " ('tightly-coupled',\n",
       "  ('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   1)),\n",
       " ('how',\n",
       "  ('teach me how to label: labeling functions from natural language with text-to-text transformers',\n",
       "   1)),\n",
       " ('temporal', ('temporal attention augmented transformer hawkes process', 1)),\n",
       " ('awake',\n",
       "  ('temporal convolutional networks and transformers for classifying the sleep stage in awake or asleep using pulse oximetry signals',\n",
       "   1)),\n",
       " ('to',\n",
       "  ('tfix: learning to fix coding errors with a text-to-text transformer', 1)),\n",
       " ('the',\n",
       "  ('the joy of dressing is an art: outfit generation using self-attention bi-lstm',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('trankit: a light-weight transformer-based toolkit for multilingual natural language processing',\n",
       "   1)),\n",
       " ('u-net',\n",
       "  ('transattunet: multi-level attention-guided u-net with transformer for medical image segmentation',\n",
       "   1)),\n",
       " ('transfer:',\n",
       "  ('transfer: learning relation-aware facial expression representations with transformers',\n",
       "   1)),\n",
       " ('awareness',\n",
       "  ('transformer meets convolution: a bilateral awareness net-work for semantic segmentation of very fine resolution ur-ban scene images',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based behavioral representation learning enables transfer learning for mobile sensing in small datasets',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('transformer-based deep image matching for generalizable person re-identification',\n",
       "   1)),\n",
       " ('media',\n",
       "  ('transformer-based extractive social media question answering on tweetqa',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   1)),\n",
       " ('transformer-style',\n",
       "  ('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformers pipeline for offensiveness detection in mexican spanish social media',\n",
       "   1)),\n",
       " ('compact',\n",
       "  ('transmask: a compact and fast speech separation model based on transformer',\n",
       "   2)),\n",
       " ('attribute-guided',\n",
       "  ('transzero++: cross attribute-guided transformer for zero-shot learning',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('trar: routing the attention spans in transformer for visual question answering',\n",
       "   1)),\n",
       " ('for', ('uformer: a general u-shaped transformer for image restoration', 1)),\n",
       " ('for',\n",
       "  ('unified transformer multi-task learning for intent classification with entity recognition',\n",
       "   1)),\n",
       " ('high-resolution',\n",
       "  ('unleashing transformers: parallel token prediction with discrete absorbing diffusion for fast high-resolution image generation from vector-quantized codes',\n",
       "   1)),\n",
       " ('unaligned',\n",
       "  ('vidface: a full-transformer solver for video facehallucination with unaligned tiny snapshots',\n",
       "   1)),\n",
       " ('are',\n",
       "  ('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   1)),\n",
       " ('feature',\n",
       "  ('vision transformer for covid-19 cxr diagnosis using chest x-ray feature corpus',\n",
       "   1)),\n",
       " ('vision', ('vision transformers are robust learners', 1)),\n",
       " ('vortx:',\n",
       "  ('vortx: volumetric 3d reconstruction with transformers for voxelwise view selection and fusion',\n",
       "   1)),\n",
       " ('3d-anas',\n",
       "  ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   1)),\n",
       " ('grounding',\n",
       "  ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   1)),\n",
       " ('fault',\n",
       "  ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   1)),\n",
       " ('transformerless',\n",
       "  ('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   1)),\n",
       " ('clustering', ('a novel self-attention deep subspace clustering', 1)),\n",
       " ('spectrogram',\n",
       "  ('a self-attention-based ensemble convolution neural network approach for sleep stage classification with merged spectrogram',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a simple single-scale vision transformer for object localization and instance segmentation',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('a transformer model-based approach to bearing fault diagnosis', 1)),\n",
       " ('handwritten',\n",
       "  ('a transformer-based math language model for handwritten math expression recognition',\n",
       "   1)),\n",
       " ('frequency',\n",
       "  ('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   1)),\n",
       " ('principle',\n",
       "  ('accuracy improvement of power transformer faults diagnostic using knn classifier with decision tree principle',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('ai-upv at iberlef-2021 detoxis task: toxicity detection in immigration-related web news comments using transformers and statistical models',\n",
       "   1)),\n",
       " ('hierarchical',\n",
       "  ('an emd-based method for the detection of power transformer faults with a hierarchical ensemble classifier',\n",
       "   1)),\n",
       " ('an',\n",
       "  ('an end-to-end speech accent recognition method based on hybrid ctc/attention transformer asr',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('an ultrawide output range ${llc}$ resonant converter based on adjustable turns ratio transformer and reconfigurable bridge',\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   1)),\n",
       " ('agreement',\n",
       "  ('are transformers a modern version of eliza? observations on french object verb agreement',\n",
       "   1)),\n",
       " ('efficiently',\n",
       "  ('ast-transformer: encoding abstract syntax trees efficiently for code summarization',\n",
       "   1)),\n",
       " ('adaptive',\n",
       "  ('augmented transformer with adaptive graph for temporal action proposal generation',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('automatic fake news detection in urdu language using transformers', 1)),\n",
       " ('medium',\n",
       "  ('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   1)),\n",
       " ('deinterleaving',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1)),\n",
       " ('object',\n",
       "  ('boosting salient object detection with transformer-based asymmetric bilateral u-net',\n",
       "   1)),\n",
       " ('sparse',\n",
       "  ('building extraction from remote sensing images with sparse token transformers',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('cae-transformer: transformer-based model to predict invasiveness of lung adenocarcinoma subsolid nodules from non-thin section 3d ct scans',\n",
       "   1)),\n",
       " ('pre-trained',\n",
       "  ('can pre-trained transformers be used in detecting complex sensitive sentences? - a monsanto case study',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('can the transformer learn nested recursion with symbol masking?', 1)),\n",
       " ('point',\n",
       "  ('candidate point selection using a self-attention mechanism for generating a smooth volatility surface under the sabr model',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('context-aware positional representation for self-attention networks', 1)),\n",
       " ('recognition',\n",
       "  ('cross-view gait recognition using pairwise spatial transformer networks',\n",
       "   1)),\n",
       " ('counting',\n",
       "  ('crowd counting method based on the self-attention residual network', 1)),\n",
       " ('x-rays',\n",
       "  ('ct-cad: context-aware transformers for end-to-end chest abnormality detection on x-rays',\n",
       "   1)),\n",
       " ('transformer', ('data transformer for anomalous trajectory detection', 1)),\n",
       " ('features',\n",
       "  ('deep features fusion with mutual attention transformer for skin lesion diagnosis',\n",
       "   1)),\n",
       " ('convolutional',\n",
       "  ('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   1)),\n",
       " ('natural',\n",
       "  ('dementia detection using transformer-based deep learning and natural language processing models',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('detecting covid-19 conspiracy theories with transformers and tf-idf', 1)),\n",
       " ('disturbance',\n",
       "  ('disturbance rejection and harmonic mitigation for solid state transformer through passivity based control',\n",
       "   1)),\n",
       " ('multimodal',\n",
       "  ('dsamt: dual-source aligned multimodal transformers for textcaps', 1)),\n",
       " ('classification',\n",
       "  ('dual-axial self-attention network for text classification', 1)),\n",
       " ('efficient',\n",
       "  ('e-dssr: efficient dynamic surgical scene reconstruction with transformer-based stereoscopic depth perception',\n",
       "   1)),\n",
       " ('from',\n",
       "  ('eeg-transformer: self-attention from transformer architecture for decoding eeg of imagined speech',\n",
       "   1)),\n",
       " ('tracking',\n",
       "  ('efficient dialogue state tracking by masked hierarchical transformer', 1)),\n",
       " ('detection',\n",
       "  ('efficient transformer based method for remote sensing image change detection',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('erratum to: evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('evaluating transformer based semantic segmentation networks for pathological image segmentation',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra',\n",
       "   1)),\n",
       " ('oil-paper',\n",
       "  ('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   1)),\n",
       " ('augmented',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1)),\n",
       " ('a',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1)),\n",
       " ('multimodal',\n",
       "  ('from multimodal to unimodal attention in transformers using knowledge distillation',\n",
       "   1)),\n",
       " ('local',\n",
       "  ('glit: neural architecture search for global and local image transformer',\n",
       "   1)),\n",
       " ('priors',\n",
       "  ('global context and geometric priors for effective non-local self-attention',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   1)),\n",
       " ('decreasing',\n",
       "  ('greedy layer pruning: decreasing inference time of transformer models',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   1)),\n",
       " ('using', ('gtn-ed: event detection using graph transformer networks', 1)),\n",
       " ('a',\n",
       "  ('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1)),\n",
       " ('improved',\n",
       "  ('improved biomedical word embeddings in the transformer era', 1)),\n",
       " ('for',\n",
       "  ('improving the efficiency of transformers for resource-constrained devices',\n",
       "   1)),\n",
       " ('instance-based',\n",
       "  ('instance-based vision transformer for subtyping of papillary renal cell carcinoma in histopathological image',\n",
       "   2)),\n",
       " ('ipe',\n",
       "  ('ipe transformer for depth completion with input-aware positional embeddings',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('joint intention and trajectory prediction based on transformer', 1)),\n",
       " ('rnn', ('last query transformer rnn for knowledge tracing', 1)),\n",
       " ('modeling',\n",
       "  ('layer-wise pruning of transformer attention heads for efficient language modeling',\n",
       "   1)),\n",
       " ('absolute',\n",
       "  ('learning multi-scene absolute pose regression with transformers', 1)),\n",
       " ('devices',\n",
       "  ('lightweight url-based phishing detection using natural language processing transformers for mobile devices',\n",
       "   1)),\n",
       " ('lightxml:',\n",
       "  ('lightxml: transformer with dynamic negative sampling for high-performance extreme multi-label text classification',\n",
       "   1)),\n",
       " ('environment',\n",
       "  ('load balancing optimization for transformer in distributed environment',\n",
       "   1)),\n",
       " ('long-span',\n",
       "  ('long-span dependencies in transformer-based summarization systems', 1)),\n",
       " ('detection',\n",
       "  ('malbert: malware detection using bidirectional encoder representations from transformers',\n",
       "   1)),\n",
       " ('augmented',\n",
       "  ('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('meta-context transformers for domain-specific response generation', 1)),\n",
       " ('for',\n",
       "  ('mhformer: multi-hypothesis transformer for 3d human pose estimation', 1)),\n",
       " ('acquisition',\n",
       "  ('modeling age of acquisition norms using transformer networks', 1)),\n",
       " ('feature',\n",
       "  ('monte carlo denoising via auxiliary feature guided self-attention', 1)),\n",
       " ('masked',\n",
       "  ('mst: masked self-supervised transformer for visual representation', 1)),\n",
       " ('transformer',\n",
       "  ('multi-level convolutional transformer with adaptive ranking for semi-supervised crowd counting',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('multi-stage aggregated transformer network for temporal language localization in videos',\n",
       "   1)),\n",
       " ('nn',\n",
       "  ('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   1)),\n",
       " ('single-channel',\n",
       "  ('noise robust acoustic modeling for single-channel speech recognition based on a stream-wise transformer architecture',\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('non-autoregressive transformer with unified bidirectional decoder for automatic speech recognition',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('nystroumlmformer: a nystroumlm-based algorithm for approximating self-attention',\n",
       "   1)),\n",
       " ('microgrid',\n",
       "  ('optimized active power management in solar pv-fed transformerless grid-connected system for rural electrified microgrid',\n",
       "   1)),\n",
       " ('software',\n",
       "  ('pasta: synthesizing object state transformers for dynamic software updates',\n",
       "   1)),\n",
       " ('to',\n",
       "  ('paying attention to astronomical transients: photometric classification with the time-series transformer',\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   1)),\n",
       " ('convolution',\n",
       "  ('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   1)),\n",
       " ('sample', ('pixeltransformer: sample conditioned signal generation', 1)),\n",
       " ('point', ('point cloud learning with transformer', 1)),\n",
       " ('for',\n",
       "  ('pre-training transformer-based framework on large-scale pediatric claims data for downstream population-specific tasks',\n",
       "   1)),\n",
       " ('encoder',\n",
       "  ('probing word translations in the transformer and trading decoder for encoder layers',\n",
       "   1)),\n",
       " ('microwave',\n",
       "  ('programmable integrated microwave photonic filter using a modulation transformer and a double-injection ring resonator',\n",
       "   1)),\n",
       " ('baselines',\n",
       "  ('pvtv2: improved baselines with pyramid vision transformer', 1)),\n",
       " ('recursive',\n",
       "  ('r2d2: recursive transformer based on differentiable tree for interpretable hierarchical language modeling',\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('ranked list fusion and re-ranking with pre-trained transformers for arqmath lab',\n",
       "   1)),\n",
       " ('principle',\n",
       "  ('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('research on residual flux density measurement for single-phase transformer core based on energy changes',\n",
       "   1)),\n",
       " ('based',\n",
       "  ('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('risk assessment algorithm for power transformer fleets based on condition and strategic importance',\n",
       "   1)),\n",
       " ('frontend',\n",
       "  ('self-attention channel combinator frontend for end-to-end multichannel far-field speech recognition',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('self-attention-based deep feature fusion for remote sensing scene classification',\n",
       "   1)),\n",
       " ('sequential',\n",
       "  ('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   1)),\n",
       " ('multi-frame',\n",
       "  ('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('simulating reading mistakes for child speech transformer-based phone recognition',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('single-read reconstruction for dna data storage using transformers', 1)),\n",
       " ('self-attention',\n",
       "  ('skyformer: remodel self-attention with gaussian kernel and nystr\\\\\"om method',\n",
       "   1)),\n",
       " ('aggregation',\n",
       "  ('sparse self-attention aggregation networks for neural sequence slice interpolation',\n",
       "   1)),\n",
       " ('sparta:',\n",
       "  ('sparta: efficient open-domain question answering via sparse transformer matching retrieval',\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('spatial context-aware self-attention model for multi-organ segmentation',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('spatio-temporal action detector with self-attention', 1)),\n",
       " ('transformer', ('spectral transform forms scalable transformer', 1)),\n",
       " ('data',\n",
       "  ('spiking transformer networks: a rate coded approach for processing sequential data',\n",
       "   1)),\n",
       " ('sting:',\n",
       "  ('sting: self-attention based time-series imputation networks using gan',\n",
       "   1)),\n",
       " ('low',\n",
       "  ('synchronization of low voltage grids fed by smart and conventional transformers',\n",
       "   1)),\n",
       " ('automated',\n",
       "  ('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('tabular transformers for modeling multivariate time series', 1)),\n",
       " ('face',\n",
       "  ('tanet: a new paradigm for global face super-resolution via transformer-cnn aggregation network',\n",
       "   1)),\n",
       " ('transformer', ('the image local autoregressive transformer', 2)),\n",
       " ('of',\n",
       "  ('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   2)),\n",
       " ('decoupling',\n",
       "  ('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   1)),\n",
       " ('answering',\n",
       "  ('towards a question answering assistant for software development using a transformer-based language model',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer based refinement network for accurate crack detection', 1)),\n",
       " ('image',\n",
       "  ('transformer with peak suppression and knowledge guidance for fine-grained image recognition',\n",
       "   1)),\n",
       " ('recognition',\n",
       "  ('transformer-based approach towards music emotion recognition from lyrics',\n",
       "   2)),\n",
       " ('at',\n",
       "  ('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   1)),\n",
       " ('3d',\n",
       "  ('transfusion: cross-view fusion with transformer for 3d human pose estimation',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('translating classical chinese poetry into modern chinese with transformer',\n",
       "   1)),\n",
       " ('weather',\n",
       "  ('transweather: transformer-based restoration of images degraded by adverse weather conditions',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('trocr: transformer-based optical character recognition with pre-trained models',\n",
       "   1)),\n",
       " ('reverberant',\n",
       "  ('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   1)),\n",
       " ('separation',\n",
       "  ('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('uncertainty-based query strategies for active learning with transformers',\n",
       "   1)),\n",
       " ('bidirectional',\n",
       "  ('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   1)),\n",
       " ('super-resolution',\n",
       "  ('video super-resolution based on spatial-temporal transformer', 1)),\n",
       " ('convolutions', ('vidtr: video transformer without convolutions', 2)),\n",
       " ('for',\n",
       "  ('visualsparta: sparse transformer fragment-level matching for large-scale text-to-image search',\n",
       "   1)),\n",
       " ('from',\n",
       "  ('vit-p: classification of genitourinary syndrome of menopause from oct images based on vision transformer models',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   1)),\n",
       " ('dbc/hz',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   1)),\n",
       " ('smart',\n",
       "  ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   1)),\n",
       " ('to',\n",
       "  ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('a latent transformer for disentangled face editing in images and videos',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   1)),\n",
       " ('linear',\n",
       "  ('a new gastric histopathology subsize image database (gashissdb) for classification algorithm test: from linear regression to visual transformer',\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('a new method of hybrid time window embedding with transformer-based traffic data classification in iot-networked environment',\n",
       "   1)),\n",
       " ('converter',\n",
       "  ('a novel leakage-current-based online insulation monitoring strategy for converter transformers using common-mode and differential-mode harmonics in vsc system',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a unified transformer-based framework for duplex text normalization', 1)),\n",
       " ('networks',\n",
       "  ('action segmentation on representations of skeleton sequences using transformer networks',\n",
       "   1)),\n",
       " ('fourier',\n",
       "  ('adaptive fourier neural operators: efficient token mixers for transformers',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('all you can embed: natural language based vehicle retrieval with spatio-temporal transformers',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('an efficient approach with application of linear and nonlinear models for evaluation of power transformer health index',\n",
       "   1)),\n",
       " ('usage',\n",
       "  ('an empirical study on the usage of transformer models for code completion',\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('an image change detection algorithm based on multi-feature self-attention fusion mechanism unet network',\n",
       "   1)),\n",
       " ('voltage',\n",
       "  ('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   2)),\n",
       " ('transformer',\n",
       "  ('analytical calculation of magnetic field in fractional-slot windings linear phase-shifting transformer based on exact subdomain model',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('anchor detr: query design for transformer-based detector', 1)),\n",
       " ('large',\n",
       "  ('arabictransformer: efficient large arabic language model with funnel transformer and electra objective',\n",
       "   1)),\n",
       " ('human',\n",
       "  ('are convolutional neural networks or transformers more like human vision?',\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   1)),\n",
       " ('scene',\n",
       "  ('atiss: autoregressive transformers for indoor scene synthesis', 1)),\n",
       " ('sampling',\n",
       "  ('ats: adaptive token sampling for efficient vision transformers', 1)),\n",
       " ('with',\n",
       "  ('autogtco: graph and tensor co-optimize for image recognition with transformers on gpu',\n",
       "   1)),\n",
       " ('models',\n",
       "  ('automatic sexism detection with multilingual transformer models ait fhstp@exist2021',\n",
       "   1)),\n",
       " ('by',\n",
       "  ('beyond nystroumlmformer - approximation of self-attention by spectral shifting',\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   1)),\n",
       " ('correction',\n",
       "  ('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('boosting inertial-based human activity recognition with transformers', 1)),\n",
       " ('matrix',\n",
       "  ('breadth-first search leakage tolerant commutation method for matrix converters in three-phase solid state transformers',\n",
       "   1)),\n",
       " ('classmates',\n",
       "  ('classmates enhanced diversity-self-attention network for dropout prediction in moocs',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   1)),\n",
       " ('transformers', ('code prediction by feeding trees to transformers', 1)),\n",
       " ('of',\n",
       "  ('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('continuous-time sequential recommendation with temporal graph collaborative transformer',\n",
       "   1)),\n",
       " ('language',\n",
       "  ('convolutions and self-attention: re-interpreting relative positions in pre-trained language models',\n",
       "   1)),\n",
       " ('sequence-to-sequence',\n",
       "  ('crisis domain adaptation using sequence-to-sequence transformers', 1)),\n",
       " ('dual', ('cross-modal retrieval with dual multi-angle self-attention', 1)),\n",
       " ('multibox',\n",
       "  ('cvt-assd: convolutional vision-transformer based attentive single shot multibox detector',\n",
       "   2)),\n",
       " ('model',\n",
       "  ('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   1)),\n",
       " ('sequential', ('deep self-attention for sequential recommendation (s)', 1)),\n",
       " ('intelligent',\n",
       "  ('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   1)),\n",
       " ('inductive',\n",
       "  ('design and optimization of 3-kw inductive power transfer charging system with compact asymmetric loosely coupled transformer for special applications',\n",
       "   1)),\n",
       " ('design',\n",
       "  ('design and research of transformer fault diagnosis method based on data-driven',\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('df-conformer: integrated architecture of conv-tasnet and conformer using linear complexity self-attention for speech enhancement',\n",
       "   1)),\n",
       " ('controllable',\n",
       "  ('diverse single image generation with controllable global structure through self-attention',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('dnabert: pre-trained bidirectional encoder representations from transformers model for dna-language in genome',\n",
       "   1)),\n",
       " ('information?',\n",
       "  ('do syntax trees help pre-trained transformers extract information?', 1)),\n",
       " ('sentinel-2',\n",
       "  ('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   1)),\n",
       " ('u-net',\n",
       "  ('ds-transunet: dual swin transformer u-net for medical image segmentation',\n",
       "   1)),\n",
       " ('graph', ('dynamic graph transformer for implicit tag recognition', 1)),\n",
       " ('image',\n",
       "  ('efficient large-scale image retrieval with deep feature orthogonality and hybrid-swin-transformers',\n",
       "   1)),\n",
       " ('and',\n",
       "  ('efficientnets and vision transformers for snake species identification using image and location information',\n",
       "   2)),\n",
       " ('for',\n",
       "  ('embodied bert: a transformer model for embodied, language-guided visual task completion',\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   1)),\n",
       " ('vessel',\n",
       "  ('encoding-decoding network with pyramid self-attention module for retinal vessel segmentation',\n",
       "   1)),\n",
       " ('transformer', ('end-to-end speaker diarization with transformer', 1)),\n",
       " ('speaker-attributed',\n",
       "  ('end-to-end speaker-attributed asr with transformer', 1)),\n",
       " ('location-guided',\n",
       "  ('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   1)),\n",
       " ('video',\n",
       "  ('enhancing transformer for video understanding using gated multi-level attention and temporal adversarial training',\n",
       "   1)),\n",
       " ('better',\n",
       "  ('enjoy the salience: towards better transformer-based faithful explanations with word salience',\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('evaluating pretrained transformer models for entity linking in task-oriented dialog',\n",
       "   1)),\n",
       " ('local',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1)),\n",
       " ('gpt,',\n",
       "  ('exploring transformers in natural language generation: gpt, bert, and xlnet',\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('fine-grained learning performance prediction via adaptive sparse self-attention networks',\n",
       "   1)),\n",
       " ('(english-hindi)',\n",
       "  ('fine-tuning pre-trained transformer based model for hate speech and offensive content identification in english indo-aryan and code-mixed (english-hindi) languages',\n",
       "   1)),\n",
       " ('density-based',\n",
       "  ('geo-spatial market segmentation and characterization exploiting user generated text through transformers and density-based clustering',\n",
       "   1)),\n",
       " ('clustered',\n",
       "  ('groupformer: group activity recognition with clustered spatial-temporal transformer',\n",
       "   1)),\n",
       " ('environments',\n",
       "  ('hierarchical rnns-based transformers maddpg for mixed cooperative-competitive environments',\n",
       "   1)),\n",
       " ('iou',\n",
       "  ('image captioning based on an improved transformer with iou position encoding',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('image-text alignment using adaptive cross-attention with transformer encoder for scene graphs',\n",
       "   1)),\n",
       " ('thermal',\n",
       "  ('improving power losses and thermal management in switch mode power converters using multiple transformers',\n",
       "   1)),\n",
       " ('in-memory',\n",
       "  ('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('integrated crossing pooling of representation learning for vision transformer',\n",
       "   1)),\n",
       " ('augmented',\n",
       "  ('kat: a knowledge augmented transformer for vision-and-language', 1)),\n",
       " ('layout',\n",
       "  ('layouttransformer: scene layout generation with conceptual and spatial diversity',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('learning defense transformers for counterattacking adversarial examples',\n",
       "   1)),\n",
       " ('counterattacking',\n",
       "  ('learning defense transformers for counterattacking adversarial examples',\n",
       "   1)),\n",
       " ('deep',\n",
       "  ('learning light-weight translation models from deep transformer', 1)),\n",
       " ('transformer',\n",
       "  ('learning tracking representations via dual-branch fully transformer networks',\n",
       "   1)),\n",
       " ('line', ('line segment detection using transformers without edges', 1)),\n",
       " ('with',\n",
       "  ('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   1)),\n",
       " ('switch',\n",
       "  ('millimeter-wave sige radiometer front end with transformer-based dicke switch and on-chip calibration noise source',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('miti-detr: object detection based on transformers with mitigatory self-attention convergence',\n",
       "   1)),\n",
       " ('control',\n",
       "  ('modulation and control of a dc-ac converter with high-frequency link transformer for grid-connected applications',\n",
       "   1)),\n",
       " ('one', ('motion planning transformers: one model to plan them all', 1)),\n",
       " ('multi-task',\n",
       "  ('mt-transunet: mediating multi-task tokens in transformers for skin lesion segmentation and classification',\n",
       "   1)),\n",
       " ('multilingual',\n",
       "  ('mt5: a massively multilingual pre-trained text-to-text transformer', 1)),\n",
       " ('in',\n",
       "  ('multi-aspect controlled response generation in a multimodal dialogue system using hierarchical transformer network',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('multi-modal fusion using fine-tuned self-attention and transfer learning for veracity analysis of web information',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('multiview detection with shadow transformer (and view-coherent data augmentation)',\n",
       "   1)),\n",
       " ('multi-scale',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1)),\n",
       " ('nlpbk',\n",
       "  ('nlpbk at vlsp-2020 shared task: compose transformer pretrained models for reliable intelligence identification on social network',\n",
       "   1)),\n",
       " ('single-phase',\n",
       "  ('online detection of inter-turn winding faults in single-phase distribution transformers using smart meter data',\n",
       "   1)),\n",
       " ('vibration',\n",
       "  ('online monitoring technology of power transformer based on vibration analysis',\n",
       "   1)),\n",
       " ('impacts',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1)),\n",
       " ('on',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1)),\n",
       " ('of', ('optimizing inference performance of transformers on cpus', 1)),\n",
       " ('for',\n",
       "  ('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   1)),\n",
       " ('cancer',\n",
       "  ('pg-tfnet: transformer-based fusion network integrating pathological images and genomic data for cancer survival analysis',\n",
       "   1)),\n",
       " ('tasks',\n",
       "  ('plate: visually-grounded planning with transformers in procedural tasks',\n",
       "   1)),\n",
       " ('financial',\n",
       "  ('polyu-cbs at the finsim-2 task: combining distributional, string-based and transformers-based features for hypernymy detection in the financial domain',\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('power law graph transformer for machine translation and representation learning',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('power transformer fault diagnosis based on dga using a convolutional neural network with noise in measurements',\n",
       "   1)),\n",
       " ('pre-trained',\n",
       "  ('pre-trained transformer-based approach for arabic question answering : a comparative study',\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   1)),\n",
       " ('universal',\n",
       "  ('pretrained transformers as universal computation engines', 1)),\n",
       " ('and',\n",
       "  ('profiling hate speech spreaders on twitter: transformers and mixed pooling',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   2)),\n",
       " ('object',\n",
       "  ('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   2)),\n",
       " ('via',\n",
       "  ('remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit',\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   1)),\n",
       " ('supporting',\n",
       "  ('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   1)),\n",
       " ('keyphrase',\n",
       "  ('searching effective transformer for seq2seq keyphrase generation', 1)),\n",
       " ('language',\n",
       "  ('searching for efficient transformers for language modeling', 1)),\n",
       " ('convolution',\n",
       "  ('searching for trionet: combining convolution with local and global self-attention',\n",
       "   1)),\n",
       " ('power',\n",
       "  ('security threat modeling for power transformers in cyber-physical environments',\n",
       "   1)),\n",
       " ('online',\n",
       "  ('simple online unmanned aerial vehicle tracking with transformer', 1)),\n",
       " ('attention',\n",
       "  ('swinbert: end-to-end transformers with sparse attention for video captioning',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('syntax-aware transformers for neural machine translation: the case of text to sign gloss translation',\n",
       "   1)),\n",
       " ('attack', ('tag: transformer attack from gradient', 1)),\n",
       " ('deep',\n",
       "  ('tb-net: a tailored, self-attention deep convolutional neural network design for detection of tuberculosis cases from chest x-ray images',\n",
       "   1)),\n",
       " ('convolutional',\n",
       "  ('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('temgnet: deep transformer-based decoding of upperlimb semg for hand gestures recognition',\n",
       "   1)),\n",
       " ('self-supervision',\n",
       "  ('temporal transformer networks with self-supervision for action recognition',\n",
       "   1)),\n",
       " ('in', ('token pooling in vision transformers', 1)),\n",
       " ('network', ('transformer based network for open information extraction', 1)),\n",
       " ('transformer',\n",
       "  ('transformer based unsupervised pre-training for acoustic representation learning',\n",
       "   1)),\n",
       " ('recognition',\n",
       "  ('transformer encoder with multi-modal multi-head attention for continuous affect recognition',\n",
       "   1)),\n",
       " ('signals',\n",
       "  ('transformer fault prognosis using deep recurrent neural network over vibration signals',\n",
       "   1)),\n",
       " ('odometry',\n",
       "  ('transformer guided geometry model for flow-based unsupervised visual odometry',\n",
       "   1)),\n",
       " ('attngan',\n",
       "  ('transformer models for enhancing attngan based text to image generation',\n",
       "   1)),\n",
       " ('assessment', ('transformer models for text coherence assessment', 1)),\n",
       " ('transformer',\n",
       "  ('transformer winding faults detection based on time series analysis', 1)),\n",
       " ('mobile',\n",
       "  ('transformer-based language models for semantic search and mobile applications retrieval',\n",
       "   1)),\n",
       " ('transformer-s2a:',\n",
       "  ('transformer-s2a: robust and efficient speech-to-animation', 1)),\n",
       " ('dynamic',\n",
       "  ('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   1)),\n",
       " ('news',\n",
       "  ('transforming fake news: robust generalisable news classification using transformers',\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('transfuse: fusing transformers and cnns for medical image segmentation',\n",
       "   1)),\n",
       " ('gan,',\n",
       "  ('transgan: two pure transformers can make one strong gan, and that can scale up',\n",
       "   1)),\n",
       " ('correlated',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1)),\n",
       " (\"transformer's\",\n",
       "  (\"trees in transformers: a theoretical analysis of the transformer's ability to represent trees\",\n",
       "   1)),\n",
       " ('as',\n",
       "  ('tt2inet: text to photo-realistic image synthesis with transformer as text encoder',\n",
       "   1)),\n",
       " ('multimodal', ('using multimodal transformers in affective computing', 1)),\n",
       " ('punctuation',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1)),\n",
       " ('promoting',\n",
       "  ('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('vtnet: visual transformer network for object goal navigation', 1)),\n",
       " ('using',\n",
       "  ('ynu-hpcc at semeval-2021 task 10: using a transformer-based source-free domain adaptation model for semantic processing',\n",
       "   1)),\n",
       " ('modeling',\n",
       "  ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a fine-grained classification method based on self-attention siamese network',\n",
       "   1)),\n",
       " ('transformer', ('a light transformer for speech-to-intent applications', 1)),\n",
       " ('network',\n",
       "  ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a simple approach to image tilt correction with self-attention mobilenet for smartphones',\n",
       "   1)),\n",
       " ('a', ('a unified pruning framework for vision transformers', 1)),\n",
       " ('cmos',\n",
       "  ('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   1)),\n",
       " ('in',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1)),\n",
       " ('for', ('adaptive image transformer for one-shot object detection', 1)),\n",
       " ('classification',\n",
       "  ('aimh at semeval-2021 task 6: multimodal classification using an ensemble of transformer models',\n",
       "   1)),\n",
       " ('matter:',\n",
       "  ('all tokens matter: token labeling for training better vision transformers',\n",
       "   1)),\n",
       " ('models',\n",
       "  ('ammu - a survey of transformer-based biomedical pretrained language models',\n",
       "   1)),\n",
       " ('empirical',\n",
       "  ('an empirical study of training self-supervised vision transformers', 1)),\n",
       " ('transformer',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1)),\n",
       " ('for',\n",
       "  ('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   1)),\n",
       " ('a', ('analysis of a transformer short-circuit fault in near zone', 1)),\n",
       " ('architectures',\n",
       "  ('audio transformers: transformer architectures for large scale audio understanding. adieu convolutions',\n",
       "   1)),\n",
       " ('with',\n",
       "  ('augmented convolutional neural networks with transformer for wireless interference identification',\n",
       "   1)),\n",
       " ('using',\n",
       "  ('automated question generation and question answering from turkish texts using text-to-text transformers',\n",
       "   1)),\n",
       " ('bidirectional',\n",
       "  ('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   1)),\n",
       " ('for', ('benchmarking a transformer-free model for ad-hoc retrieval', 1)),\n",
       " ('mental',\n",
       "  ('bert-based transformers for early detection of mental health illnesses',\n",
       "   1)),\n",
       " ('based',\n",
       "  (\"bloomnet: a robust transformer based model for bloom's learning outcome classification\",\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('bootstrapping vits: towards liberating vision transformers from pre-training',\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('bossnas: exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search',\n",
       "   2)),\n",
       " ('box-attention', ('boxer: box-attention for 2d and 3d transformers', 1)),\n",
       " ('properties?',\n",
       "  ('can transformer language models predict psychometric properties?', 1)),\n",
       " ('using',\n",
       "  ('child face age progression and regression using self-attention multi-scale patch gan',\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('co-evolution transformer for protein contact prediction', 1)),\n",
       " ('emotion',\n",
       "  ('combining a parallel 2d cnn with a self-attention dilated residual network for ctc-based discrete speech emotion recognition',\n",
       "   1)),\n",
       " ('comparison',\n",
       "  ('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   1)),\n",
       " ('network',\n",
       "  ('convolutional neural network (cnn) vs visual transformer (vit) for digital holography',\n",
       "   1)),\n",
       " ('videos',\n",
       "  ('dance with self-attention: a new look of conditional random fields on anomaly detection in videos',\n",
       "   1)),\n",
       " ('under',\n",
       "  ('diagnosis of inter-turn shorts of loaded transformer under various load currents and power factors; impulse voltage-based frequency response approach',\n",
       "   1)),\n",
       " ('long',\n",
       "  ('discodvt: generating long text with discourse-aware discrete variational transformer',\n",
       "   1)),\n",
       " ...]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(title, features), TF] -> [features, (title, TF)] \n",
    "tf=reduce.map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
    "tf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9b5af11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dual-mode',\n",
       "  ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "   1,\n",
       "   1)),\n",
       " ('word',\n",
       "  ('a comparative study of transformers on word sense disambiguation', 2, 1)),\n",
       " ('matching',\n",
       "  ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('multiple',\n",
       "  ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('integration',\n",
       "  ('a modular multilevel converter (mmc) based solid-state transformer (sst) topology with simplified energy conversion process and magnetic integration',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('a new model of transformer operation state evaluation based on analytic hierarchy process and association rule mining',\n",
       "   1,\n",
       "   1)),\n",
       " ('rare',\n",
       "  ('a note on learning rare events in molecular dynamics using lstm and transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('system',\n",
       "  ('a pi+passivity-based control of a wind energy conversion system enabled with a solid-state transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('training',\n",
       "  ('a sample-based training method for distantly supervised relation extraction with pre-trained transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('natural',\n",
       "  ('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   1,\n",
       "   1)),\n",
       " ('injection',\n",
       "  ('a task-oriented dialogue architecture via transformer neural language models and symbolic injection',\n",
       "   1,\n",
       "   1)),\n",
       " ('era',\n",
       "  ('a transformer based sales prediction of smart container in new retail era',\n",
       "   1,\n",
       "   1)),\n",
       " ('mri',\n",
       "  ('a transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain mri images',\n",
       "   1,\n",
       "   1)),\n",
       " ('verification',\n",
       "  ('adversarial attacks on kinship verification using transformer', 1, 1)),\n",
       " ('more', ('are transformers more robust than cnns?', 1, 1)),\n",
       " ('assessing',\n",
       "  ('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('automated essay scoring using efficient transformer-based language models',\n",
       "   1,\n",
       "   1)),\n",
       " ('trial',\n",
       "  ('automated tabulation of clinical trial results: a joint entity and relation extraction approach with transformer-based language representations',\n",
       "   1,\n",
       "   1)),\n",
       " ('rail',\n",
       "  ('automatic detection of rail components via a deep convolutional transformer network',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('ava:',\n",
       "  ('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('speaker', ('avatr: one-shot speaker extraction with transformers', 1, 1)),\n",
       " ('extraction',\n",
       "  ('avatr: one-shot speaker extraction with transformers', 1, 1)),\n",
       " ('voltage',\n",
       "  ('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('bert',\n",
       "  ('bert based transformers lead the way in extraction of health information from social media',\n",
       "   1,\n",
       "   1)),\n",
       " ('visual',\n",
       "  ('beyond self-attention: external attention using two linear layers for visual tasks',\n",
       "   1,\n",
       "   1)),\n",
       " ('vaccine',\n",
       "  ('bidirectional encoder representations from transformers for the covid-19 vaccine stance classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('billion-scale pretraining with vision transformers for multi-task visual representations',\n",
       "   1,\n",
       "   1)),\n",
       " ('controllable',\n",
       "  ('c5t5: controllable generation of organic molecules with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('computation-aware',\n",
       "  ('cate: computation-aware neural architecture encoding with transformers',\n",
       "   2,\n",
       "   1)),\n",
       " ('melody',\n",
       "  ('chord conditioned melody generation with transformer based decoders',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('cmsaone@dravidian-codemix-fire2020: a meta embedding and transformer model for code-mixed sentiment analysis on social media text',\n",
       "   1,\n",
       "   1)),\n",
       " ('sexism',\n",
       "  ('combining transformer-based models with traditional machine learning approaches for sexism identification in social networks at exist 2021',\n",
       "   1,\n",
       "   1)),\n",
       " ('accelerated',\n",
       "  ('consistent accelerated inference via confident adaptive transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('agent',\n",
       "  ('conversational agent embodying a historical figure using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('deepfake detection scheme based on vision transformer and distillation',\n",
       "   1,\n",
       "   1)),\n",
       " ('deeplpc-mhanet:',\n",
       "  ('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('method',\n",
       "  ('defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('detecting dementia from speech and transcripts using transformers', 1, 1)),\n",
       " ('transformer',\n",
       "  ('detection of transformer winding axial displacement by kirchhoff and delay and sum radar imaging algorithms',\n",
       "   1,\n",
       "   1)),\n",
       " ('real-time',\n",
       "  ('developing real-time streaming transformer transducer for speech recognition on large-scale dataset',\n",
       "   1,\n",
       "   1)),\n",
       " ('semantic',\n",
       "  ('diagnosing transformers in task-oriented semantic parsing', 1, 1)),\n",
       " ('discriminative',\n",
       "  ('discriminative and generative transformer-based models for situation entity classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('dispensed transformer network for unsupervised domain adaptation', 1, 1)),\n",
       " ('for',\n",
       "  ('dlsa: dual-learning based on self-attention for rating prediction', 1, 1)),\n",
       " ('classification',\n",
       "  ('eeg classification with transformer-based models', 1, 1)),\n",
       " ('strategies',\n",
       "  ('empirical analysis of training strategies of transformer-based japanese chit-chat systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('spotting',\n",
       "  ('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('lightweight',\n",
       "  ('evaluating transformers for lightweight action recognition', 1, 1)),\n",
       " ('power',\n",
       "  ('evaluation of static synchronous compensator and rail power conditioner in electrified railway systems using v/v and scott power transformers',\n",
       "   2,\n",
       "   1)),\n",
       " ('at',\n",
       "  ('everything at once - multi-modal fusion transformer for video retrieval',\n",
       "   1,\n",
       "   1)),\n",
       " ('dementia',\n",
       "  ('explainable identification of dementia from transcripts using transformer networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('and', ('exploring and improving mobile level vision transformers', 1, 1)),\n",
       " ('via',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1,\n",
       "   1)),\n",
       " ('spaces',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('exploring the promises of transformer-based lms for the representation of normative claims in the legal domain',\n",
       "   2,\n",
       "   1)),\n",
       " ('and', ('fast and precise certification of transformers', 1, 1)),\n",
       " ('point', ('fast point transformer', 1, 1)),\n",
       " ('a',\n",
       "  ('fbert: a neural transformer for identifying offensive content', 2, 1)),\n",
       " ('fine-tuning',\n",
       "  ('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   1,\n",
       "   1)),\n",
       " ('can', ('generative video transformer: can objects be the words?', 1, 1)),\n",
       " ('fast',\n",
       "  ('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('high-fidelity pluralistic image completion with transformers', 2, 1)),\n",
       " ('ice', ('ice hockey player identification via transformers', 1, 1)),\n",
       " ('via', ('ice hockey player identification via transformers', 1, 1)),\n",
       " ('hope',\n",
       "  ('iiitt@lt-edi-eacl2021-hope speech detection: there is always hope in transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('and', ('image captioning with transformer and knowledge graph', 1, 1)),\n",
       " ('via',\n",
       "  ('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('accelerator',\n",
       "  ('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   1,\n",
       "   1)),\n",
       " ('khmer',\n",
       "  ('incorporating transformer models for sentiment analysis and news classification in khmer',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-supervised',\n",
       "  ('integration of patch features through self-supervised learning and transformer for survival analysis on whole slide images',\n",
       "   1,\n",
       "   1)),\n",
       " ('reacutepondre',\n",
       "  (\"interaction retardeacutee dans l'encodeur du transformer pour reacutepondre efficacement aux questions dans un domaine ouvert\",\n",
       "   1,\n",
       "   1)),\n",
       " ('karl-trans-ner:',\n",
       "  ('karl-trans-ner: knowledge aware representation learning for named entity recognition using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('to',\n",
       "  ('language modeling using lmus: 10x better data efficiency or improved scaling compared to transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('audio',\n",
       "  ('large scale audio understanding without transformers/ convolutions/ berts/ mixers/ attention/ rnns or ...',\n",
       "   1,\n",
       "   1)),\n",
       " ('error',\n",
       "  ('lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing',\n",
       "   1,\n",
       "   1)),\n",
       " ('super-resolution',\n",
       "  ('light field image super-resolution with transformers', 1, 1)),\n",
       " ('vision', ('local-to-global self-attention in vision transformers', 1, 1)),\n",
       " ('removal',\n",
       "  ('m2gan: a multi-stage self-attention network for image rain removal on autonomous vehicles',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-attribute',\n",
       "  ('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('malbert: using transformers for cybersecurity and malicious software detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('efficiency',\n",
       "  ('mate: multi-view attention for table transformer efficiency', 2, 1)),\n",
       " ('and',\n",
       "  ('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   2,\n",
       "   1)),\n",
       " ('meeting',\n",
       "  ('meetsum: transforming meeting transcript summarization using transformers!',\n",
       "   1,\n",
       "   1)),\n",
       " ('active',\n",
       "  ('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   1,\n",
       "   1)),\n",
       " ('age',\n",
       "  ('modeling age of acquisition norms using transformer networks', 1, 1)),\n",
       " ('networks',\n",
       "  ('modular graph transformer networks for multi-label image classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers', ('multi-airport delay prediction with transformers', 1, 1)),\n",
       " ('automatic',\n",
       "  ('multi-head fusion attention for transformer-based end-to-end automatic speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('multi-head self-attention via vision transformer for zero-shot learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('four-wire',\n",
       "  ('multi-input transformer-less four-wire microinverter with distributed mppt for pv systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('speech',\n",
       "  (\"multilingual speech translation with unified transformer: huawei noah's ark lab at iwslt 2021\",\n",
       "   1,\n",
       "   1)),\n",
       " ('framework',\n",
       "  ('multimodal graph-based transformer framework for biomedical relation extraction',\n",
       "   1,\n",
       "   1)),\n",
       " ('incremental',\n",
       "  ('multimodal incremental transformer with visual grounding for visual dialogue generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('motion', ('multimodal motion prediction with stacked transformers', 2, 1)),\n",
       " ('using',\n",
       "  ('ncu-nlp at rocling-2021 shared task: using macbert transformers for dimensional sentiment analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('document',\n",
       "  ('nlp-iis@ut at semeval-2021 task 4: machine reading comprehension using the long document transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('effectiveness',\n",
       "  ('on the effectiveness of vision transformers for zero-shot face anti-spoofing',\n",
       "   1,\n",
       "   1)),\n",
       " ('sentiment',\n",
       "  ('opinion extraction as a structured sentiment analysis using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('reduce',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1,\n",
       "   1)),\n",
       " ('models',\n",
       "  ('optimizing domain specificity of transformer-based language models for extractive summarization of financial news articles in korean',\n",
       "   1,\n",
       "   1)),\n",
       " ('optimizing',\n",
       "  ('optimizing inference performance of transformers on cpus', 1, 1)),\n",
       " ('with',\n",
       "  ('paraphrasing academic text: a study of back-translating anatomy and physiology with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('pedestrian',\n",
       "  ('pedestrian trajectory prediction via spatial interaction transformer network',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('phylotransformer: a discriminative model for mutation prediction based on a multi-head self-attention mechanism',\n",
       "   1,\n",
       "   1)),\n",
       " ('cloud', ('point cloud learning with transformer', 1, 1)),\n",
       " ('based',\n",
       "  ('power grid cascading failure prediction based on transformer', 1, 1)),\n",
       " ('and',\n",
       "  ('power transformer fault diagnosis with intrinsic time-scale decomposition and xgboost classifier',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('pq-transformer: jointly parsing 3d objects and layouts from point clouds',\n",
       "   1,\n",
       "   1)),\n",
       " ('summarizers',\n",
       "  ('predicting discourse trees from transformer-based neural summarizers',\n",
       "   1,\n",
       "   1)),\n",
       " ('normalized',\n",
       "  ('progressively normalized self-attention network for video polyp segmentation',\n",
       "   2,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('ptq4vit: post-training quantization framework for vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('pushing the limits of rule reasoning in transformers through natural language satisfiability',\n",
       "   1,\n",
       "   1)),\n",
       " ('autonomous',\n",
       "  ('real-time semantic segmentation with dual encoder and self-attention mechanism for autonomous driving',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning,',\n",
       "  ('reasoning with transformer-based models: deep learning, but shallow reasoning',\n",
       "   1,\n",
       "   1)),\n",
       " ('capac-itance',\n",
       "  ('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('research on on-line detection method of transformer winding deformation based on vfto',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "   1,\n",
       "   1)),\n",
       " ('contextualized',\n",
       "  ('retra: recurrent transformers for learning temporally contextualized knowledge graph embeddings',\n",
       "   1,\n",
       "   1)),\n",
       " ('scale',\n",
       "  ('scale efficiently: insights from pre-training and fine-tuning transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('consistency',\n",
       "  ('scat: stride consistency with auto-regressive regressor and transformer for hand pose estimation',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('seizure prediction using convolutional neural networks and sequence transformer networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('action',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('atherosclerotic',\n",
       "  ('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   1,\n",
       "   1)),\n",
       " ('tissue',\n",
       "  ('self-attention based virtual staining for bright-field images of label-free human carotid atherosclerotic plaque tissue section',\n",
       "   1,\n",
       "   1)),\n",
       " ('between',\n",
       "  ('self-attention between datapoints: going beyond individual input-output pairs in deep learning',\n",
       "   2,\n",
       "   1)),\n",
       " ('super-resolution', ('self-attention for audio super-resolution', 1, 1)),\n",
       " ('networks',\n",
       "  ('self-attention generative adversarial networks for times series vhr multispectral image generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('self-attention presents low-dimensional knowledge graph embeddings for link prediction',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('self-attention-based temporary curiosity in reinforcement learning exploration',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('self-supervised pre-training of swin transformers for 3d medical image analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('using',\n",
       "  ('semi-supervised sound event detection using self-attention and multiple techniques of consistency training',\n",
       "   1,\n",
       "   1)),\n",
       " ('transcription',\n",
       "  ('sequence-to-sequence piano transcription with transformers', 1, 1)),\n",
       " ('bidirectional',\n",
       "  ('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('session-based',\n",
       "  ('session-based recommendation with self-attention networks', 1, 1)),\n",
       " ('fpga',\n",
       "  ('short-circuited turn fault diagnosis in transformers by using vibration signals, statistical time features, and support vector machines on fpga',\n",
       "   1,\n",
       "   1)),\n",
       " ('with', ('single-shot motion completion with transformer', 1, 1)),\n",
       " ('graph',\n",
       "  ('spatial-temporal transformer for dynamic scene graph generation', 2, 1)),\n",
       " ('with', ('speaker-aware speech enhancement with self-attention', 1, 1)),\n",
       " ('spelling', ('spelling correction with denoising transformer', 1, 1)),\n",
       " ('comments',\n",
       "  ('ssn_dibertsity@lt-edi-eacl2021: hope speech detection on multilingual youtube comments via transformer based approach',\n",
       "   1,\n",
       "   1)),\n",
       " ('high-resolution',\n",
       "  ('styleswin: transformer-based gan for high-resolution image generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   1,\n",
       "   1)),\n",
       " ('t3-vis:',\n",
       "  ('t3-vis: visual analytic for training and fine-tuning transformers in nlp',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('tackling italian university assessment tests with transformer-based language models',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('text-conditioned transformer for automatic pronunciation error detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents',\n",
       "   1,\n",
       "   1)),\n",
       " ('overcurrent',\n",
       "  ('the cause of transformer zero sequence overcurrent protection act', 1, 1)),\n",
       " ('of',\n",
       "  ('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   1,\n",
       "   1)),\n",
       " ('router:',\n",
       "  ('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('the transformer network for the traveling salesman problem', 1, 1)),\n",
       " ('token', ('token pooling in vision transformers', 1, 1)),\n",
       " ('object',\n",
       "  ('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('transmvsnet: global context-aware multi-view stereo network with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('trar: routing the attention spans in transformer for visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('tuta:',\n",
       "  ('tuta: tree-based transformers for generally structured table pre-training',\n",
       "   1,\n",
       "   1)),\n",
       " ('image', ('u-shape transformer for underwater image enhancement', 1, 1)),\n",
       " ('2021:',\n",
       "  ('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('swisstext-2021:',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1,\n",
       "   1)),\n",
       " ('text',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('video relation detection via tracklet based visual transformer', 1, 1)),\n",
       " ('video', ('video super-resolution transformer', 1, 1)),\n",
       " ('transformers', ('vision transformers are robust learners', 1, 1)),\n",
       " ('part-and-sum',\n",
       "  ('visual composite set detection using part-and-sum transformers', 1, 1)),\n",
       " ('of',\n",
       "  ('voltage dependence of the reference system in medium- and high-voltage current transformer calibrations',\n",
       "   1,\n",
       "   1)),\n",
       " ('speed',\n",
       "  ('wind speed forecasting method based on deep learning strategy using long short term memory neural network and transformer model',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "   1,\n",
       "   1)),\n",
       " ('attention',\n",
       "  ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   1,\n",
       "   1)),\n",
       " ('distribution',\n",
       "  ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   1,\n",
       "   1)),\n",
       " ('oil-paper',\n",
       "  ('a modified simulation model for predicting the fds of transformer oil-paper insulation under nonuniform aging',\n",
       "   1,\n",
       "   1)),\n",
       " ('contracts',\n",
       "  ('a multi-modal transformer-based code summarization approach for smart contracts',\n",
       "   2,\n",
       "   1)),\n",
       " ('grid',\n",
       "  ('a new state-of-the-art transformers-based load forecaster on the smart grid domain',\n",
       "   1,\n",
       "   1)),\n",
       " ('interleaved',\n",
       "  ('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   1,\n",
       "   1)),\n",
       " ('approach',\n",
       "  ('a transformer based approach for fighting covid-19 fake news', 1, 1)),\n",
       " ('reversing',\n",
       "  ('a transformer-based framework for neutralizing and reversing the political polarity of news articles',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('accelerating framework of transformer by hardware design and model compression co-optimization',\n",
       "   1,\n",
       "   1)),\n",
       " ('direct',\n",
       "  ('an approach to steady-state power transformer modeling considering direct current resistance test measurements',\n",
       "   1,\n",
       "   1)),\n",
       " ('impulse',\n",
       "  ('an automatic data acquisition device for transformer oscillating switching impulse voltage tests',\n",
       "   1,\n",
       "   1)),\n",
       " ('vibration',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('items',\n",
       "  ('augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('image', ('beit: bert pre-training of image transformers', 1, 1)),\n",
       " ('detection',\n",
       "  ('benchmarking detection transfer learning with vision transformers', 1, 1)),\n",
       " ('that',\n",
       "  ('bert busters: outlier dimensions that disrupt transformers', 1, 1)),\n",
       " ('online',\n",
       "  ('bilingual self-attention network: generating headlines for online linguistic questions',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-scale',\n",
       "  ('cac-emvt: efficient coronary artery calcium segmentation with multi-scale vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('javanese',\n",
       "  ('canonical segmentation using affix characters as a unit on transformer for javanese language',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('case relation transformer: a crossmodal language generation model for fetching instructions',\n",
       "   2,\n",
       "   1)),\n",
       " ('recursive',\n",
       "  ('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   1,\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('cdtrans: cross-domain transformer for unsupervised domain adaptation',\n",
       "   1,\n",
       "   1)),\n",
       " ('via',\n",
       "  ('certified patch robustness via smoothed vision transformers', 1, 1)),\n",
       " ('answering',\n",
       "  ('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('code', ('code prediction by feeding trees to transformers', 1, 1)),\n",
       " ('video',\n",
       "  ('combining efficientnet and vision transformers for video deepfake detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('comformer: code comment generation via transformer and fusion method-based hybrid code representation',\n",
       "   1,\n",
       "   1)),\n",
       " ('machine',\n",
       "  ('comparison of machine learning algorithms for the prediction of mechanical stress in three-phase power transformer winding conductors',\n",
       "   1,\n",
       "   1)),\n",
       " ('component-level',\n",
       "  ('component-level thermo-electromagnetic nonlinear transient finite element modeling of solid-state transformer for dc grid studies',\n",
       "   1,\n",
       "   1)),\n",
       " ('linkable',\n",
       "  ('contextual-semantic-aware linkable knowledge prediction in stack overflow via self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer?',\n",
       "  ('convolutional neural network or vision transformer? benchmarking various machine learning models for distracted driver detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('from',\n",
       "  ('covid-net us: a tailored, highly efficient, self-attention deep convolutional neural network design for detection of covid-19 patient cases from point-of-care ultrasound imaging',\n",
       "   1,\n",
       "   1)),\n",
       " ('full', ('cptr: full transformer network for image captioning', 1, 1)),\n",
       " ('transformer',\n",
       "  ('crossvit: cross-attention multi-scale vision transformer for image classification',\n",
       "   2,\n",
       "   1)),\n",
       " ('model-based',\n",
       "  ('cs-um6p at semeval-2021 task 1: a deep learning model-based pre-trained transformer encoder for lexical complexity',\n",
       "   1,\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('deep transformer networks for time series classification: the npp safety case',\n",
       "   1,\n",
       "   1)),\n",
       " ('deep',\n",
       "  ('delving deep into the generalization of vision transformers under distribution shifts',\n",
       "   1,\n",
       "   1)),\n",
       " ('connectivity,',\n",
       "  ('demystifying local vision transformer: sparse connectivity, weight sharing, and dynamic weight',\n",
       "   1,\n",
       "   1)),\n",
       " ('records',\n",
       "  ('detection of abusive records by analyzing the tweets in urdu language exploring transformer based models',\n",
       "   1,\n",
       "   1)),\n",
       " ('via',\n",
       "  ('dg-trans: automatic code summarization via dynamic graph attention-based transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('diformer: directional transformer for neural machine translation', 1, 1)),\n",
       " ('discrete',\n",
       "  ('discrete representations strengthen vision transformer robustness', 1, 1)),\n",
       " ('admission',\n",
       "  ('disease classification on admission and on discharge with residual cnn-transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('dissolved gas analysis for transformer fault based on learning spiking neural p system with belief adaboost',\n",
       "   1,\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('do transformers really perform badly for graph representation?', 1, 1)),\n",
       " ('explicit',\n",
       "  ('do we really need explicit position encodings for vision transformers?',\n",
       "   1,\n",
       "   1)),\n",
       " ('unwarping',\n",
       "  ('doctr: document image transformer for geometric unwarping and illumination correction',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-temporal',\n",
       "  ('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('dpnet: dual-path network for efficient object detectioj with lightweight self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('title',\n",
       "  ('dsgpt: domain-specific generative pre-training of transformers for text generation in e-commerce title and review summarization',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('dynamic transformer for efficient machine translation on embedded devices',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('effective ensembling of transformer based language models for acronyms identification',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('efficient-capsnet: capsule network with self-attention routing', 1, 1)),\n",
       " ('auto-regressive',\n",
       "  ('embedding calibration for music semantic similarity using auto-regressive transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('robot', ('empathetic robot with transformer-based dialogue agent', 1, 1)),\n",
       " ('machine',\n",
       "  ('english machine translation model based on an improved self-attention technology',\n",
       "   1,\n",
       "   1)),\n",
       " ('structures',\n",
       "  ('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('enriching non-autoregressive transformer with syntactic and semantic structures for neural machine translation',\n",
       "   1,\n",
       "   1)),\n",
       " ('linguistic',\n",
       "  ('enriching the transformer with linguistic factors for low-resource machine translation',\n",
       "   1,\n",
       "   1)),\n",
       " ('principles',\n",
       "  ('erratum: rodrigo-mor et al. principles of charge estimation methods using high-frequency current transformer sensors in partial discharge measurements. sensors 2020, 20, 2520',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('evolving transformer architecture for neural machine translation', 1, 1)),\n",
       " ('for',\n",
       "  ('evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   1,\n",
       "   1)),\n",
       " ('domain',\n",
       "  ('exploring sequence feature alignment for domain adaptive detection transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('content',\n",
       "  ('exploring transformer based models to identify hate speech and offensive content in english and indo-aryan languages',\n",
       "   1,\n",
       "   1)),\n",
       " ('moisture',\n",
       "  ('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   1,\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('feature fusion vision transformer for fine-grained visual categorization',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('few-shot temporal action localization with query adaptive transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('fine-tuning of pre-trained transformers for hate, offensive, and profane content detection in english and marathi',\n",
       "   1,\n",
       "   1)),\n",
       " ('microscopy',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1,\n",
       "   1)),\n",
       " ('llc',\n",
       "  ('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   1,\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('fu covid-19 ai agent built on attention algorithm using a combination of transformer, albert model, and rasa framework',\n",
       "   1,\n",
       "   1)),\n",
       " ('abnormal',\n",
       "  ('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('generative adversarial networks for abnormal event detection in videos based on self-attention mechanism',\n",
       "   1,\n",
       "   1)),\n",
       " ('geometry-contrastive',\n",
       "  ('geometry-contrastive transformer for generalized 3d pose transfer', 1, 1)),\n",
       " ('self-attention',\n",
       "  ('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   1,\n",
       "   1)),\n",
       " ('computation',\n",
       "  ('greenformers: improving computation and memory efficiency in transformer models via low-rank approximation',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('hate speech and offensive content identification based on self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('current',\n",
       "  ('high-frequency current transformer design and implementation considerations for wideband partial discharge applications',\n",
       "   1,\n",
       "   1)),\n",
       " ('differential',\n",
       "  ('how geometry affects sensitivity of a differential transformer for contactless characterization of liquids',\n",
       "   1,\n",
       "   1)),\n",
       " ('i2c2w:',\n",
       "  ('i2c2w: image-to-character-to-word transformers for accurate scene text recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('high',\n",
       "  ('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   1,\n",
       "   1)),\n",
       " ('voltage',\n",
       "  ('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "   1,\n",
       "   1)),\n",
       " ('implicit',\n",
       "  ('implicit transformer network for screen content image continuous super-resolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('approximation',\n",
       "  ('improved few-shot learning method for transformer fault diagnosis based on approximation space and belief functions',\n",
       "   1,\n",
       "   1)),\n",
       " ('translation',\n",
       "  ('incorporating relative position information in transformer-based sign language recognition and translation',\n",
       "   1,\n",
       "   1)),\n",
       " ('10',\n",
       "  ('indt5: a text-to-text transformer for 10 indigenous languages', 1, 1)),\n",
       " ('a',\n",
       "  ('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('inversemv: composing piano scores with a convolutional video-music transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('model',\n",
       "  ('keyword transformer: a self-attention model for keyword spotting', 1, 1)),\n",
       " ('via',\n",
       "  ('learning generalizable vision-tactile robotic grasping strategy for deformable objects via transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('features',\n",
       "  ('learning transformer features for image quality assessment', 1, 1)),\n",
       " ('multi-view',\n",
       "  ('legoformer: transformers for block-by-block multi-view 3d reconstruction',\n",
       "   1,\n",
       "   1)),\n",
       " ('adaptive',\n",
       "  ('make a long image short: adaptive token length for vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('mgsan:',\n",
       "  ('mgsan: a multi-granularity self-attention network for next poi recommendation',\n",
       "   1,\n",
       "   1)),\n",
       " ('u-net', ('mixed transformer u-net for medical image segmentation', 1, 1)),\n",
       " ('gait',\n",
       "  ('mldt: multi-task learning with denoising transformer for gait identity and emotion recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('frequency',\n",
       "  ('modeling capacitive low-power voltage transformer behavior over temperature and frequency',\n",
       "   1,\n",
       "   1)),\n",
       " ('winding',\n",
       "  ('modelling of high frequency coreless planar transformer with twr hexagonal winding',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('modified deep transformers for gnss time series prediction', 1, 1)),\n",
       " ('auxiliary',\n",
       "  ('monte carlo denoising via auxiliary feature guided self-attention', 1, 1)),\n",
       " ('video',\n",
       "  ('morphmlp: a self-attention free, mlp-like backbone for image and video',\n",
       "   1,\n",
       "   1)),\n",
       " ('dynamic', ('multi-exit vision transformer for dynamic inference', 1, 1)),\n",
       " ('transformer-based',\n",
       "  ('mutformer: a context-dependent transformer-based model to predict pathogenic missense mutations',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('ncuee-nlp at mediqa 2021: health question summarization using pegasus transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('model',\n",
       "  ('noniterative design of litz-wire high-frequency gapped-transformer (lw-hfgt) for llc converters based on optimal core-geometry factor model (okgm)',\n",
       "   1,\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('on efficient transformer and image pre-training for low-level vision',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers:',\n",
       "  ('on the impact of grid harmonics in transformers: a case study', 1, 1)),\n",
       " ('audio-visual',\n",
       "  ('optimizing latency for online video captioningusing audio-visual transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('completion',\n",
       "  ('pctma-net: point cloud transformer with morphing atlas-based point generation network for dense point cloud completion',\n",
       "   1,\n",
       "   1)),\n",
       " ('cloud',\n",
       "  ('point-bert: pre-training 3d point cloud transformers with masked point modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('optimization',\n",
       "  ('portfolio optimization with 2d relative-attentional gated transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('power transformer fault diagnosis system based on internet of things',\n",
       "   1,\n",
       "   1)),\n",
       " ('fistula',\n",
       "  ('predicting esophageal fistula risks using a multimodal self-attention network',\n",
       "   1,\n",
       "   1)),\n",
       " ('scientific',\n",
       "  ('predicting real-time scientific experiments using transformer models and reinforcement learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision-and-language',\n",
       "  ('probing inter-modality: visual parsing with self-attention for vision-and-language pre-training',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('prostformer: pre-trained progressive space-time self-attention model for traffic flow forecasting',\n",
       "   1,\n",
       "   1)),\n",
       " ('for', ('pyramid medical transformer for medical image segmentation', 1, 1)),\n",
       " ('transformer',\n",
       "  ('radiology report generation for rare diseases via few-shot transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('remote sensing image defogging networks based on dual self-attention boost residual octave convolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('feature',\n",
       "  ('research on hybrid feature selection method of power transformer based on fuzzy information entropy',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('revamping cross-modal recipe retrieval with hierarchical transformers and self-supervised learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('risc-vtf: risc-v based extended instruction set for transformer', 1, 1)),\n",
       " ('vs',\n",
       "  (\"rnn's vs transformers: training language models on deficit datasets\",\n",
       "   1,\n",
       "   1)),\n",
       " ('component',\n",
       "  ('running status diagnosis of onboard traction transformers based on kernel principal component analysis and fuzzy clustering',\n",
       "   1,\n",
       "   1)),\n",
       " ('adversarial',\n",
       "  ('sa-capsgan: using capsule networks with embedded self-attention for generative adversarial network',\n",
       "   1,\n",
       "   1)),\n",
       " ('cooperative',\n",
       "  ('sa-matd3: self-attention-based multi-agent continuous control method in cooperative environments',\n",
       "   1,\n",
       "   1)),\n",
       " ('among', ('self-attention agreement among capsules', 1, 1)),\n",
       " ('inside',\n",
       "  ('self-attention attribution: interpreting information interactions inside transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('anchor',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('proposal',\n",
       "  ('self-attention based anchor proposal for skeleton-based action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('relations',\n",
       "  ('self-attention graph residual convolutional networks for event detection with dependency relations',\n",
       "   1,\n",
       "   1)),\n",
       " ('building',\n",
       "  ('self-attention in reconstruction bias u-net for semantic segmentation of building rooftops in optical remote sensing images',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-supervised', ('self-supervised video transformer', 1, 1)),\n",
       " ('arcs',\n",
       "  ('sentimentarcs: a novel method for self-supervised sentiment analysis of time series shows sota transformers can struggle finding narrative arcs',\n",
       "   1,\n",
       "   1)),\n",
       " ('lesion',\n",
       "  ('severity quantification and lesion localization of covid-19 on cxr using vision transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('low-complexity',\n",
       "  ('shallow convolution-augmented transformer with differentiable neural computer for low-complexity classification of variable-length acoustic scene',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('shuffle transformer with feature alignment for video face parsing', 1, 1)),\n",
       " ('image',\n",
       "  ('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('skyformer: remodel self-attention with gaussian kernel and nystroumlm method',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning', ('sparse spatial transformers for few-shot learning', 1, 1)),\n",
       " ('segmentation',\n",
       "  ('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('stformer: a noise-aware efficient spatio-temporal transformer architecture for traffic forecasting',\n",
       "   1,\n",
       "   1)),\n",
       " ('stochastic',\n",
       "  ('stochastic attention head removal: a simple and effective method for improving transformer based asr models',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('streaming transformer for hardware efficient voice trigger detection and false trigger mitigation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('study on the sound radiation efficiency of a typical distribution transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('voxel',\n",
       "  ('svt-net: a super light-weight network for large scale place recognition using sparse voxel transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('tag: gradient attack on transformer-based language models', 1, 1)),\n",
       " ('hostility',\n",
       "  ('task adaptive pretraining of transformers for hostility detection', 1, 1)),\n",
       " ('tcl:',\n",
       "  ('tcl: transformer-based dynamic graph modelling via contrastive learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('estimation',\n",
       "  ('test-time personalization with a transformer for human pose estimation',\n",
       "   2,\n",
       "   1)),\n",
       " ('the',\n",
       "  ('the development of precision 500/√3-kv two-stage voltage transformer with high-voltage excitation',\n",
       "   1,\n",
       "   1)),\n",
       " ('too',\n",
       "  ('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   1,\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('towards more efficient insertion transformer with fractional positional encoding',\n",
       "   1,\n",
       "   1)),\n",
       " ('phase',\n",
       "  ('trans-svnet: accurate phase recognition from surgical videos via hybrid embedding aggregation transformer',\n",
       "   2,\n",
       "   1)),\n",
       " ('couplet',\n",
       "  ('transcouplet: transformer based chinese couplet generation', 1, 1)),\n",
       " ('transformer',\n",
       "  ('transformer based end-to-end mispronunciation detection and diagnosis',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('transformer based neural network for fine-grained classification of vehicle color',\n",
       "   1,\n",
       "   1)),\n",
       " ('scheme',\n",
       "  ('transformer meets dcfam: a novel semantic segmentation scheme for fine-resolution remote sensing images',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer reasoning network for personalized review summarization',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('transformer-based dual relation graph for multi-label image recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('portuguese',\n",
       "  ('transformers and transfer learning for improving portuguese semantic role labeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('russian',\n",
       "  ('transformers for headline selection for russian news clusters', 1, 1)),\n",
       " ('fake',\n",
       "  ('transforming fake news: robust generalisable news classification using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('efficient',\n",
       "  ('transhash: transformer-based hamming hashing for efficient image retrieval',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('translation transformers rediscover inherent data domains', 1, 1)),\n",
       " ('transformer',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1,\n",
       "   1)),\n",
       " ('instance',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('tritransnet: rgb-d salient object detection with a triplet transformer embedding network',\n",
       "   1,\n",
       "   1)),\n",
       " ('denoising',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoder for unsupervised sentence embedding learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('tsdae:',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('twitter dataset and evaluation of transformers for turkish sentiment analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('two-hand pose estimation from the non-cropped rgb image with self-attention based network',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('umuteam at meoffendes 2021: ensemble learning for offensive language identification using linguistic features, fine-grained negation, and transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('overcoming',\n",
       "  ('understanding and overcoming the challenges of efficient transformer quantization',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('video joint modelling based on hierarchical transformer for co-summarization',\n",
       "   1,\n",
       "   1)),\n",
       " ('viesum:',\n",
       "  ('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   1,\n",
       "   1)),\n",
       " ('text',\n",
       "  ('vision and text transformer for predicting answerability on visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('vision transformer for plant disease detection: plantvit', 1, 1)),\n",
       " ('disease',\n",
       "  ('vision transformer for plant disease detection: plantvit', 1, 1)),\n",
       " ('transformer',\n",
       "  ('vision transformer using low-level chest x-ray feature corpus for covid-19 diagnosis and severity quantification',\n",
       "   1,\n",
       "   1)),\n",
       " ('grounding', ('visual grounding with transformers', 1, 1)),\n",
       " ('vitality:',\n",
       "  ('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   1,\n",
       "   1)),\n",
       " ('use?',\n",
       "  ('what context features can transformer language models use?', 1, 1)),\n",
       " ('for',\n",
       "  ('wide-band current transformers for traveling-waves-based protection applications',\n",
       "   1,\n",
       "   1)),\n",
       " ('intrinsic',\n",
       "  ('word representation learning in multimodal pre-trained transformers: an intrinsic evaluation',\n",
       "   1,\n",
       "   1)),\n",
       " ('wrtre:',\n",
       "  ('wrtre: weighted relative position transformer for joint entity and relation extraction',\n",
       "   1,\n",
       "   1)),\n",
       " ('16.8-to-21.6',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1,\n",
       "   1)),\n",
       " ('three-phase',\n",
       "  ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('fine-grained',\n",
       "  ('a fine-grained classification method based on self-attention siamese network',\n",
       "   1,\n",
       "   1)),\n",
       " ('communication',\n",
       "  ('a mm-wave gm-assisted transformer-based matching network 2x2 phased-array receiver for 5g communication and radar systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('dc',\n",
       "  ('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "   1,\n",
       "   1)),\n",
       " ('novel',\n",
       "  ('a novel suppression method for grounding transformer against earth current from urban rail transit',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a pre-ln transformer network model with lexical features for fine-grained sentiment classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('dilated',\n",
       "  ('a serial-parallel self-attention network joint with multi-scale dilated convolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('synthesis',\n",
       "  ('a sketch-transformer network for face photo-sketch synthesis', 1, 1)),\n",
       " ('and',\n",
       "  ('a study of social and behavioral determinants of health in lung cancer patients using transformers-based natural language processing models',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   1,\n",
       "   1)),\n",
       " ('cells',\n",
       "  ('a transformer-less voltage equalizer for energy storage cells based on double-tiered multi-stacked converters',\n",
       "   1,\n",
       "   1)),\n",
       " ('fpga:',\n",
       "  ('accommodating transformer onto fpga: coupling the balanced model compression and fpga-implementation optimization',\n",
       "   1,\n",
       "   1)),\n",
       " ('an',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('llc',\n",
       "  ('analysis and design of an integrated magnetics planar transformer for high power density llc resonant converter',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer', ('asformer: transformer for action segmentation', 1, 1)),\n",
       " ('winding',\n",
       "  ('assessment of effect of winding geometry on thermal performance of retrofilled transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('be specific, be clear: bridging machine and human captions by scene-guided transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('array-based',\n",
       "  ('beamtransformer: microphone array-based overlapping speech detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('mri',\n",
       "  ('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('perform',\n",
       "  ('causal transformers perform below chance on recursive nested constructions, unlike humans',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('combining cnns with transformer for multimodal 3d mri brain tumor segmentation with self-supervised pretraining',\n",
       "   1,\n",
       "   1)),\n",
       " ('solid-state-transformers',\n",
       "  ('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('constructing',\n",
       "  ('constructing global coherence representations: identifying interpretability and coherences of transformer attention in time series data',\n",
       "   1,\n",
       "   1)),\n",
       " ('aggregation',\n",
       "  ('contextual similarity aggregation with self-attention for visual re-ranking',\n",
       "   1,\n",
       "   1)),\n",
       " ('matching',\n",
       "  ('cotr: correspondence transformer for matching across images', 1, 1)),\n",
       " ('models',\n",
       "  ('cross-modal transformer-based neural correction models for automatic speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('cyclegan-based',\n",
       "  ('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('cyclic diffeomorphic transformer nets for contour alignment', 1, 1)),\n",
       " ('for',\n",
       "  ('deep transformer networks for time series classification: the npp safety case',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('deeplpc-mhanet: multi-head self-attention for augmented kalman filter-based speech enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('ensemble',\n",
       "  ('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('low-loss',\n",
       "  ('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('ultra-wideband',\n",
       "  ('design of high-isolation and low-loss single pole double throw switch based on the triple-coupled transformer for ultra-wideband phased array systems',\n",
       "   1,\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('discriminative and generative transformer-based models for situation entity classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('diverse',\n",
       "  ('diverse image inpainting with bidirectional and autoregressive transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('dropout regularization for self-supervised learning of transformer encoder speech representation',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-modal',\n",
       "  ('dynamic graph representation learning for video dialog via multi-modal shuffled transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('properties',\n",
       "  ('effect of iron/titania-based nanomaterials on the dielectric properties of mineral oil, natural and synthetic esters as transformers insulating fluid',\n",
       "   1,\n",
       "   1)),\n",
       " ('voltages',\n",
       "  ('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('efficient video transformers with spatial-temporal token selection',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('electric transformer oil leakage visual detection as service based on lstm and genetic algorithm',\n",
       "   1,\n",
       "   1)),\n",
       " ('properties',\n",
       "  ('emerging properties in self-supervised vision transformers', 1, 1)),\n",
       " ('end-to-end',\n",
       "  ('end-to-end human object interaction detection with hoi transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('end-to-end',\n",
       "  ('end-to-end temporal action detection with transformer', 1, 1)),\n",
       " ('models',\n",
       "  ('enhancing lstm models with self-attention and stateful training', 1, 1)),\n",
       " ('a',\n",
       "  ('ernie-doc: a retrospective long-document modeling transformer', 1, 1)),\n",
       " ('reply',\n",
       "  ('exploring low-cost transformer model compression for large-scale commercial reply suggestions',\n",
       "   1,\n",
       "   1)),\n",
       " ('subtypes',\n",
       "  ('gene transformer: transformers for the gene expression-based classification of cancer subtypes',\n",
       "   1,\n",
       "   1)),\n",
       " ('drum',\n",
       "  ('global structure-aware drum transcription based on self-attention mechanisms',\n",
       "   1,\n",
       "   1)),\n",
       " ('attention:',\n",
       "  ('grid partitioned attention: efficient transformerapproximation with inductive bias for high resolution detail generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   1,\n",
       "   1)),\n",
       " ('current',\n",
       "  ('h9 and h10 transformer-less solar photovoltaic inverters for leakage current suppression and harmonic current reduction',\n",
       "   2,\n",
       "   1)),\n",
       " ('features',\n",
       "  ('hcit: deepfake video detection using a hybrid model of cnn features and vision transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('unsupervised',\n",
       "  ('hierarchical transformer: unsupervised representation learning for skeleton-based human action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('how many layers and why? an analysis of the model depth in transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('dialogue',\n",
       "  ('hsan: a hierarchical self-attention network for multi-turn dialogue generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('sms',\n",
       "  ('hybrid cnn-gru framework with integrated pre-trained language transformer for sms phishing detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('image captioning in hindi language using transformer networks', 1, 1)),\n",
       " ('transformers',\n",
       "  ('image captioning using multiple transformers for self-attention mechanism',\n",
       "   1,\n",
       "   1)),\n",
       " ('probability',\n",
       "  ('interval fuzzy probability method for power transformer multiple fault diagnosis',\n",
       "   1,\n",
       "   1)),\n",
       " ('lexically-aware',\n",
       "  ('lbert: lexically-aware transformers based bidirectional encoder representation model for learning universal bio-entity relations',\n",
       "   1,\n",
       "   1)),\n",
       " ('hyperspectral',\n",
       "  ('learning a 3d-cnn and transformer prior for hyperspectral image super-resolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('features',\n",
       "  ('legal text classification and summarization using transformers and joint text features',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('lightweight causal transformer with local self-attention for real-time speech enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('locating inter-turn faults in transformer windings using isometric feature mapping of frequency response traces',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('ma-bert: learning representation by incorporating multi-attribute knowledge in transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('mask-guided spectral-wise transformer for efficient hyperspectral image reconstruction',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('measurement of very fast transient overvoltages in current transformers at open air hv substations',\n",
       "   1,\n",
       "   1)),\n",
       " ('cross-transformer',\n",
       "  ('mect: multi-metadata embedding based cross-transformer for chinese named entity recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('memory-efficient',\n",
       "  ('memory-efficient transformers via top-k attention', 1, 1)),\n",
       " ('trilinear',\n",
       "  ('mirtt: learning multimodal interaction representations from trilinear transformers for visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('modeling of cross-circulating currents in a mmc with parallel connected submodules in solid state transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('biomedical',\n",
       "  ('multi-compound transformer for accurate biomedical image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('multi-modal fusion transformer for end-to-end autonomous driving', 1, 1)),\n",
       " ('for',\n",
       "  ('multi-transformer: a new neural network-based architecture for forecasting sandp volatility',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('multilevel inverter with a new modulation method applied to solid-state transformer in pv applications',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   1,\n",
       "   1)),\n",
       " ('smart',\n",
       "  ('new operation opportunities for the solid-state transformer in smart homes: a comprehensive analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('nlp',\n",
       "  (\"noisy text data: achilles' heel of popular transformer based nlp models\",\n",
       "   1,\n",
       "   1)),\n",
       " ('removal',\n",
       "  ('non-local self-attention mechanism for real-time context embedding deep shadow removal network',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('noninvasive self-attention for side information fusion in sequential recommendation',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-agent',\n",
       "  ('offline pre-trained multi-agent decision transformer: one big sequence model tackles all smac tasks',\n",
       "   1,\n",
       "   1)),\n",
       " ('attention-based',\n",
       "  ('on exploring attention-based explanation for transformer models in text classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('on improving adversarial transferability of vision transformers', 1, 1)),\n",
       " ('speech',\n",
       "  ('on-device streaming transformer-based end-to-end speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('re-identification',\n",
       "  ('person re-identification with a locally aware transformer', 1, 1)),\n",
       " ('position-informed',\n",
       "  ('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('poat-net:',\n",
       "  ('poat-net: parallel offset-attention assisted transformer for 3d object detection for autonomous driving',\n",
       "   1,\n",
       "   1)),\n",
       " ('(roger',\n",
       "  ('power transformer faults diagnosis using undestructive methods (roger and iec) and artificial neural network for dissolved gas analysis applied on the functional transformer in the algerian north-eastern: a comparative study',\n",
       "   1,\n",
       "   1)),\n",
       " ('domain', ('pre-training transformers for domain adaptation', 1, 1)),\n",
       " ('image',\n",
       "  ('rams-trans: recurrent attention multi-scale transformer for fine-grained image recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('real-time',\n",
       "  ('real-time prediction of ocean observation data based on transformer model',\n",
       "   1,\n",
       "   1)),\n",
       " ('sensing',\n",
       "  ('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('representation',\n",
       "  ('representation learning for neural population activity with neural data transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('rethinking skip connection with layer normalization in transformers and resnets',\n",
       "   1,\n",
       "   1)),\n",
       " ('field',\n",
       "  ('robustness evaluation of transformer-based form field extractors via form attacks',\n",
       "   1,\n",
       "   1)),\n",
       " ('rpt:',\n",
       "  ('rpt: relational pre-trained transformer is almost all you need towards democratizing data preparation',\n",
       "   1,\n",
       "   1)),\n",
       " ('sequence-to-sequence',\n",
       "  ('s2s-ft: fine-tuning pretrained transformer encoders for sequence-to-sequence learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('using',\n",
       "  ('security requirements classification into groups using nlp transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('visual',\n",
       "  ('self-adaptive neural module transformer for visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('semi-supervised graph instance transformer for mental health inference',\n",
       "   1,\n",
       "   1)),\n",
       " ('are',\n",
       "  ('soft sensing transformer: hundreds of sensors are worth a single word',\n",
       "   2,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('spatio-temporal self-attention network for video saliency prediction',\n",
       "   1,\n",
       "   1)),\n",
       " ('spectr:',\n",
       "  ('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('speech emotion recognition using recurrent neural networks with directional self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('data',\n",
       "  ('stabilizing deep q-learning with convnets and vision transformers under data augmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('study on operation parameter characteristics of induction filter distribution transformer in low-voltage distribution network',\n",
       "   1,\n",
       "   1)),\n",
       " ('trillion',\n",
       "  ('switch transformers: scaling to trillion parameter models with simple and efficient sparsity',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('target-specified sequence labeling with multi-head self-attention for target-oriented opinion words extraction',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('tbn-vit: temporal bilateral network with vision transformer for video scene parsing',\n",
       "   1,\n",
       "   1)),\n",
       " ('@finsim-2:',\n",
       "  ('tcs_witm_2021 @finsim-2: transformer based models for automatic classification of financial terms',\n",
       "   1,\n",
       "   1)),\n",
       " ('template', ('template filling with generative transformers', 1, 1)),\n",
       " ('prediction',\n",
       "  ('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "   1,\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('the layout generation algorithm of graphic design based on transformer-cvae',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('the neural data router: adaptive control flow in transformers improves systematic generalization',\n",
       "   1,\n",
       "   1)),\n",
       " ('accuracy',\n",
       "  ('token labeling: training a 85.4% top-1 accuracy vision transformer with 56m parameters on imagenet',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('too much in common: shifting of embeddings in transformer language models and its implications',\n",
       "   1,\n",
       "   1)),\n",
       " ('comprehensive',\n",
       "  ('towards a comprehensive understanding and accurate evaluation of societal biases in pre-trained transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('image',\n",
       "  ('towards end-to-end image compression and analysis with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('towards explainable end-to-end prostate cancer relapse prediction from hande images combining self-attention multiple instance learning with a recurrent neural network',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer:',\n",
       "  ('trading with the momentum transformer: an intelligent and interpretable architecture',\n",
       "   1,\n",
       "   1)),\n",
       " ('ais',\n",
       "  ('traisformer-a generative transformer for ais trajectory prediction',\n",
       "   1,\n",
       "   1)),\n",
       " ('trans4trans:',\n",
       "  ('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('transformation of transient overvoltages by inductive voltage transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('transformer ensemble system for detection of offensive content in dravidian languages',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based approaches for personality detection using the mbti model',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('transformer-based korean pretrained language models: a survey on three years of progress',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('transformer-based long-term viewport prediction in 360° video: scanpath is all you need',\n",
       "   1,\n",
       "   1)),\n",
       " ('eligibility',\n",
       "  ('transformer-based named entity recognition for parsing clinical trial eligibility criteria',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transmorph: transformer for unsupervised medical image registration',\n",
       "   1,\n",
       "   1)),\n",
       " ('flow',\n",
       "  ('trufm: a transformer-guided framework for fine-grained urban flow inference',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('tsdae: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('block-online',\n",
       "  ('tunet: a block-online bandwidth extension model based on transformers and self-supervised pretraining',\n",
       "   1,\n",
       "   1)),\n",
       " ('to',\n",
       "  ('turkish text classification: from lexicon analysis to bidirectional transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision-language',\n",
       "  ('ufo: a unified transformer for vision-language representation learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('umuteam at exist 2021: sexist language identification based on linguistic features and transformers in spanish and english',\n",
       "   1,\n",
       "   1)),\n",
       " ('bot', ('understanding transformers for bot detection in twitter', 1, 1)),\n",
       " ('joint-flexible',\n",
       "  ('unsupervised cross-domain person re-identification with self-attention and joint-flexible optimization',\n",
       "   1,\n",
       "   1)),\n",
       " ('production',\n",
       "  ('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   1,\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('using recurrent neural network structure with enhanced multi-head self-attention for sentiment analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('video background music generation with controllable music transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision', ('vivit: a video vision transformer', 1, 1)),\n",
       " ('image',\n",
       "  ('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   1,\n",
       "   1)),\n",
       " ('word', ('w-core transformer model for chinese word segmentation', 1, 1)),\n",
       " ('importance',\n",
       "  ('what helps transformers recognize conversational structure? importance of context, punctuation, and labels in dialog act recognition',\n",
       "   2,\n",
       "   1)),\n",
       " ('sensing',\n",
       "  ('wifimod: transformer-based indoor human mobility modeling using passive sensing',\n",
       "   2,\n",
       "   1)),\n",
       " ('pixel',\n",
       "  ('word2pix: word to pixel cross attention transformer in visual grounding',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('x-volution: on the unification of convolution and self-attention', 1, 1)),\n",
       " ('text',\n",
       "  ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "   1,\n",
       "   1)),\n",
       " ('new',\n",
       "  ('a new method for transformer fault prediction based on multifeature enhancement and refined long short-term memory',\n",
       "   1,\n",
       "   1)),\n",
       " ('wave',\n",
       "  ('a new method of wave parameter retrieve based on transformer', 1, 1)),\n",
       " ('2d',\n",
       "  ('a transformer architecture based on bert and 2d convolutional neural network to identify dna enhancers from sequence information',\n",
       "   1,\n",
       "   1)),\n",
       " ('high',\n",
       "  ('a transformer with high coupling coefficient and small area based on tsv',\n",
       "   1,\n",
       "   1)),\n",
       " ('differential',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1,\n",
       "   1)),\n",
       " ('adversarial',\n",
       "  ('adversarial attacks on kinship verification using transformer', 1, 1)),\n",
       " ('obscure',\n",
       "  ('all bark and no bite: rogue dimensions in transformer language models obscure representational quality',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('an explainable transformer-based deep learning model for the prediction of incident heart failure',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('analyzing covid-19 tweets with transformer-based language models', 1, 1)),\n",
       " ('microorganism',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('multilayer',\n",
       "  ('applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('zero-shot',\n",
       "  ('ask2transformers: zero-shot domain labelling with pretrained language models',\n",
       "   1,\n",
       "   1)),\n",
       " ('prediction',\n",
       "  ('attendaffectnet-emotion prediction of movie viewers using multimodal fusion with self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('video',\n",
       "  ('attention distillation for detection transformers: application to real-time video object detection in ultrasound',\n",
       "   1,\n",
       "   1)),\n",
       " ('design',\n",
       "  ('autotrans: automating transformer design via reinforced architecture search',\n",
       "   1,\n",
       "   1)),\n",
       " ('shap',\n",
       "  ('bert meets shapley: extending shap explanations to transformer-based classifiers',\n",
       "   1,\n",
       "   1)),\n",
       " ('arabic',\n",
       "  ('bert transformer model for detecting arabic gpt2 auto-generated tweets',\n",
       "   1,\n",
       "   1)),\n",
       " ('distribution',\n",
       "  ('black-hole optimization applied to the parametric estimation in distribution transformers considering voltage and current measures',\n",
       "   1,\n",
       "   1)),\n",
       " ('signals',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('bornon: bengali image captioning with transformer-based deep learning approach',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-winding',\n",
       "  ('calculation of error of multi-winding voltage transformer under arbitrary secondary load by determinant method',\n",
       "   1,\n",
       "   1)),\n",
       " ('can',\n",
       "  ('can the transformer be used as a drop-in replacement for rnns in text-generating gans?',\n",
       "   1,\n",
       "   1)),\n",
       " ('modeling',\n",
       "  ('combining rnn with transformer for modeling multi-leg trips', 1, 1)),\n",
       " ('converter',\n",
       "  ('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('considering nested tree structure in sentence extractive summarization with pre-trained transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('processing',\n",
       "  ('constrained transformer network for ecg signal processing and arrhythmia classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('sign',\n",
       "  ('context matters: self-attention for sign language recognition', 1, 1)),\n",
       " ('convolution',\n",
       "  ('contnet: why not use convolution and transformer at the same time?',\n",
       "   1,\n",
       "   1)),\n",
       " ('controllable',\n",
       "  ('controllable sentence simplification with a unified text-to-text transfer transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('convdysat:',\n",
       "  ('convdysat: deep neural representation learning on dynamic graphs via self-attention and convolutional neural networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('graphs',\n",
       "  ('conversational question answering over knowledge graphs with transformer and graph attention networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('cotr: correspondence transformer for matching across images', 1, 1)),\n",
       " ('transformer',\n",
       "  ('cross-lingual hate speech detection using transformer models', 1, 1)),\n",
       " ('transformers',\n",
       "  ('cvt: introducing convolutions to vision transformers', 1, 1)),\n",
       " ('convolutional',\n",
       "  ('dapnet: a double self-attention convolutional network for point cloud semantic labeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('dct:',\n",
       "  ('dct: dynamic compressive transformer for modeling unbounded sequence',\n",
       "   1,\n",
       "   1)),\n",
       " ('method',\n",
       "  ('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   1,\n",
       "   1)),\n",
       " ('current',\n",
       "  ('design and performance study of a temperature compensated ±1100-kv uhvdc all fiber current transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('diagnosing transformers in task-oriented semantic parsing', 1, 1)),\n",
       " ('for',\n",
       "  ('directional graph transformer-based control flow embedding for malware classification',\n",
       "   1,\n",
       "   1)),\n",
       " (\"don't\",\n",
       "  (\"don't shoot butterfly with rifles: multi-channel continuous speech separation with early exit transformer\",\n",
       "   1,\n",
       "   1)),\n",
       " ('answering',\n",
       "  ('dual self-attention with co-attention networks for visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer', ('dual transformer for point cloud analysis', 1, 1)),\n",
       " ('recognition',\n",
       "  ('dualformer: local-global stratified transformer for efficient video recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('eeg',\n",
       "  ('eeg-convtransformer for single-trial eeg based visual stimuli classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('high',\n",
       "  ('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('efficient transformer based method for remote sensing image change detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   2,\n",
       "   1)),\n",
       " ('insensitive',\n",
       "  ('emotional robbert and insensitive bertje: combining transformers and affect lexica for dutch emotion detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('end-to-end spoken language understanding using transformer networks and self-supervised pre-trained features',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('enhancing transformer with horizontal and vertical guiding mechanisms for neural language modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('enhancing transformers with gradient boosted decision trees for nli fine-tuning',\n",
       "   1,\n",
       "   1)),\n",
       " ('the',\n",
       "  ('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   1,\n",
       "   1)),\n",
       " ('inter-resonance',\n",
       "  ('evaluating the inter-resonance characteristics of various power transformer winding designs',\n",
       "   1,\n",
       "   1)),\n",
       " ('univariate',\n",
       "  ('evaluation of the transformer architecture for univariate time series forecasting',\n",
       "   1,\n",
       "   1)),\n",
       " ('synthetic',\n",
       "  ('experimental validation of a method of drying cellulose insulation in distribution transformers using circulating synthetic ester',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('exploring a unified sequence-to-sequence transformer for medical product safety monitoring in social media',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('exploring multi-task multi-lingual learning of transformer models for hate speech and offensive speech identification in social media',\n",
       "   2,\n",
       "   1)),\n",
       " ('makeup',\n",
       "  ('facial attribute transformers for precise and robust makeup transfer',\n",
       "   1,\n",
       "   1)),\n",
       " ('using',\n",
       "  ('fad-bert: improved prediction of fad binding sites using pre-training of deep bidirectional transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('catboost',\n",
       "  ('fault diagnosis of oil-immersed power transformer based on difference-mutation brain storm optimized catboost model',\n",
       "   1,\n",
       "   1)),\n",
       " ('combination',\n",
       "  ('feature combination meets attention: baidu soccer embeddings and transformer based temporal detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('federal learning based covid-19 fake news detection with deep self-attention network',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "   1,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('fine-tuning vision transformers for the prediction of state variables in ising models',\n",
       "   1,\n",
       "   1)),\n",
       " ('social',\n",
       "  ('fnr: a similarity and transformer-based approach to detect multi-modal fake news in social media',\n",
       "   1,\n",
       "   1)),\n",
       " ('attention',\n",
       "  ('focal attention for long-range interactions in vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('bidirectional',\n",
       "  ('front-end bidirectional symmetric bipolar outputs llc dc-transformer (dcx) for a half bridge class-d audio amplifier',\n",
       "   1,\n",
       "   1)),\n",
       " ('protein',\n",
       "  ('geometric transformers for protein interface contact prediction', 1, 1)),\n",
       " ('microscopy',\n",
       "  ('global voxel transformer networks for augmented microscopy', 1, 1)),\n",
       " ('model',\n",
       "  ('grasping or forgetting? makt: a dynamic model via multi-head self-attention for knowledge tracing',\n",
       "   1,\n",
       "   1)),\n",
       " ('guiding',\n",
       "  ('guiding query position and performing similar attention for transformer-based detection heads',\n",
       "   1,\n",
       "   1)),\n",
       " ('accurate',\n",
       "  ('hi-behrt: hierarchical transformer-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('identify hate speech spreaders on twitter using transformer embeddings features and automl classifiers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('improved transformer net for hyperspectral image classification', 1, 1)),\n",
       " ('mechanism',\n",
       "  ('incorporating sentimental trend into gated mechanism based transformer network for story ending generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('state',\n",
       "  ('incorporating transformer and lstm to kalman filter with em algorithm for state estimation',\n",
       "   1,\n",
       "   1)),\n",
       " ('induced',\n",
       "  ('induced local attention for transformer models in speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance',\n",
       "   1,\n",
       "   1)),\n",
       " ('yolov3',\n",
       "  ('integrate yolov3 with a self-attention mechanism for underwater object detection based on forward-looking sonar images',\n",
       "   1,\n",
       "   1)),\n",
       " ('signals:',\n",
       "  ('introducing attention mechanism for eeg signals: emotion recognition with vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('energy',\n",
       "  ('irene-viz: visualizing energy consumption of transformer models', 1, 1)),\n",
       " ('with',\n",
       "  ('korean grammatical error correction based on transformer with copying mechanisms and grammatical noise implantation methods',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('learning attributed graph representation with communicative message passing transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('loss',\n",
       "  ('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "   1,\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('learning dynamic and hierarchical traffic spatiotemporal features with transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('field', ('light field image super-resolution with transformers', 1, 1)),\n",
       " ('moment',\n",
       "  ('locformer: enabling transformers to perform temporal moment localization on long untrimmed videos with a feature sampling approach',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('long-short transformer: efficient transformers for language and vision',\n",
       "   1,\n",
       "   1)),\n",
       " ('two',\n",
       "  ('looking beyond two frames: end-to-end multi-object tracking using spatial and temporal transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('low-dimensional depth local dual-view features embedded transformer for electrocardiogram signal quality assessment',\n",
       "   1,\n",
       "   1)),\n",
       " ('text',\n",
       "  ('match-ignition: plugging pagerank into transformer for long-form text matching',\n",
       "   2,\n",
       "   1)),\n",
       " ('of',\n",
       "  ('measuring harmonics with inductive voltage transformers in presence of subharmonics',\n",
       "   1,\n",
       "   1)),\n",
       " ('video',\n",
       "  ('multimodal video summarization via time-aware transformers', 1, 1)),\n",
       " ('on',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1,\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('named entity recognition and relation extraction for covid-19: explainable active learning with word2vec embeddings and transformer-based bert models',\n",
       "   1,\n",
       "   1)),\n",
       " ('text',\n",
       "  ('neural transfer learning with transformers for social science text analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('model',\n",
       "  ('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "   1,\n",
       "   1)),\n",
       " ('sequential',\n",
       "  ('non-invasive self-attention for side information fusion in sequential recommendation',\n",
       "   1,\n",
       "   1)),\n",
       " ('based', ('oriented target detection algorithm based on transformer', 1, 1)),\n",
       " ('distributed',\n",
       "  ('pipetransformer: automated elastic pipelining for distributed training of transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('pose transformers (potr): human motion prediction with non-autoregressive transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('recurrent',\n",
       "  ('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   1,\n",
       "   1)),\n",
       " ('nlp',\n",
       "  ('pruning attention heads of transformer models using a* search: a novel approach to compress big nlp architectures',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('pyramid medical transformer for medical image segmentation', 1, 1)),\n",
       " ('segmentation',\n",
       "  ('pyramid medical transformer for medical image segmentation', 1, 1)),\n",
       " ('quantitative',\n",
       "  ('quantitative analysis and simple monitoring for partial discharge from transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('contextualized',\n",
       "  ('question classification using universal sentence encoder and deep contextualized transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('retrieval-augmented',\n",
       "  ('retrieval-augmented transformer-xl for close-domain dialog generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('robustness',\n",
       "  ('reveal of vision transformers robustness against adversarial attacks',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('roma at semeval-2021 task 7: a transformer-based approach for detecting and rating humor and offense',\n",
       "   2,\n",
       "   1)),\n",
       " ('text-to-image',\n",
       "  ('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   1,\n",
       "   1)),\n",
       " ('languages',\n",
       "  ('self-attention networks can process bounded hierarchical languages',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('short and long range relation based spatio-temporal transformer for micro-expression recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('siamese',\n",
       "  ('siamese transformer pyramid networks for real-time uav tracking', 1, 1)),\n",
       " ('with',\n",
       "  ('simpler is better: few-shot semantic segmentation with classifier weight transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('spam',\n",
       "  ('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('social network spam detection based on albert and combination of bi-lstm with self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('complexity',\n",
       "  ('soft: softmax-free transformer with linear complexity', 1, 1)),\n",
       " ('self-attention',\n",
       "  ('starnet: joint action-space prediction with star graphs and implicit global frame self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('query',\n",
       "  ('structure-aware parameter-free group query via heterogeneous information network transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('tightly-coupled',\n",
       "  ('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   1,\n",
       "   1)),\n",
       " ('how',\n",
       "  ('teach me how to label: labeling functions from natural language with text-to-text transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('temporal',\n",
       "  ('temporal attention augmented transformer hawkes process', 1, 1)),\n",
       " ('awake',\n",
       "  ('temporal convolutional networks and transformers for classifying the sleep stage in awake or asleep using pulse oximetry signals',\n",
       "   1,\n",
       "   1)),\n",
       " ('to',\n",
       "  ('tfix: learning to fix coding errors with a text-to-text transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('the',\n",
       "  ('the joy of dressing is an art: outfit generation using self-attention bi-lstm',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('trankit: a light-weight transformer-based toolkit for multilingual natural language processing',\n",
       "   1,\n",
       "   1)),\n",
       " ('u-net',\n",
       "  ('transattunet: multi-level attention-guided u-net with transformer for medical image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transfer:',\n",
       "  ('transfer: learning relation-aware facial expression representations with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('awareness',\n",
       "  ('transformer meets convolution: a bilateral awareness net-work for semantic segmentation of very fine resolution ur-ban scene images',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based behavioral representation learning enables transfer learning for mobile sensing in small datasets',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('transformer-based deep image matching for generalizable person re-identification',\n",
       "   1,\n",
       "   1)),\n",
       " ('media',\n",
       "  ('transformer-based extractive social media question answering on tweetqa',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-style',\n",
       "  ('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformers pipeline for offensiveness detection in mexican spanish social media',\n",
       "   1,\n",
       "   1)),\n",
       " ('compact',\n",
       "  ('transmask: a compact and fast speech separation model based on transformer',\n",
       "   2,\n",
       "   1)),\n",
       " ('attribute-guided',\n",
       "  ('transzero++: cross attribute-guided transformer for zero-shot learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('trar: routing the attention spans in transformer for visual question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('uformer: a general u-shaped transformer for image restoration', 1, 1)),\n",
       " ('for',\n",
       "  ('unified transformer multi-task learning for intent classification with entity recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('high-resolution',\n",
       "  ('unleashing transformers: parallel token prediction with discrete absorbing diffusion for fast high-resolution image generation from vector-quantized codes',\n",
       "   1,\n",
       "   1)),\n",
       " ('unaligned',\n",
       "  ('vidface: a full-transformer solver for video facehallucination with unaligned tiny snapshots',\n",
       "   1,\n",
       "   1)),\n",
       " ('are',\n",
       "  ('viesum: how robust are transformer-based models on vietnamese summarization?',\n",
       "   1,\n",
       "   1)),\n",
       " ('feature',\n",
       "  ('vision transformer for covid-19 cxr diagnosis using chest x-ray feature corpus',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision', ('vision transformers are robust learners', 1, 1)),\n",
       " ('vortx:',\n",
       "  ('vortx: volumetric 3d reconstruction with transformers for voxelwise view selection and fusion',\n",
       "   1,\n",
       "   1)),\n",
       " ('3d-anas',\n",
       "  ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('grounding',\n",
       "  ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   1,\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "   1,\n",
       "   1)),\n",
       " ('fault',\n",
       "  ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformerless',\n",
       "  ('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "   1,\n",
       "   1)),\n",
       " ('clustering', ('a novel self-attention deep subspace clustering', 1, 1)),\n",
       " ('spectrogram',\n",
       "  ('a self-attention-based ensemble convolution neural network approach for sleep stage classification with merged spectrogram',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a simple single-scale vision transformer for object localization and instance segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('a transformer model-based approach to bearing fault diagnosis', 1, 1)),\n",
       " ('handwritten',\n",
       "  ('a transformer-based math language model for handwritten math expression recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('frequency',\n",
       "  ('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   1,\n",
       "   1)),\n",
       " ('principle',\n",
       "  ('accuracy improvement of power transformer faults diagnostic using knn classifier with decision tree principle',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('ai-upv at iberlef-2021 detoxis task: toxicity detection in immigration-related web news comments using transformers and statistical models',\n",
       "   1,\n",
       "   1)),\n",
       " ('hierarchical',\n",
       "  ('an emd-based method for the detection of power transformer faults with a hierarchical ensemble classifier',\n",
       "   1,\n",
       "   1)),\n",
       " ('an',\n",
       "  ('an end-to-end speech accent recognition method based on hybrid ctc/attention transformer asr',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('an ultrawide output range ${llc}$ resonant converter based on adjustable turns ratio transformer and reconfigurable bridge',\n",
       "   1,\n",
       "   1)),\n",
       " ('analysis',\n",
       "  ('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   1,\n",
       "   1)),\n",
       " ('agreement',\n",
       "  ('are transformers a modern version of eliza? observations on french object verb agreement',\n",
       "   1,\n",
       "   1)),\n",
       " ('efficiently',\n",
       "  ('ast-transformer: encoding abstract syntax trees efficiently for code summarization',\n",
       "   1,\n",
       "   1)),\n",
       " ('adaptive',\n",
       "  ('augmented transformer with adaptive graph for temporal action proposal generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('automatic fake news detection in urdu language using transformers', 1, 1)),\n",
       " ('medium',\n",
       "  ('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('deinterleaving',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('blind deinterleaving of signals in time series with self-attention based soft min-cost flow learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('object',\n",
       "  ('boosting salient object detection with transformer-based asymmetric bilateral u-net',\n",
       "   1,\n",
       "   1)),\n",
       " ('sparse',\n",
       "  ('building extraction from remote sensing images with sparse token transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('cae-transformer: transformer-based model to predict invasiveness of lung adenocarcinoma subsolid nodules from non-thin section 3d ct scans',\n",
       "   1,\n",
       "   1)),\n",
       " ('pre-trained',\n",
       "  ('can pre-trained transformers be used in detecting complex sensitive sentences? - a monsanto case study',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('can the transformer learn nested recursion with symbol masking?', 1, 1)),\n",
       " ('point',\n",
       "  ('candidate point selection using a self-attention mechanism for generating a smooth volatility surface under the sabr model',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('context-aware positional representation for self-attention networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('recognition',\n",
       "  ('cross-view gait recognition using pairwise spatial transformer networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('counting',\n",
       "  ('crowd counting method based on the self-attention residual network',\n",
       "   1,\n",
       "   1)),\n",
       " ('x-rays',\n",
       "  ('ct-cad: context-aware transformers for end-to-end chest abnormality detection on x-rays',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('data transformer for anomalous trajectory detection', 1, 1)),\n",
       " ('features',\n",
       "  ('deep features fusion with mutual attention transformer for skin lesion diagnosis',\n",
       "   1,\n",
       "   1)),\n",
       " ('convolutional',\n",
       "  ('deeppppred: deep ensemble learning with transformers, recurrent and convolutional neural networks for human protein-phenotype co-mention classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('natural',\n",
       "  ('dementia detection using transformer-based deep learning and natural language processing models',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('detecting covid-19 conspiracy theories with transformers and tf-idf',\n",
       "   1,\n",
       "   1)),\n",
       " ('disturbance',\n",
       "  ('disturbance rejection and harmonic mitigation for solid state transformer through passivity based control',\n",
       "   1,\n",
       "   1)),\n",
       " ('multimodal',\n",
       "  ('dsamt: dual-source aligned multimodal transformers for textcaps', 1, 1)),\n",
       " ('classification',\n",
       "  ('dual-axial self-attention network for text classification', 1, 1)),\n",
       " ('efficient',\n",
       "  ('e-dssr: efficient dynamic surgical scene reconstruction with transformer-based stereoscopic depth perception',\n",
       "   1,\n",
       "   1)),\n",
       " ('from',\n",
       "  ('eeg-transformer: self-attention from transformer architecture for decoding eeg of imagined speech',\n",
       "   1,\n",
       "   1)),\n",
       " ('tracking',\n",
       "  ('efficient dialogue state tracking by masked hierarchical transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('efficient transformer based method for remote sensing image change detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('erratum to: evotuning protocols for transformer-based variant effect prediction on multi-domain proteins',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('evaluating transformer based semantic segmentation networks for pathological image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra',\n",
       "   1,\n",
       "   1)),\n",
       " ('oil-paper',\n",
       "  ('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "   1,\n",
       "   1)),\n",
       " ('augmented',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  (\"from augmented microscopy to the topological transformer: a new approach in cell image analysis for alzheimer's research\",\n",
       "   1,\n",
       "   1)),\n",
       " ('multimodal',\n",
       "  ('from multimodal to unimodal attention in transformers using knowledge distillation',\n",
       "   1,\n",
       "   1)),\n",
       " ('local',\n",
       "  ('glit: neural architecture search for global and local image transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('priors',\n",
       "  ('global context and geometric priors for effective non-local self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('going beyond linear transformers with recurrent fast weight programmers',\n",
       "   1,\n",
       "   1)),\n",
       " ('decreasing',\n",
       "  ('greedy layer pruning: decreasing inference time of transformer models',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('grtr: generative-retrieval transformers for data-efficient dialogue domain adaptation',\n",
       "   1,\n",
       "   1)),\n",
       " ('using', ('gtn-ed: event detection using graph transformer networks', 1, 1)),\n",
       " ('a',\n",
       "  ('heterogeneous transformer: a scale adaptable neural network architecture for device activity detection',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('improved',\n",
       "  ('improved biomedical word embeddings in the transformer era', 1, 1)),\n",
       " ('for',\n",
       "  ('improving the efficiency of transformers for resource-constrained devices',\n",
       "   1,\n",
       "   1)),\n",
       " ('instance-based',\n",
       "  ('instance-based vision transformer for subtyping of papillary renal cell carcinoma in histopathological image',\n",
       "   2,\n",
       "   1)),\n",
       " ('ipe',\n",
       "  ('ipe transformer for depth completion with input-aware positional embeddings',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('joint intention and trajectory prediction based on transformer', 1, 1)),\n",
       " ('rnn', ('last query transformer rnn for knowledge tracing', 1, 1)),\n",
       " ('modeling',\n",
       "  ('layer-wise pruning of transformer attention heads for efficient language modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('absolute',\n",
       "  ('learning multi-scene absolute pose regression with transformers', 1, 1)),\n",
       " ('devices',\n",
       "  ('lightweight url-based phishing detection using natural language processing transformers for mobile devices',\n",
       "   1,\n",
       "   1)),\n",
       " ('lightxml:',\n",
       "  ('lightxml: transformer with dynamic negative sampling for high-performance extreme multi-label text classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('environment',\n",
       "  ('load balancing optimization for transformer in distributed environment',\n",
       "   1,\n",
       "   1)),\n",
       " ('long-span',\n",
       "  ('long-span dependencies in transformer-based summarization systems', 1, 1)),\n",
       " ('detection',\n",
       "  ('malbert: malware detection using bidirectional encoder representations from transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('augmented',\n",
       "  ('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('meta-context transformers for domain-specific response generation', 1, 1)),\n",
       " ('for',\n",
       "  ('mhformer: multi-hypothesis transformer for 3d human pose estimation',\n",
       "   1,\n",
       "   1)),\n",
       " ('acquisition',\n",
       "  ('modeling age of acquisition norms using transformer networks', 1, 1)),\n",
       " ('feature',\n",
       "  ('monte carlo denoising via auxiliary feature guided self-attention', 1, 1)),\n",
       " ('masked',\n",
       "  ('mst: masked self-supervised transformer for visual representation', 1, 1)),\n",
       " ('transformer',\n",
       "  ('multi-level convolutional transformer with adaptive ranking for semi-supervised crowd counting',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('multi-stage aggregated transformer network for temporal language localization in videos',\n",
       "   1,\n",
       "   1)),\n",
       " ('nn',\n",
       "  ('multilingual pre-trained transformers and convolutional nn classification models for technical domain identification',\n",
       "   1,\n",
       "   1)),\n",
       " ('single-channel',\n",
       "  ('noise robust acoustic modeling for single-channel speech recognition based on a stream-wise transformer architecture',\n",
       "   1,\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('non-autoregressive transformer with unified bidirectional decoder for automatic speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('nystroumlmformer: a nystroumlm-based algorithm for approximating self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('microgrid',\n",
       "  ('optimized active power management in solar pv-fed transformerless grid-connected system for rural electrified microgrid',\n",
       "   1,\n",
       "   1)),\n",
       " ('software',\n",
       "  ('pasta: synthesizing object state transformers for dynamic software updates',\n",
       "   1,\n",
       "   1)),\n",
       " ('to',\n",
       "  ('paying attention to astronomical transients: photometric classification with the time-series transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   1,\n",
       "   1)),\n",
       " ('convolution',\n",
       "  ('pisltrc: position-informed sign language transformer with content-aware convolution',\n",
       "   1,\n",
       "   1)),\n",
       " ('sample', ('pixeltransformer: sample conditioned signal generation', 1, 1)),\n",
       " ('point', ('point cloud learning with transformer', 1, 1)),\n",
       " ('for',\n",
       "  ('pre-training transformer-based framework on large-scale pediatric claims data for downstream population-specific tasks',\n",
       "   1,\n",
       "   1)),\n",
       " ('encoder',\n",
       "  ('probing word translations in the transformer and trading decoder for encoder layers',\n",
       "   1,\n",
       "   1)),\n",
       " ('microwave',\n",
       "  ('programmable integrated microwave photonic filter using a modulation transformer and a double-injection ring resonator',\n",
       "   1,\n",
       "   1)),\n",
       " ('baselines',\n",
       "  ('pvtv2: improved baselines with pyramid vision transformer', 1, 1)),\n",
       " ('recursive',\n",
       "  ('r2d2: recursive transformer based on differentiable tree for interpretable hierarchical language modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('fusion',\n",
       "  ('ranked list fusion and re-ranking with pre-trained transformers for arqmath lab',\n",
       "   1,\n",
       "   1)),\n",
       " ('principle',\n",
       "  ('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('research on residual flux density measurement for single-phase transformer core based on energy changes',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  ('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   1,\n",
       "   1)),\n",
       " ('algorithm',\n",
       "  ('research on transformer fault diagnosis method based on neighborhood rough set and grey wolf algorithm optimized support vector machine',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('risk assessment algorithm for power transformer fleets based on condition and strategic importance',\n",
       "   1,\n",
       "   1)),\n",
       " ('frontend',\n",
       "  ('self-attention channel combinator frontend for end-to-end multichannel far-field speech recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('self-attention recurrent summarization network with reinforcement learning for video summarization task',\n",
       "   1,\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('self-attention-based deep feature fusion for remote sensing scene classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('sequential',\n",
       "  ('sequential recommendation with bidirectional chronological augmentation of transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-frame',\n",
       "  ('siamtrans: zero-shot multi-frame image restoration with pre-trained siamese transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('simulating reading mistakes for child speech transformer-based phone recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('single-read reconstruction for dna data storage using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('skyformer: remodel self-attention with gaussian kernel and nystr\\\\\"om method',\n",
       "   1,\n",
       "   1)),\n",
       " ('aggregation',\n",
       "  ('sparse self-attention aggregation networks for neural sequence slice interpolation',\n",
       "   1,\n",
       "   1)),\n",
       " ('sparta:',\n",
       "  ('sparta: efficient open-domain question answering via sparse transformer matching retrieval',\n",
       "   1,\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('spatial context-aware self-attention model for multi-organ segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('spatio-temporal action detector with self-attention', 1, 1)),\n",
       " ('transformer', ('spectral transform forms scalable transformer', 1, 1)),\n",
       " ('data',\n",
       "  ('spiking transformer networks: a rate coded approach for processing sequential data',\n",
       "   1,\n",
       "   1)),\n",
       " ('sting:',\n",
       "  ('sting: self-attention based time-series imputation networks using gan',\n",
       "   1,\n",
       "   1)),\n",
       " ('low',\n",
       "  ('synchronization of low voltage grids fed by smart and conventional transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('automated',\n",
       "  ('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('tabular transformers for modeling multivariate time series', 1, 1)),\n",
       " ('face',\n",
       "  ('tanet: a new paradigm for global face super-resolution via transformer-cnn aggregation network',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer', ('the image local autoregressive transformer', 2, 1)),\n",
       " ('of',\n",
       "  ('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   2,\n",
       "   1)),\n",
       " ('decoupling',\n",
       "  ('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "   1,\n",
       "   1)),\n",
       " ('answering',\n",
       "  ('towards a question answering assistant for software development using a transformer-based language model',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('transformer based refinement network for accurate crack detection', 1, 1)),\n",
       " ('image',\n",
       "  ('transformer with peak suppression and knowledge guidance for fine-grained image recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('recognition',\n",
       "  ('transformer-based approach towards music emotion recognition from lyrics',\n",
       "   2,\n",
       "   1)),\n",
       " ('at',\n",
       "  ('transformer-based language models for factoid question answering at bioasq9b',\n",
       "   1,\n",
       "   1)),\n",
       " ('3d',\n",
       "  ('transfusion: cross-view fusion with transformer for 3d human pose estimation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('translating classical chinese poetry into modern chinese with transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('weather',\n",
       "  ('transweather: transformer-based restoration of images degraded by adverse weather conditions',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('trocr: transformer-based optical character recognition with pre-trained models',\n",
       "   1,\n",
       "   1)),\n",
       " ('reverberant',\n",
       "  ('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   1,\n",
       "   1)),\n",
       " ('separation',\n",
       "  ('trunet: transformer-recurrent-u network for multi-channel reverberant sound source separation',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('uncertainty-based query strategies for active learning with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('bidirectional',\n",
       "  ('using event-based web-scraping methods and bidirectional transformers to characterize covid-19 outbreaks in food production and retail settings',\n",
       "   1,\n",
       "   1)),\n",
       " ('super-resolution',\n",
       "  ('video super-resolution based on spatial-temporal transformer', 1, 1)),\n",
       " ('convolutions', ('vidtr: video transformer without convolutions', 2, 1)),\n",
       " ('for',\n",
       "  ('visualsparta: sparse transformer fragment-level matching for large-scale text-to-image search',\n",
       "   1,\n",
       "   1)),\n",
       " ('from',\n",
       "  ('vit-p: classification of genitourinary syndrome of menopause from oct images based on vision transformer models',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('dbc/hz',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('smart',\n",
       "  ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "   1,\n",
       "   1)),\n",
       " ('to',\n",
       "  ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('a latent transformer for disentangled face editing in images and videos',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('segmentation',\n",
       "  ('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('linear',\n",
       "  ('a new gastric histopathology subsize image database (gashissdb) for classification algorithm test: from linear regression to visual transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('traffic',\n",
       "  ('a new method of hybrid time window embedding with transformer-based traffic data classification in iot-networked environment',\n",
       "   1,\n",
       "   1)),\n",
       " ('converter',\n",
       "  ('a novel leakage-current-based online insulation monitoring strategy for converter transformers using common-mode and differential-mode harmonics in vsc system',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a unified transformer-based framework for duplex text normalization',\n",
       "   1,\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('action segmentation on representations of skeleton sequences using transformer networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('fourier',\n",
       "  ('adaptive fourier neural operators: efficient token mixers for transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('all you can embed: natural language based vehicle retrieval with spatio-temporal transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('an efficient approach with application of linear and nonlinear models for evaluation of power transformer health index',\n",
       "   1,\n",
       "   1)),\n",
       " ('usage',\n",
       "  ('an empirical study on the usage of transformer models for code completion',\n",
       "   1,\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('an image change detection algorithm based on multi-feature self-attention fusion mechanism unet network',\n",
       "   1,\n",
       "   1)),\n",
       " ('voltage',\n",
       "  ('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   2,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('analytical calculation of magnetic field in fractional-slot windings linear phase-shifting transformer based on exact subdomain model',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('anchor detr: query design for transformer-based detector', 1, 1)),\n",
       " ('large',\n",
       "  ('arabictransformer: efficient large arabic language model with funnel transformer and electra objective',\n",
       "   1,\n",
       "   1)),\n",
       " ('human',\n",
       "  ('are convolutional neural networks or transformers more like human vision?',\n",
       "   1,\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('assessing the effectiveness of multilingual transformer-based text embeddings for named entity recognition in portuguese',\n",
       "   1,\n",
       "   1)),\n",
       " ('scene',\n",
       "  ('atiss: autoregressive transformers for indoor scene synthesis', 1, 1)),\n",
       " ('sampling',\n",
       "  ('ats: adaptive token sampling for efficient vision transformers', 1, 1)),\n",
       " ('with',\n",
       "  ('autogtco: graph and tensor co-optimize for image recognition with transformers on gpu',\n",
       "   1,\n",
       "   1)),\n",
       " ('models',\n",
       "  ('automatic sexism detection with multilingual transformer models ait fhstp@exist2021',\n",
       "   1,\n",
       "   1)),\n",
       " ('by',\n",
       "  ('beyond nystroumlmformer - approximation of self-attention by spectral shifting',\n",
       "   1,\n",
       "   1)),\n",
       " ('mechanism',\n",
       "  ('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   1,\n",
       "   1)),\n",
       " ('correction',\n",
       "  ('boost transformer with bert and copying mechanism for asr error correction',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('boosting inertial-based human activity recognition with transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('matrix',\n",
       "  ('breadth-first search leakage tolerant commutation method for matrix converters in three-phase solid state transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('classmates',\n",
       "  ('classmates enhanced diversity-self-attention network for dropout prediction in moocs',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers', ('code prediction by feeding trees to transformers', 1, 1)),\n",
       " ('of',\n",
       "  ('computational feasibility of multi-objective optimal design techniques for grid-connected multi-cell solid-state-transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('graph',\n",
       "  ('continuous-time sequential recommendation with temporal graph collaborative transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('language',\n",
       "  ('convolutions and self-attention: re-interpreting relative positions in pre-trained language models',\n",
       "   1,\n",
       "   1)),\n",
       " ('sequence-to-sequence',\n",
       "  ('crisis domain adaptation using sequence-to-sequence transformers', 1, 1)),\n",
       " ('dual',\n",
       "  ('cross-modal retrieval with dual multi-angle self-attention', 1, 1)),\n",
       " ('multibox',\n",
       "  ('cvt-assd: convolutional vision-transformer based attentive single shot multibox detector',\n",
       "   2,\n",
       "   1)),\n",
       " ('model',\n",
       "  ('cycletransgan-evc: a cyclegan-based emotional voice conversion model with transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('sequential',\n",
       "  ('deep self-attention for sequential recommendation (s)', 1, 1)),\n",
       " ('intelligent',\n",
       "  ('deephealth: a self-attention based method for instant intelligent predictive maintenance in industrial internet of things',\n",
       "   1,\n",
       "   1)),\n",
       " ('inductive',\n",
       "  ('design and optimization of 3-kw inductive power transfer charging system with compact asymmetric loosely coupled transformer for special applications',\n",
       "   1,\n",
       "   1)),\n",
       " ('design',\n",
       "  ('design and research of transformer fault diagnosis method based on data-driven',\n",
       "   1,\n",
       "   1)),\n",
       " ('speech',\n",
       "  ('df-conformer: integrated architecture of conv-tasnet and conformer using linear complexity self-attention for speech enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('controllable',\n",
       "  ('diverse single image generation with controllable global structure through self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('dnabert: pre-trained bidirectional encoder representations from transformers model for dna-language in genome',\n",
       "   1,\n",
       "   1)),\n",
       " ('information?',\n",
       "  ('do syntax trees help pre-trained transformers extract information?',\n",
       "   1,\n",
       "   1)),\n",
       " ('sentinel-2',\n",
       "  ('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "   1,\n",
       "   1)),\n",
       " ('u-net',\n",
       "  ('ds-transunet: dual swin transformer u-net for medical image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('graph', ('dynamic graph transformer for implicit tag recognition', 1, 1)),\n",
       " ('image',\n",
       "  ('efficient large-scale image retrieval with deep feature orthogonality and hybrid-swin-transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('and',\n",
       "  ('efficientnets and vision transformers for snake species identification using image and location information',\n",
       "   2,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('embodied bert: a transformer model for embodied, language-guided visual task completion',\n",
       "   1,\n",
       "   1)),\n",
       " ('detection',\n",
       "  ('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('emotion detection for spanish with data augmentation and transformer-based models',\n",
       "   1,\n",
       "   1)),\n",
       " ('vessel',\n",
       "  ('encoding-decoding network with pyramid self-attention module for retinal vessel segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer', ('end-to-end speaker diarization with transformer', 1, 1)),\n",
       " ('speaker-attributed',\n",
       "  ('end-to-end speaker-attributed asr with transformer', 1, 1)),\n",
       " ('location-guided',\n",
       "  ('end-to-end transformer-based open-vocabulary keyword spotting with location-guided local attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('video',\n",
       "  ('enhancing transformer for video understanding using gated multi-level attention and temporal adversarial training',\n",
       "   1,\n",
       "   1)),\n",
       " ('better',\n",
       "  ('enjoy the salience: towards better transformer-based faithful explanations with word salience',\n",
       "   1,\n",
       "   1)),\n",
       " ('entity',\n",
       "  ('evaluating pretrained transformer models for entity linking in task-oriented dialog',\n",
       "   1,\n",
       "   1)),\n",
       " ('local',\n",
       "  ('exploring neural language models via analysis of local and global self-attention spaces',\n",
       "   1,\n",
       "   1)),\n",
       " ('gpt,',\n",
       "  ('exploring transformers in natural language generation: gpt, bert, and xlnet',\n",
       "   1,\n",
       "   1)),\n",
       " ('networks',\n",
       "  ('fine-grained learning performance prediction via adaptive sparse self-attention networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('(english-hindi)',\n",
       "  ('fine-tuning pre-trained transformer based model for hate speech and offensive content identification in english indo-aryan and code-mixed (english-hindi) languages',\n",
       "   1,\n",
       "   1)),\n",
       " ('density-based',\n",
       "  ('geo-spatial market segmentation and characterization exploiting user generated text through transformers and density-based clustering',\n",
       "   1,\n",
       "   1)),\n",
       " ('clustered',\n",
       "  ('groupformer: group activity recognition with clustered spatial-temporal transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('environments',\n",
       "  ('hierarchical rnns-based transformers maddpg for mixed cooperative-competitive environments',\n",
       "   1,\n",
       "   1)),\n",
       " ('iou',\n",
       "  ('image captioning based on an improved transformer with iou position encoding',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('image-text alignment using adaptive cross-attention with transformer encoder for scene graphs',\n",
       "   1,\n",
       "   1)),\n",
       " ('thermal',\n",
       "  ('improving power losses and thermal management in switch mode power converters using multiple transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('in-memory',\n",
       "  ('in-memory computing based accelerator for transformer networks for long sequences',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('integrated crossing pooling of representation learning for vision transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('augmented',\n",
       "  ('kat: a knowledge augmented transformer for vision-and-language', 1, 1)),\n",
       " ('layout',\n",
       "  ('layouttransformer: scene layout generation with conceptual and spatial diversity',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('learning defense transformers for counterattacking adversarial examples',\n",
       "   1,\n",
       "   1)),\n",
       " ('counterattacking',\n",
       "  ('learning defense transformers for counterattacking adversarial examples',\n",
       "   1,\n",
       "   1)),\n",
       " ('deep',\n",
       "  ('learning light-weight translation models from deep transformer', 1, 1)),\n",
       " ('transformer',\n",
       "  ('learning tracking representations via dual-branch fully transformer networks',\n",
       "   1,\n",
       "   1)),\n",
       " ('line', ('line segment detection using transformers without edges', 1, 1)),\n",
       " ('with',\n",
       "  ('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "   1,\n",
       "   1)),\n",
       " ('switch',\n",
       "  ('millimeter-wave sige radiometer front end with transformer-based dicke switch and on-chip calibration noise source',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('miti-detr: object detection based on transformers with mitigatory self-attention convergence',\n",
       "   1,\n",
       "   1)),\n",
       " ('control',\n",
       "  ('modulation and control of a dc-ac converter with high-frequency link transformer for grid-connected applications',\n",
       "   1,\n",
       "   1)),\n",
       " ('one', ('motion planning transformers: one model to plan them all', 1, 1)),\n",
       " ('multi-task',\n",
       "  ('mt-transunet: mediating multi-task tokens in transformers for skin lesion segmentation and classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('multilingual',\n",
       "  ('mt5: a massively multilingual pre-trained text-to-text transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('multi-aspect controlled response generation in a multimodal dialogue system using hierarchical transformer network',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('multi-modal fusion using fine-tuned self-attention and transfer learning for veracity analysis of web information',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('multiview detection with shadow transformer (and view-coherent data augmentation)',\n",
       "   1,\n",
       "   1)),\n",
       " ('multi-scale',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('muslcat: multi-scale multi-level convolutional attention transformer for discriminative music modeling on raw waveforms',\n",
       "   1,\n",
       "   1)),\n",
       " ('nlpbk',\n",
       "  ('nlpbk at vlsp-2020 shared task: compose transformer pretrained models for reliable intelligence identification on social network',\n",
       "   1,\n",
       "   1)),\n",
       " ('single-phase',\n",
       "  ('online detection of inter-turn winding faults in single-phase distribution transformers using smart meter data',\n",
       "   1,\n",
       "   1)),\n",
       " ('vibration',\n",
       "  ('online monitoring technology of power transformer based on vibration analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('impacts',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1,\n",
       "   1)),\n",
       " ('on',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "   1,\n",
       "   1)),\n",
       " ('of', ('optimizing inference performance of transformers on cpus', 1, 1)),\n",
       " ('for',\n",
       "  ('perspectives and prospects on transformer architecture for cross-modal tasks with language and vision',\n",
       "   1,\n",
       "   1)),\n",
       " ('cancer',\n",
       "  ('pg-tfnet: transformer-based fusion network integrating pathological images and genomic data for cancer survival analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('tasks',\n",
       "  ('plate: visually-grounded planning with transformers in procedural tasks',\n",
       "   1,\n",
       "   1)),\n",
       " ('financial',\n",
       "  ('polyu-cbs at the finsim-2 task: combining distributional, string-based and transformers-based features for hypernymy detection in the financial domain',\n",
       "   1,\n",
       "   1)),\n",
       " ('learning',\n",
       "  ('power law graph transformer for machine translation and representation learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('power transformer fault diagnosis based on dga using a convolutional neural network with noise in measurements',\n",
       "   1,\n",
       "   1)),\n",
       " ('pre-trained',\n",
       "  ('pre-trained transformer-based approach for arabic question answering : a comparative study',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-attention',\n",
       "  ('predicting the next location: a self-attention and recurrent neural network model with temporal context',\n",
       "   1,\n",
       "   1)),\n",
       " ('universal',\n",
       "  ('pretrained transformers as universal computation engines', 1, 1)),\n",
       " ('and',\n",
       "  ('profiling hate speech spreaders on twitter: transformers and mixed pooling',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   2,\n",
       "   1)),\n",
       " ('object',\n",
       "  ('ptt: point-track-transformer module for 3d single object tracking in point clouds',\n",
       "   2,\n",
       "   1)),\n",
       " ('via',\n",
       "  ('remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit',\n",
       "   1,\n",
       "   1)),\n",
       " ('classification',\n",
       "  ('remote sensing time series classification based on self-attention mechanism and time sequence enhancement',\n",
       "   1,\n",
       "   1)),\n",
       " ('supporting',\n",
       "  ('sam-gan: self-attention supporting multi-stage generative adversarial networks for text-to-image synthesis',\n",
       "   1,\n",
       "   1)),\n",
       " ('keyphrase',\n",
       "  ('searching effective transformer for seq2seq keyphrase generation', 1, 1)),\n",
       " ('language',\n",
       "  ('searching for efficient transformers for language modeling', 1, 1)),\n",
       " ('convolution',\n",
       "  ('searching for trionet: combining convolution with local and global self-attention',\n",
       "   1,\n",
       "   1)),\n",
       " ('power',\n",
       "  ('security threat modeling for power transformers in cyber-physical environments',\n",
       "   1,\n",
       "   1)),\n",
       " ('online',\n",
       "  ('simple online unmanned aerial vehicle tracking with transformer', 1, 1)),\n",
       " ('attention',\n",
       "  ('swinbert: end-to-end transformers with sparse attention for video captioning',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('syntax-aware transformers for neural machine translation: the case of text to sign gloss translation',\n",
       "   1,\n",
       "   1)),\n",
       " ('attack', ('tag: transformer attack from gradient', 1, 1)),\n",
       " ('deep',\n",
       "  ('tb-net: a tailored, self-attention deep convolutional neural network design for detection of tuberculosis cases from chest x-ray images',\n",
       "   1,\n",
       "   1)),\n",
       " ('convolutional',\n",
       "  ('tcct: tightly-coupled convolutional transformer on time series forecasting',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('temgnet: deep transformer-based decoding of upperlimb semg for hand gestures recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('self-supervision',\n",
       "  ('temporal transformer networks with self-supervision for action recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('in', ('token pooling in vision transformers', 1, 1)),\n",
       " ('network',\n",
       "  ('transformer based network for open information extraction', 1, 1)),\n",
       " ('transformer',\n",
       "  ('transformer based unsupervised pre-training for acoustic representation learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('recognition',\n",
       "  ('transformer encoder with multi-modal multi-head attention for continuous affect recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('signals',\n",
       "  ('transformer fault prognosis using deep recurrent neural network over vibration signals',\n",
       "   1,\n",
       "   1)),\n",
       " ('odometry',\n",
       "  ('transformer guided geometry model for flow-based unsupervised visual odometry',\n",
       "   1,\n",
       "   1)),\n",
       " ('attngan',\n",
       "  ('transformer models for enhancing attngan based text to image generation',\n",
       "   1,\n",
       "   1)),\n",
       " ('assessment', ('transformer models for text coherence assessment', 1, 1)),\n",
       " ('transformer',\n",
       "  ('transformer winding faults detection based on time series analysis',\n",
       "   1,\n",
       "   1)),\n",
       " ('mobile',\n",
       "  ('transformer-based language models for semantic search and mobile applications retrieval',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-s2a:',\n",
       "  ('transformer-s2a: robust and efficient speech-to-animation', 1, 1)),\n",
       " ('dynamic',\n",
       "  ('transformer-style relational reasoning with dynamic memory updating for temporal network modeling',\n",
       "   1,\n",
       "   1)),\n",
       " ('news',\n",
       "  ('transforming fake news: robust generalisable news classification using transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformers',\n",
       "  ('transfuse: fusing transformers and cnns for medical image segmentation',\n",
       "   1,\n",
       "   1)),\n",
       " ('gan,',\n",
       "  ('transgan: two pure transformers can make one strong gan, and that can scale up',\n",
       "   1,\n",
       "   1)),\n",
       " ('correlated',\n",
       "  ('transmil: transformer based correlated multiple instance learning for whole slide image classication',\n",
       "   1,\n",
       "   1)),\n",
       " (\"transformer's\",\n",
       "  (\"trees in transformers: a theoretical analysis of the transformer's ability to represent trees\",\n",
       "   1,\n",
       "   1)),\n",
       " ('as',\n",
       "  ('tt2inet: text to photo-realistic image synthesis with transformer as text encoder',\n",
       "   1,\n",
       "   1)),\n",
       " ('multimodal',\n",
       "  ('using multimodal transformers in affective computing', 1, 1)),\n",
       " ('punctuation',\n",
       "  ('uzh onpoint at swisstext-2021: sentence end and punctuation prediction in nlg text through ensembling of different transformers (short paper)',\n",
       "   1,\n",
       "   1)),\n",
       " ('promoting',\n",
       "  ('vitality: promoting serendipitous discovery of academic literature with transformers and visual analytics',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('vtamiq: transformers for attention modulated image quality assessment',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('vtnet: visual transformer network for object goal navigation', 1, 1)),\n",
       " ('using',\n",
       "  ('ynu-hpcc at semeval-2021 task 10: using a transformer-based source-free domain adaptation model for semantic processing',\n",
       "   1,\n",
       "   1)),\n",
       " ('modeling',\n",
       "  ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer-based',\n",
       "  ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "   1,\n",
       "   1)),\n",
       " ('a',\n",
       "  ('a fine-grained classification method based on self-attention siamese network',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('a light transformer for speech-to-intent applications', 1, 1)),\n",
       " ('network',\n",
       "  ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('a simple approach to image tilt correction with self-attention mobilenet for smartphones',\n",
       "   1,\n",
       "   1)),\n",
       " ('a', ('a unified pruning framework for vision transformers', 1, 1)),\n",
       " ('cmos',\n",
       "  ('a wideband cmos frequency quadrupler with transformer-based tail feedback loop',\n",
       "   1,\n",
       "   1)),\n",
       " ('in',\n",
       "  ('accurate fault diagnosis in transformers using an auxiliary current-compensation-based framework for differential relays',\n",
       "   1,\n",
       "   1)),\n",
       " ('for', ('adaptive image transformer for one-shot object detection', 1, 1)),\n",
       " ('classification',\n",
       "  ('aimh at semeval-2021 task 6: multimodal classification using an ensemble of transformer models',\n",
       "   1,\n",
       "   1)),\n",
       " ('matter:',\n",
       "  ('all tokens matter: token labeling for training better vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('models',\n",
       "  ('ammu - a survey of transformer-based biomedical pretrained language models',\n",
       "   1,\n",
       "   1)),\n",
       " ('empirical',\n",
       "  ('an empirical study of training self-supervised vision transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('an end-to-end framework combining time-frequency expert knowledge and modified transformer networks for vibration signal classification',\n",
       "   1,\n",
       "   1)),\n",
       " ('for',\n",
       "  ('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('analysis and visualization of time-varying harmonics in transformer inrush currents',\n",
       "   1,\n",
       "   1)),\n",
       " ('a', ('analysis of a transformer short-circuit fault in near zone', 1, 1)),\n",
       " ('architectures',\n",
       "  ('audio transformers: transformer architectures for large scale audio understanding. adieu convolutions',\n",
       "   1,\n",
       "   1)),\n",
       " ('with',\n",
       "  ('augmented convolutional neural networks with transformer for wireless interference identification',\n",
       "   1,\n",
       "   1)),\n",
       " ('using',\n",
       "  ('automated question generation and question answering from turkish texts using text-to-text transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('bidirectional',\n",
       "  ('ava: a financial service chatbot based on deep bidirectional transformers',\n",
       "   1,\n",
       "   1)),\n",
       " ('for', ('benchmarking a transformer-free model for ad-hoc retrieval', 1, 1)),\n",
       " ('mental',\n",
       "  ('bert-based transformers for early detection of mental health illnesses',\n",
       "   1,\n",
       "   1)),\n",
       " ('based',\n",
       "  (\"bloomnet: a robust transformer based model for bloom's learning outcome classification\",\n",
       "   1,\n",
       "   1)),\n",
       " ('vision',\n",
       "  ('bootstrapping vits: towards liberating vision transformers from pre-training',\n",
       "   1,\n",
       "   1)),\n",
       " ('neural',\n",
       "  ('bossnas: exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search',\n",
       "   2,\n",
       "   1)),\n",
       " ('box-attention', ('boxer: box-attention for 2d and 3d transformers', 1, 1)),\n",
       " ('properties?',\n",
       "  ('can transformer language models predict psychometric properties?', 1, 1)),\n",
       " ('using',\n",
       "  ('child face age progression and regression using self-attention multi-scale patch gan',\n",
       "   1,\n",
       "   1)),\n",
       " ('transformer',\n",
       "  ('co-evolution transformer for protein contact prediction', 1, 1)),\n",
       " ('emotion',\n",
       "  ('combining a parallel 2d cnn with a self-attention dilated residual network for ctc-based discrete speech emotion recognition',\n",
       "   1,\n",
       "   1)),\n",
       " ('comparison',\n",
       "  ('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "   1,\n",
       "   1)),\n",
       " ('network',\n",
       "  ('convolutional neural network (cnn) vs visual transformer (vit) for digital holography',\n",
       "   1,\n",
       "   1)),\n",
       " ('videos',\n",
       "  ('dance with self-attention: a new look of conditional random fields on anomaly detection in videos',\n",
       "   1,\n",
       "   1)),\n",
       " ('under',\n",
       "  ('diagnosis of inter-turn shorts of loaded transformer under various load currents and power factors; impulse voltage-based frequency response approach',\n",
       "   1,\n",
       "   1)),\n",
       " ('long',\n",
       "  ('discodvt: generating long text with discourse-aware discrete variational transformer',\n",
       "   1,\n",
       "   1)),\n",
       " ...]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(title, features), TF] -> [features, (title, TF , 1)]  : count 1 for every time feature appear in each title \n",
    "map3=reduce.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
    "map3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5600f7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dual-mode', 1),\n",
       " ('word', 1),\n",
       " ('matching', 1),\n",
       " ('multiple', 1),\n",
       " ('integration', 1),\n",
       " ('and', 1),\n",
       " ('rare', 1),\n",
       " ('system', 1),\n",
       " ('training', 1),\n",
       " ('natural', 1),\n",
       " ('injection', 1),\n",
       " ('era', 1),\n",
       " ('mri', 1),\n",
       " ('verification', 1),\n",
       " ('more', 1),\n",
       " ('assessing', 1),\n",
       " ('transformer-based', 1),\n",
       " ('trial', 1),\n",
       " ('rail', 1),\n",
       " ('transformer', 1),\n",
       " ('ava:', 1),\n",
       " ('speaker', 1),\n",
       " ('extraction', 1),\n",
       " ('voltage', 1),\n",
       " ('bert', 1),\n",
       " ('visual', 1),\n",
       " ('vaccine', 1),\n",
       " ('transformers', 1),\n",
       " ('controllable', 1),\n",
       " ('computation-aware', 1),\n",
       " ('melody', 1),\n",
       " ('a', 1),\n",
       " ('sexism', 1),\n",
       " ('accelerated', 1),\n",
       " ('agent', 1),\n",
       " ('transformer-based', 1),\n",
       " ('on', 1),\n",
       " ('deeplpc-mhanet:', 1),\n",
       " ('method', 1),\n",
       " ('transformers', 1),\n",
       " ('transformer', 1),\n",
       " ('real-time', 1),\n",
       " ('semantic', 1),\n",
       " ('discriminative', 1),\n",
       " ('domain', 1),\n",
       " ('for', 1),\n",
       " ('classification', 1),\n",
       " ('strategies', 1),\n",
       " ('spotting', 1),\n",
       " ('lightweight', 1),\n",
       " ('power', 1),\n",
       " ('at', 1),\n",
       " ('dementia', 1),\n",
       " ('and', 1),\n",
       " ('via', 1),\n",
       " ('spaces', 1),\n",
       " ('of', 1),\n",
       " ('and', 1),\n",
       " ('point', 1),\n",
       " ('a', 1),\n",
       " ('fine-tuning', 1),\n",
       " ('can', 1),\n",
       " ('fast', 1),\n",
       " ('image', 1),\n",
       " ('ice', 1),\n",
       " ('via', 1),\n",
       " ('hope', 1),\n",
       " ('and', 1),\n",
       " ('via', 1),\n",
       " ('prediction', 1),\n",
       " ('accelerator', 1),\n",
       " ('khmer', 1),\n",
       " ('self-supervised', 1),\n",
       " ('reacutepondre', 1),\n",
       " ('karl-trans-ner:', 1),\n",
       " ('to', 1),\n",
       " ('audio', 1),\n",
       " ('error', 1),\n",
       " ('super-resolution', 1),\n",
       " ('vision', 1),\n",
       " ('removal', 1),\n",
       " ('multi-attribute', 1),\n",
       " ('detection', 1),\n",
       " ('efficiency', 1),\n",
       " ('and', 1),\n",
       " ('meeting', 1),\n",
       " ('active', 1),\n",
       " ('age', 1),\n",
       " ('networks', 1),\n",
       " ('transformers', 1),\n",
       " ('automatic', 1),\n",
       " ('learning', 1),\n",
       " ('four-wire', 1),\n",
       " ('speech', 1),\n",
       " ('framework', 1),\n",
       " ('incremental', 1),\n",
       " ('motion', 1),\n",
       " ('using', 1),\n",
       " ('document', 1),\n",
       " ('effectiveness', 1),\n",
       " ('sentiment', 1),\n",
       " ('reduce', 1),\n",
       " ('models', 1),\n",
       " ('optimizing', 1),\n",
       " ('with', 1),\n",
       " ('pedestrian', 1),\n",
       " ('prediction', 1),\n",
       " ('cloud', 1),\n",
       " ('based', 1),\n",
       " ('and', 1),\n",
       " ('and', 1),\n",
       " ('summarizers', 1),\n",
       " ('normalized', 1),\n",
       " ('for', 1),\n",
       " ('transformers', 1),\n",
       " ('autonomous', 1),\n",
       " ('learning,', 1),\n",
       " ('capac-itance', 1),\n",
       " ('transformer', 1),\n",
       " ('and', 1),\n",
       " ('contextualized', 1),\n",
       " ('scale', 1),\n",
       " ('consistency', 1),\n",
       " ('neural', 1),\n",
       " ('action', 1),\n",
       " ('atherosclerotic', 1),\n",
       " ('tissue', 1),\n",
       " ('between', 1),\n",
       " ('super-resolution', 1),\n",
       " ('networks', 1),\n",
       " ('graph', 1),\n",
       " ('for', 1),\n",
       " ('learning', 1),\n",
       " ('of', 1),\n",
       " ('using', 1),\n",
       " ('transcription', 1),\n",
       " ('bidirectional', 1),\n",
       " ('session-based', 1),\n",
       " ('fpga', 1),\n",
       " ('with', 1),\n",
       " ('graph', 1),\n",
       " ('with', 1),\n",
       " ('spelling', 1),\n",
       " ('comments', 1),\n",
       " ('high-resolution', 1),\n",
       " ('learning', 1),\n",
       " ('t3-vis:', 1),\n",
       " ('transformer-based', 1),\n",
       " ('detection', 1),\n",
       " ('transformer-based', 1),\n",
       " ('overcurrent', 1),\n",
       " ('of', 1),\n",
       " ('router:', 1),\n",
       " ('transformer', 1),\n",
       " ('token', 1),\n",
       " ('object', 1),\n",
       " ('network', 1),\n",
       " ('transformer', 1),\n",
       " ('tuta:', 1),\n",
       " ('image', 1),\n",
       " ('2021:', 1),\n",
       " ('swisstext-2021:', 1),\n",
       " ('text', 1),\n",
       " ('transformer', 1),\n",
       " ('video', 1),\n",
       " ('transformers', 1),\n",
       " ('part-and-sum', 1),\n",
       " ('of', 1),\n",
       " ('speed', 1),\n",
       " ('transformer', 1),\n",
       " ('attention', 1),\n",
       " ('distribution', 1),\n",
       " ('oil-paper', 1),\n",
       " ('contracts', 1),\n",
       " ('grid', 1),\n",
       " ('interleaved', 1),\n",
       " ('approach', 1),\n",
       " ('reversing', 1),\n",
       " ('of', 1),\n",
       " ('direct', 1),\n",
       " ('impulse', 1),\n",
       " ('vibration', 1),\n",
       " ('items', 1),\n",
       " ('image', 1),\n",
       " ('detection', 1),\n",
       " ('that', 1),\n",
       " ('online', 1),\n",
       " ('multi-scale', 1),\n",
       " ('javanese', 1),\n",
       " ('language', 1),\n",
       " ('recursive', 1),\n",
       " ('domain', 1),\n",
       " ('via', 1),\n",
       " ('answering', 1),\n",
       " ('code', 1),\n",
       " ('video', 1),\n",
       " ('fusion', 1),\n",
       " ('machine', 1),\n",
       " ('component-level', 1),\n",
       " ('linkable', 1),\n",
       " ('transformer?', 1),\n",
       " ('from', 1),\n",
       " ('full', 1),\n",
       " ('transformer', 1),\n",
       " ('model-based', 1),\n",
       " ('networks', 1),\n",
       " ('deep', 1),\n",
       " ('connectivity,', 1),\n",
       " ('records', 1),\n",
       " ('via', 1),\n",
       " ('neural', 1),\n",
       " ('discrete', 1),\n",
       " ('admission', 1),\n",
       " ('based', 1),\n",
       " ('graph', 1),\n",
       " ('explicit', 1),\n",
       " ('unwarping', 1),\n",
       " ('multi-temporal', 1),\n",
       " ('with', 1),\n",
       " ('title', 1),\n",
       " ('on', 1),\n",
       " ('for', 1),\n",
       " ('network', 1),\n",
       " ('auto-regressive', 1),\n",
       " ('robot', 1),\n",
       " ('machine', 1),\n",
       " ('structures', 1),\n",
       " ('neural', 1),\n",
       " ('linguistic', 1),\n",
       " ('principles', 1),\n",
       " ('neural', 1),\n",
       " ('for', 1),\n",
       " ('domain', 1),\n",
       " ('content', 1),\n",
       " ('moisture', 1),\n",
       " ('fusion', 1),\n",
       " ('transformer', 1),\n",
       " ('for', 1),\n",
       " ('microscopy', 1),\n",
       " ('llc', 1),\n",
       " ('algorithm', 1),\n",
       " ('abnormal', 1),\n",
       " ('in', 1),\n",
       " ('geometry-contrastive', 1),\n",
       " ('self-attention', 1),\n",
       " ('computation', 1),\n",
       " ('and', 1),\n",
       " ('neural', 1),\n",
       " ('network', 1),\n",
       " ('current', 1),\n",
       " ('differential', 1),\n",
       " ('i2c2w:', 1),\n",
       " ('high', 1),\n",
       " ('voltage', 1),\n",
       " ('implicit', 1),\n",
       " ('approximation', 1),\n",
       " ('translation', 1),\n",
       " ('10', 1),\n",
       " ('a', 1),\n",
       " ('transformer', 1),\n",
       " ('model', 1),\n",
       " ('via', 1),\n",
       " ('features', 1),\n",
       " ('multi-view', 1),\n",
       " ('adaptive', 1),\n",
       " ('mgsan:', 1),\n",
       " ('u-net', 1),\n",
       " ('gait', 1),\n",
       " ('frequency', 1),\n",
       " ('winding', 1),\n",
       " ('prediction', 1),\n",
       " ('auxiliary', 1),\n",
       " ('video', 1),\n",
       " ('dynamic', 1),\n",
       " ('transformer-based', 1),\n",
       " ('transformers', 1),\n",
       " ('model', 1),\n",
       " ('efficient', 1),\n",
       " ('transformers:', 1),\n",
       " ('audio-visual', 1),\n",
       " ('completion', 1),\n",
       " ('cloud', 1),\n",
       " ('optimization', 1),\n",
       " ('of', 1),\n",
       " ('fistula', 1),\n",
       " ('scientific', 1),\n",
       " ('vision-and-language', 1),\n",
       " ('self-attention', 1),\n",
       " ('for', 1),\n",
       " ('transformer', 1),\n",
       " ('on', 1),\n",
       " ('feature', 1),\n",
       " ('with', 1),\n",
       " ('based', 1),\n",
       " ('vs', 1),\n",
       " ('component', 1),\n",
       " ('adversarial', 1),\n",
       " ('cooperative', 1),\n",
       " ('among', 1),\n",
       " ('inside', 1),\n",
       " ('anchor', 1),\n",
       " ('proposal', 1),\n",
       " ('relations', 1),\n",
       " ('building', 1),\n",
       " ('self-supervised', 1),\n",
       " ('arcs', 1),\n",
       " ('lesion', 1),\n",
       " ('low-complexity', 1),\n",
       " ('transformer', 1),\n",
       " ('image', 1),\n",
       " ('with', 1),\n",
       " ('learning', 1),\n",
       " ('segmentation', 1),\n",
       " ('traffic', 1),\n",
       " ('stochastic', 1),\n",
       " ('detection', 1),\n",
       " ('transformer', 1),\n",
       " ('voxel', 1),\n",
       " ('language', 1),\n",
       " ('hostility', 1),\n",
       " ('tcl:', 1),\n",
       " ('estimation', 1),\n",
       " ('the', 1),\n",
       " ('too', 1),\n",
       " ('efficient', 1),\n",
       " ('phase', 1),\n",
       " ('couplet', 1),\n",
       " ('transformer', 1),\n",
       " ('based', 1),\n",
       " ('scheme', 1),\n",
       " ('for', 1),\n",
       " ('image', 1),\n",
       " ('portuguese', 1),\n",
       " ('russian', 1),\n",
       " ('fake', 1),\n",
       " ('efficient', 1),\n",
       " ('transformers', 1),\n",
       " ('transformer', 1),\n",
       " ('instance', 1),\n",
       " ('detection', 1),\n",
       " ('denoising', 1),\n",
       " ('tsdae:', 1),\n",
       " ('analysis', 1),\n",
       " ('image', 1),\n",
       " ('transformers', 1),\n",
       " ('overcoming', 1),\n",
       " ('based', 1),\n",
       " ('viesum:', 1),\n",
       " ('text', 1),\n",
       " ('transformer', 1),\n",
       " ('disease', 1),\n",
       " ('transformer', 1),\n",
       " ('grounding', 1),\n",
       " ('vitality:', 1),\n",
       " ('use?', 1),\n",
       " ('for', 1),\n",
       " ('intrinsic', 1),\n",
       " ('wrtre:', 1),\n",
       " ('16.8-to-21.6', 1),\n",
       " ('three-phase', 1),\n",
       " ('fine-grained', 1),\n",
       " ('communication', 1),\n",
       " ('dc', 1),\n",
       " ('novel', 1),\n",
       " ('a', 1),\n",
       " ('dilated', 1),\n",
       " ('synthesis', 1),\n",
       " ('and', 1),\n",
       " ('a', 1),\n",
       " ('cells', 1),\n",
       " ('fpga:', 1),\n",
       " ('an', 1),\n",
       " ('and', 1),\n",
       " ('llc', 1),\n",
       " ('of', 1),\n",
       " ('transformer', 1),\n",
       " ('winding', 1),\n",
       " ('transformer', 1),\n",
       " ('array-based', 1),\n",
       " ('mri', 1),\n",
       " ('perform', 1),\n",
       " ('for', 1),\n",
       " ('solid-state-transformers', 1),\n",
       " ('constructing', 1),\n",
       " ('aggregation', 1),\n",
       " ('matching', 1),\n",
       " ('models', 1),\n",
       " ('cyclegan-based', 1),\n",
       " ('transformer', 1),\n",
       " ('for', 1),\n",
       " ('for', 1),\n",
       " ('ensemble', 1),\n",
       " ('low-loss', 1),\n",
       " ('ultra-wideband', 1),\n",
       " ('classification', 1),\n",
       " ('diverse', 1),\n",
       " ('of', 1),\n",
       " ('multi-modal', 1),\n",
       " ('properties', 1),\n",
       " ('voltages', 1),\n",
       " ('with', 1),\n",
       " ('and', 1),\n",
       " ('properties', 1),\n",
       " ('end-to-end', 1),\n",
       " ('end-to-end', 1),\n",
       " ('models', 1),\n",
       " ('a', 1),\n",
       " ('reply', 1),\n",
       " ('subtypes', 1),\n",
       " ('drum', 1),\n",
       " ('attention:', 1),\n",
       " ('for', 1),\n",
       " ('current', 1),\n",
       " ('features', 1),\n",
       " ('for', 1),\n",
       " ('unsupervised', 1),\n",
       " ('and', 1),\n",
       " ('dialogue', 1),\n",
       " ('sms', 1),\n",
       " ('image', 1),\n",
       " ('transformers', 1),\n",
       " ('probability', 1),\n",
       " ('lexically-aware', 1),\n",
       " ('hyperspectral', 1),\n",
       " ('features', 1),\n",
       " ('transformer', 1),\n",
       " ('in', 1),\n",
       " ('learning', 1),\n",
       " ('image', 1),\n",
       " ('transformers', 1),\n",
       " ('cross-transformer', 1),\n",
       " ('memory-efficient', 1),\n",
       " ('trilinear', 1),\n",
       " ('of', 1),\n",
       " ('biomedical', 1),\n",
       " ('fusion', 1),\n",
       " ('for', 1),\n",
       " ('transformer', 1),\n",
       " ('for', 1),\n",
       " ('smart', 1),\n",
       " ('nlp', 1),\n",
       " ('removal', 1),\n",
       " ('in', 1),\n",
       " ('multi-agent', 1),\n",
       " ('attention-based', 1),\n",
       " ('transformers', 1),\n",
       " ('speech', 1),\n",
       " ('re-identification', 1),\n",
       " ('position-informed', 1),\n",
       " ('poat-net:', 1),\n",
       " ('(roger', 1),\n",
       " ('domain', 1),\n",
       " ('image', 1),\n",
       " ('real-time', 1),\n",
       " ('sensing', 1),\n",
       " ('representation', 1),\n",
       " ('and', 1),\n",
       " ('field', 1),\n",
       " ('rpt:', 1),\n",
       " ('sequence-to-sequence', 1),\n",
       " ('using', 1),\n",
       " ('visual', 1),\n",
       " ('for', 1),\n",
       " ('are', 1),\n",
       " ('network', 1),\n",
       " ('spectr:', 1),\n",
       " ('networks', 1),\n",
       " ('data', 1),\n",
       " ('transformer', 1),\n",
       " ('trillion', 1),\n",
       " ('self-attention', 1),\n",
       " ('with', 1),\n",
       " ('@finsim-2:', 1),\n",
       " ('template', 1),\n",
       " ('prediction', 1),\n",
       " ('algorithm', 1),\n",
       " ('transformers', 1),\n",
       " ('accuracy', 1),\n",
       " ('language', 1),\n",
       " ('comprehensive', 1),\n",
       " ('image', 1),\n",
       " ('prediction', 1),\n",
       " ('transformer:', 1),\n",
       " ('ais', 1),\n",
       " ('trans4trans:', 1),\n",
       " ('of', 1),\n",
       " ('detection', 1),\n",
       " ('for', 1),\n",
       " ('language', 1),\n",
       " ('prediction', 1),\n",
       " ('eligibility', 1),\n",
       " ('for', 1),\n",
       " ('flow', 1),\n",
       " ('learning', 1),\n",
       " ('block-online', 1),\n",
       " ('to', 1),\n",
       " ('vision-language', 1),\n",
       " ('transformers', 1),\n",
       " ('bot', 1),\n",
       " ('joint-flexible', 1),\n",
       " ('production', 1),\n",
       " ('analysis', 1),\n",
       " ('transformer', 1),\n",
       " ('vision', 1),\n",
       " ('image', 1),\n",
       " ('word', 1),\n",
       " ('importance', 1),\n",
       " ('sensing', 1),\n",
       " ('pixel', 1),\n",
       " ('on', 1),\n",
       " ('text', 1),\n",
       " ('with', 1),\n",
       " ('new', 1),\n",
       " ('wave', 1),\n",
       " ('2d', 1),\n",
       " ('high', 1),\n",
       " ('differential', 1),\n",
       " ('adversarial', 1),\n",
       " ('obscure', 1),\n",
       " ('transformer-based', 1),\n",
       " ('with', 1),\n",
       " ('microorganism', 1),\n",
       " ('multilayer', 1),\n",
       " ('zero-shot', 1),\n",
       " ('prediction', 1),\n",
       " ('video', 1),\n",
       " ('design', 1),\n",
       " ('shap', 1),\n",
       " ('arabic', 1),\n",
       " ('distribution', 1),\n",
       " ('signals', 1),\n",
       " ('with', 1),\n",
       " ('multi-winding', 1),\n",
       " ('can', 1),\n",
       " ('modeling', 1),\n",
       " ('converter', 1),\n",
       " ('with', 1),\n",
       " ('processing', 1),\n",
       " ('sign', 1),\n",
       " ('convolution', 1),\n",
       " ('controllable', 1),\n",
       " ('convdysat:', 1),\n",
       " ('graphs', 1),\n",
       " ('for', 1),\n",
       " ('transformer', 1),\n",
       " ('transformers', 1),\n",
       " ('convolutional', 1),\n",
       " ('dct:', 1),\n",
       " ('method', 1),\n",
       " ('current', 1),\n",
       " ('transformers', 1),\n",
       " ('for', 1),\n",
       " (\"don't\", 1),\n",
       " ('answering', 1),\n",
       " ('transformer', 1),\n",
       " ('recognition', 1),\n",
       " ('eeg', 1),\n",
       " ('high', 1),\n",
       " ('based', 1),\n",
       " ('and', 1),\n",
       " ('insensitive', 1),\n",
       " ('transformer', 1),\n",
       " ('language', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('inter-resonance', 1),\n",
       " ('univariate', 1),\n",
       " ('synthetic', 1),\n",
       " ('a', 1),\n",
       " ('learning', 1),\n",
       " ('makeup', 1),\n",
       " ('using', 1),\n",
       " ('catboost', 1),\n",
       " ('combination', 1),\n",
       " ('self-attention', 1),\n",
       " ('detection', 1),\n",
       " ('of', 1),\n",
       " ('social', 1),\n",
       " ('attention', 1),\n",
       " ('bidirectional', 1),\n",
       " ('protein', 1),\n",
       " ('microscopy', 1),\n",
       " ('model', 1),\n",
       " ('guiding', 1),\n",
       " ('accurate', 1),\n",
       " ('and', 1),\n",
       " ('transformer', 1),\n",
       " ('mechanism', 1),\n",
       " ('state', 1),\n",
       " ('induced', 1),\n",
       " ('for', 1),\n",
       " ('yolov3', 1),\n",
       " ('signals:', 1),\n",
       " ('energy', 1),\n",
       " ('with', 1),\n",
       " ('with', 1),\n",
       " ('loss', 1),\n",
       " ('traffic', 1),\n",
       " ('field', 1),\n",
       " ('moment', 1),\n",
       " ('vision', 1),\n",
       " ('two', 1),\n",
       " ('transformer', 1),\n",
       " ('text', 1),\n",
       " ('of', 1),\n",
       " ('video', 1),\n",
       " ('on', 1),\n",
       " ('entity', 1),\n",
       " ('text', 1),\n",
       " ('model', 1),\n",
       " ('sequential', 1),\n",
       " ('based', 1),\n",
       " ('distributed', 1),\n",
       " ('with', 1),\n",
       " ('recurrent', 1),\n",
       " ('nlp', 1),\n",
       " ('transformer', 1),\n",
       " ('segmentation', 1),\n",
       " ('quantitative', 1),\n",
       " ('contextualized', 1),\n",
       " ('retrieval-augmented', 1),\n",
       " ('robustness', 1),\n",
       " ('and', 1),\n",
       " ('text-to-image', 1),\n",
       " ('languages', 1),\n",
       " ('and', 1),\n",
       " ('siamese', 1),\n",
       " ('with', 1),\n",
       " ('spam', 1),\n",
       " ('on', 1),\n",
       " ('complexity', 1),\n",
       " ('self-attention', 1),\n",
       " ('query', 1),\n",
       " ('tightly-coupled', 1),\n",
       " ('how', 1),\n",
       " ('temporal', 1),\n",
       " ('awake', 1),\n",
       " ('to', 1),\n",
       " ('the', 1),\n",
       " ('a', 1),\n",
       " ('u-net', 1),\n",
       " ('transfer:', 1),\n",
       " ('awareness', 1),\n",
       " ('for', 1),\n",
       " ('transformer-based', 1),\n",
       " ('media', 1),\n",
       " ('for', 1),\n",
       " ('transformer-style', 1),\n",
       " ('for', 1),\n",
       " ('compact', 1),\n",
       " ('attribute-guided', 1),\n",
       " ('in', 1),\n",
       " ('for', 1),\n",
       " ('for', 1),\n",
       " ('high-resolution', 1),\n",
       " ('unaligned', 1),\n",
       " ('are', 1),\n",
       " ('feature', 1),\n",
       " ('vision', 1),\n",
       " ('vortx:', 1),\n",
       " ('3d-anas', 1),\n",
       " ('grounding', 1),\n",
       " ('mechanism', 1),\n",
       " ('fault', 1),\n",
       " ('transformerless', 1),\n",
       " ('clustering', 1),\n",
       " ('spectrogram', 1),\n",
       " ('for', 1),\n",
       " ('transformer', 1),\n",
       " ('handwritten', 1),\n",
       " ('frequency', 1),\n",
       " ('principle', 1),\n",
       " ('detection', 1),\n",
       " ('hierarchical', 1),\n",
       " ('an', 1),\n",
       " ('on', 1),\n",
       " ('analysis', 1),\n",
       " ('agreement', 1),\n",
       " ('efficiently', 1),\n",
       " ('adaptive', 1),\n",
       " ('in', 1),\n",
       " ('medium', 1),\n",
       " ('segmentation', 1),\n",
       " ('deinterleaving', 1),\n",
       " ('self-attention', 1),\n",
       " ('object', 1),\n",
       " ('sparse', 1),\n",
       " ('transformer-based', 1),\n",
       " ('pre-trained', 1),\n",
       " ('with', 1),\n",
       " ('point', 1),\n",
       " ('for', 1),\n",
       " ('recognition', 1),\n",
       " ('counting', 1),\n",
       " ('x-rays', 1),\n",
       " ('transformer', 1),\n",
       " ('features', 1),\n",
       " ('convolutional', 1),\n",
       " ('natural', 1),\n",
       " ('with', 1),\n",
       " ('disturbance', 1),\n",
       " ('multimodal', 1),\n",
       " ('classification', 1),\n",
       " ('efficient', 1),\n",
       " ('from', 1),\n",
       " ('tracking', 1),\n",
       " ('detection', 1),\n",
       " ('for', 1),\n",
       " ('for', 1),\n",
       " ('a', 1),\n",
       " ('oil-paper', 1),\n",
       " ('augmented', 1),\n",
       " ('a', 1),\n",
       " ('multimodal', 1),\n",
       " ('local', 1),\n",
       " ('priors', 1),\n",
       " ('with', 1),\n",
       " ('decreasing', 1),\n",
       " ('transformers', 1),\n",
       " ('using', 1),\n",
       " ('a', 1),\n",
       " ('with', 1),\n",
       " ('improved', 1),\n",
       " ('for', 1),\n",
       " ('instance-based', 1),\n",
       " ('ipe', 1),\n",
       " ('and', 1),\n",
       " ('rnn', 1),\n",
       " ('modeling', 1),\n",
       " ('absolute', 1),\n",
       " ('devices', 1),\n",
       " ('lightxml:', 1),\n",
       " ('environment', 1),\n",
       " ('long-span', 1),\n",
       " ('detection', 1),\n",
       " ('augmented', 1),\n",
       " ('for', 1),\n",
       " ('for', 1),\n",
       " ('acquisition', 1),\n",
       " ('feature', 1),\n",
       " ('masked', 1),\n",
       " ('transformer', 1),\n",
       " ('in', 1),\n",
       " ('nn', 1),\n",
       " ('single-channel', 1),\n",
       " ('speech', 1),\n",
       " ('a', 1),\n",
       " ('microgrid', 1),\n",
       " ('software', 1),\n",
       " ('to', 1),\n",
       " ('vision', 1),\n",
       " ('convolution', 1),\n",
       " ('sample', 1),\n",
       " ('point', 1),\n",
       " ('for', 1),\n",
       " ('encoder', 1),\n",
       " ('microwave', 1),\n",
       " ('baselines', 1),\n",
       " ('recursive', 1),\n",
       " ('fusion', 1),\n",
       " ('principle', 1),\n",
       " ('transformer', 1),\n",
       " ('based', 1),\n",
       " ('algorithm', 1),\n",
       " ('for', 1),\n",
       " ('frontend', 1),\n",
       " ('with', 1),\n",
       " ('classification', 1),\n",
       " ('sequential', 1),\n",
       " ('multi-frame', 1),\n",
       " ('speech', 1),\n",
       " ('for', 1),\n",
       " ('self-attention', 1),\n",
       " ('aggregation', 1),\n",
       " ('sparta:', 1),\n",
       " ('segmentation', 1),\n",
       " ('self-attention', 1),\n",
       " ('transformer', 1),\n",
       " ('data', 1),\n",
       " ('sting:', 1),\n",
       " ('low', 1),\n",
       " ('automated', 1),\n",
       " ('transformers', 1),\n",
       " ('face', 1),\n",
       " ('transformer', 1),\n",
       " ('of', 1),\n",
       " ('decoupling', 1),\n",
       " ('answering', 1),\n",
       " ('for', 1),\n",
       " ('image', 1),\n",
       " ('recognition', 1),\n",
       " ('at', 1),\n",
       " ('3d', 1),\n",
       " ('transformer', 1),\n",
       " ('weather', 1),\n",
       " ('transformer-based', 1),\n",
       " ('reverberant', 1),\n",
       " ('separation', 1),\n",
       " ('for', 1),\n",
       " ('bidirectional', 1),\n",
       " ('super-resolution', 1),\n",
       " ('convolutions', 1),\n",
       " ('for', 1),\n",
       " ('from', 1),\n",
       " ('for', 1),\n",
       " ('dbc/hz', 1),\n",
       " ('learning', 1),\n",
       " ('smart', 1),\n",
       " ('network', 1),\n",
       " ('to', 1),\n",
       " ('and', 1),\n",
       " ('self-attention', 1),\n",
       " ('transformer', 1),\n",
       " ('segmentation', 1),\n",
       " ('linear', 1),\n",
       " ('traffic', 1),\n",
       " ('converter', 1),\n",
       " ('a', 1),\n",
       " ('networks', 1),\n",
       " ('fourier', 1),\n",
       " ('with', 1),\n",
       " ('transformer', 1),\n",
       " ('usage', 1),\n",
       " ('mechanism', 1),\n",
       " ('voltage', 1),\n",
       " ('transformer', 1),\n",
       " ('transformer-based', 1),\n",
       " ('large', 1),\n",
       " ('human', 1),\n",
       " ('entity', 1),\n",
       " ('scene', 1),\n",
       " ('sampling', 1),\n",
       " ('with', 1),\n",
       " ('models', 1),\n",
       " ('by', 1),\n",
       " ('mechanism', 1),\n",
       " ('correction', 1),\n",
       " ('with', 1),\n",
       " ('matrix', 1),\n",
       " ('classmates', 1),\n",
       " ('for', 1),\n",
       " ('transformers', 1),\n",
       " ('of', 1),\n",
       " ('graph', 1),\n",
       " ('language', 1),\n",
       " ('sequence-to-sequence', 1),\n",
       " ('dual', 1),\n",
       " ('multibox', 1),\n",
       " ('model', 1),\n",
       " ('sequential', 1),\n",
       " ('intelligent', 1),\n",
       " ('inductive', 1),\n",
       " ('design', 1),\n",
       " ('speech', 1),\n",
       " ('controllable', 1),\n",
       " ('for', 1),\n",
       " ('information?', 1),\n",
       " ('sentinel-2', 1),\n",
       " ('u-net', 1),\n",
       " ('graph', 1),\n",
       " ('image', 1),\n",
       " ('and', 1),\n",
       " ('for', 1),\n",
       " ('detection', 1),\n",
       " ('with', 1),\n",
       " ('vessel', 1),\n",
       " ('transformer', 1),\n",
       " ('speaker-attributed', 1),\n",
       " ('location-guided', 1),\n",
       " ('video', 1),\n",
       " ('better', 1),\n",
       " ('entity', 1),\n",
       " ('local', 1),\n",
       " ('gpt,', 1),\n",
       " ('networks', 1),\n",
       " ('(english-hindi)', 1),\n",
       " ('density-based', 1),\n",
       " ('clustered', 1),\n",
       " ('environments', 1),\n",
       " ('iou', 1),\n",
       " ('for', 1),\n",
       " ('thermal', 1),\n",
       " ('in-memory', 1),\n",
       " ('for', 1),\n",
       " ('augmented', 1),\n",
       " ('layout', 1),\n",
       " ('transformers', 1),\n",
       " ('counterattacking', 1),\n",
       " ('deep', 1),\n",
       " ('transformer', 1),\n",
       " ('line', 1),\n",
       " ('with', 1),\n",
       " ('switch', 1),\n",
       " ('with', 1),\n",
       " ('control', 1),\n",
       " ('one', 1),\n",
       " ('multi-task', 1),\n",
       " ('multilingual', 1),\n",
       " ('in', 1),\n",
       " ('for', 1),\n",
       " ('with', 1),\n",
       " ('multi-scale', 1),\n",
       " ('transformer', 1),\n",
       " ('nlpbk', 1),\n",
       " ('single-phase', 1),\n",
       " ('vibration', 1),\n",
       " ('impacts', 1),\n",
       " ('on', 1),\n",
       " ('with', 1),\n",
       " ('of', 1),\n",
       " ('for', 1),\n",
       " ('cancer', 1),\n",
       " ('tasks', 1),\n",
       " ('financial', 1),\n",
       " ('learning', 1),\n",
       " ('neural', 1),\n",
       " ('pre-trained', 1),\n",
       " ('self-attention', 1),\n",
       " ('universal', 1),\n",
       " ('and', 1),\n",
       " ('for', 1),\n",
       " ('object', 1),\n",
       " ('via', 1),\n",
       " ('classification', 1),\n",
       " ('supporting', 1),\n",
       " ('keyphrase', 1),\n",
       " ('language', 1),\n",
       " ('convolution', 1),\n",
       " ('power', 1),\n",
       " ('online', 1),\n",
       " ('attention', 1),\n",
       " ('neural', 1),\n",
       " ('attack', 1),\n",
       " ('deep', 1),\n",
       " ('convolutional', 1),\n",
       " ('for', 1),\n",
       " ('self-supervision', 1),\n",
       " ('in', 1),\n",
       " ('network', 1),\n",
       " ('transformer', 1),\n",
       " ('recognition', 1),\n",
       " ('signals', 1),\n",
       " ('odometry', 1),\n",
       " ('attngan', 1),\n",
       " ('assessment', 1),\n",
       " ('transformer', 1),\n",
       " ('mobile', 1),\n",
       " ('transformer-s2a:', 1),\n",
       " ('dynamic', 1),\n",
       " ('news', 1),\n",
       " ('transformers', 1),\n",
       " ('gan,', 1),\n",
       " ('correlated', 1),\n",
       " (\"transformer's\", 1),\n",
       " ('as', 1),\n",
       " ('multimodal', 1),\n",
       " ('punctuation', 1),\n",
       " ('promoting', 1),\n",
       " ('for', 1),\n",
       " ('network', 1),\n",
       " ('using', 1),\n",
       " ('modeling', 1),\n",
       " ('transformer-based', 1),\n",
       " ('a', 1),\n",
       " ('for', 1),\n",
       " ('a', 1),\n",
       " ('transformer', 1),\n",
       " ('network', 1),\n",
       " ('for', 1),\n",
       " ('a', 1),\n",
       " ('cmos', 1),\n",
       " ('in', 1),\n",
       " ('for', 1),\n",
       " ('classification', 1),\n",
       " ('matter:', 1),\n",
       " ('models', 1),\n",
       " ('empirical', 1),\n",
       " ('transformer', 1),\n",
       " ('for', 1),\n",
       " ('transformer', 1),\n",
       " ('a', 1),\n",
       " ('architectures', 1),\n",
       " ('with', 1),\n",
       " ('using', 1),\n",
       " ('bidirectional', 1),\n",
       " ('for', 1),\n",
       " ('mental', 1),\n",
       " ('based', 1),\n",
       " ('vision', 1),\n",
       " ('neural', 1),\n",
       " ('box-attention', 1),\n",
       " ('properties?', 1),\n",
       " ('using', 1),\n",
       " ('transformer', 1),\n",
       " ('emotion', 1),\n",
       " ('comparison', 1),\n",
       " ('network', 1),\n",
       " ('videos', 1),\n",
       " ('under', 1),\n",
       " ('long', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[features, (title, TF , 1)] -> (feature, 1) : count 1 for every time feature appear in each title \n",
    "map4=map3.map(lambda x:(x[0],x[1][2]))\n",
    "map4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b8fd3c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 2),\n",
       " ('couplet', 1),\n",
       " ('an', 96),\n",
       " ('2d', 7),\n",
       " ('step', 2),\n",
       " ('quality', 19),\n",
       " ('matters', 1),\n",
       " ('policy', 2),\n",
       " ('carlo', 1),\n",
       " ('cognlp-sheffield', 1),\n",
       " ('solve', 4),\n",
       " ('maritime', 1),\n",
       " ('shell-type', 2),\n",
       " ('temgnet:', 1),\n",
       " ('standards', 1),\n",
       " ('doubler', 1),\n",
       " ('everything', 2),\n",
       " ('asr,', 1),\n",
       " ('plates', 1),\n",
       " ('am-lstm', 1),\n",
       " ('wide-range', 1),\n",
       " ('rooftops', 1),\n",
       " ('process:', 1),\n",
       " ('readonce', 1),\n",
       " ('colorectal', 1),\n",
       " ('orange', 1),\n",
       " ('restaurant', 1),\n",
       " ('cs-um6p', 1),\n",
       " ('sence', 1),\n",
       " ('unsupervised', 30),\n",
       " ('how', 11),\n",
       " ('media', 10),\n",
       " ('two-way', 1),\n",
       " ('leakage', 8),\n",
       " ('lm', 1),\n",
       " ('representational', 2),\n",
       " ('icd-10', 2),\n",
       " ('speeding', 1),\n",
       " ('ufo-vit:', 1),\n",
       " ('integrating', 6),\n",
       " ('task:', 7),\n",
       " ('marbert:', 1),\n",
       " ('nearest', 1),\n",
       " ('pilot:', 1),\n",
       " ('cosformer:', 1),\n",
       " ('soccer', 1),\n",
       " ('co-segmentation', 1),\n",
       " ('knn', 1),\n",
       " ('leads', 1),\n",
       " ('generic', 1),\n",
       " ('s2s-ft:', 1),\n",
       " ('reordering', 1),\n",
       " ('crops', 1),\n",
       " ('communicative', 2),\n",
       " ('entity-and-relation', 1),\n",
       " ('retraining', 1),\n",
       " ('japanese', 1),\n",
       " ('updet:', 2),\n",
       " ('exist2021:', 1),\n",
       " ('ct-cad:', 1),\n",
       " ('network-driven', 1),\n",
       " ('re-interpreting', 1),\n",
       " ('what,', 1),\n",
       " ('distributional,', 1),\n",
       " ('faces', 1),\n",
       " ('cpus', 1),\n",
       " ('demystify', 1),\n",
       " ('voltage', 30),\n",
       " ('cooperative', 1),\n",
       " ('dc', 10),\n",
       " ('hybrid', 44),\n",
       " ('unwanted', 1),\n",
       " ('diabetic', 5),\n",
       " ('ndt-transformer:', 1),\n",
       " ('sports', 1),\n",
       " ('tabtransformer', 1),\n",
       " ('tricks', 2),\n",
       " ('karl', 1),\n",
       " ('synthesizing', 3),\n",
       " ('math', 2),\n",
       " ('emotive', 2),\n",
       " ('distance-aware', 1),\n",
       " ('versus', 1),\n",
       " ('ruite:', 1),\n",
       " ('pushing', 2),\n",
       " ('regulators', 1),\n",
       " ('formation', 2),\n",
       " ('rediscover', 1),\n",
       " ('perturbations', 2),\n",
       " ('analysing', 2),\n",
       " ('paratope', 1),\n",
       " ('long-read', 1),\n",
       " ('(shl)', 1),\n",
       " ('diode', 1),\n",
       " ('version', 1),\n",
       " ('coordinated', 1),\n",
       " ('cnn-self-attention', 1),\n",
       " ('stand-alone', 1),\n",
       " ('end-to-end,', 2),\n",
       " ('decoder-only', 1),\n",
       " ('speed,', 1),\n",
       " ('poat-net:', 1),\n",
       " ('energy', 12),\n",
       " ('correction', 10),\n",
       " ('channel', 5),\n",
       " ('deepanis:', 1),\n",
       " ('shifter', 2),\n",
       " ('multi-instance', 2),\n",
       " ('arbitrary', 3),\n",
       " ('concept', 3),\n",
       " ('separable', 2),\n",
       " ('collider', 1),\n",
       " ('synchronous', 3),\n",
       " ('adjustable', 1),\n",
       " ('definition', 1),\n",
       " ('semask:', 1),\n",
       " ('m6:', 1),\n",
       " ('visualizing', 2),\n",
       " ('it', 2),\n",
       " ('lcl', 1),\n",
       " ('deep3dranker:', 1),\n",
       " ('blind', 4),\n",
       " ('context-dependent', 1),\n",
       " ('sub-graph', 1),\n",
       " ('clothing', 2),\n",
       " ('surprise', 1),\n",
       " ('protagonist-aware', 1),\n",
       " ('numerical', 2),\n",
       " ('$\\\\mathcal{laja}{-}$', 1),\n",
       " ('margins', 1),\n",
       " ('hat-net:', 1),\n",
       " ('loss', 9),\n",
       " ('measure', 3),\n",
       " ('marathi', 3),\n",
       " ('text-to-text', 16),\n",
       " ('losses', 2),\n",
       " ('retrosynthesis', 2),\n",
       " ('iiitt@lt-edi-eacl2021-hope', 1),\n",
       " ('imagery', 4),\n",
       " ('size', 5),\n",
       " ('retinopathy', 3),\n",
       " ('effective', 16),\n",
       " ('liquids', 1),\n",
       " ('...', 1),\n",
       " ('vqa', 2),\n",
       " ('flux', 1),\n",
       " ('distress', 2),\n",
       " ('sam-gan:', 1),\n",
       " ('turn', 2),\n",
       " ('enlivening', 1),\n",
       " ('paragraph-level', 2),\n",
       " ('nystroumlmformer:', 1),\n",
       " ('zero-resource', 1),\n",
       " ('java', 1),\n",
       " ('paragraph', 1),\n",
       " ('got', 1),\n",
       " ('aligning', 1),\n",
       " ('humourous', 1),\n",
       " ('transformer-xl', 2),\n",
       " ('chip', 2),\n",
       " ('character-level', 2),\n",
       " ('performing', 1),\n",
       " ('dance', 3),\n",
       " ('multi-band', 1),\n",
       " ('semi-structured', 1),\n",
       " ('multiport', 1),\n",
       " ('3m-transformers', 1),\n",
       " ('25.4%', 1),\n",
       " ('ouvert', 1),\n",
       " ('structures:', 1),\n",
       " ('sparsely', 1),\n",
       " ('transduction', 1),\n",
       " ('competing', 2),\n",
       " ('cooking', 1),\n",
       " ('chemical', 3),\n",
       " ('ofhands', 1),\n",
       " ('graph-augmented', 1),\n",
       " ('hcit:', 1),\n",
       " ('k-nn', 1),\n",
       " ('bash', 1),\n",
       " ('microcontroller', 1),\n",
       " ('interpret:', 1),\n",
       " ('ucatr:', 1),\n",
       " ('question-aware', 1),\n",
       " ('panoptic', 2),\n",
       " ('eliza?', 1),\n",
       " ('me:', 1),\n",
       " ('foundation', 1),\n",
       " ('codemixfire2021:', 1),\n",
       " ('xlnet', 2),\n",
       " ('contextualised', 1),\n",
       " ('scaffold', 1),\n",
       " ('image', 216),\n",
       " ('vision-language', 4),\n",
       " ('attngan', 1),\n",
       " ('android', 1),\n",
       " ('monocular', 5),\n",
       " ('cause', 3),\n",
       " ('pvg', 1),\n",
       " ('equal', 1),\n",
       " ('questions', 7),\n",
       " ('min-cost', 1),\n",
       " ('self-attentional', 2),\n",
       " ('speech-to-animation', 1),\n",
       " ('manufacturing', 1),\n",
       " ('compensation', 2),\n",
       " ('relapse', 1),\n",
       " ('intrusion', 1),\n",
       " ('solution', 2),\n",
       " ('fed', 3),\n",
       " ('receptor', 1),\n",
       " ('lithuanian', 1),\n",
       " ('sur', 1),\n",
       " ('let:', 1),\n",
       " ('more:', 1),\n",
       " ('notch', 1),\n",
       " ('prevent', 1),\n",
       " ('esters', 1),\n",
       " ('salience', 1),\n",
       " ('system', 46),\n",
       " ('hope', 8),\n",
       " ('probability', 1),\n",
       " ('roma', 1),\n",
       " ('tables', 2),\n",
       " ('electronic', 13),\n",
       " ('models:', 5),\n",
       " ('platforms', 2),\n",
       " ('convtransformer', 2),\n",
       " ('element', 4),\n",
       " ('in-phase', 1),\n",
       " ('visualization', 6),\n",
       " ('informer,', 1),\n",
       " ('punctuation,', 1),\n",
       " ('dealing', 1),\n",
       " ('asag', 1),\n",
       " ('patterns', 3),\n",
       " ('tweet', 1),\n",
       " ('ar-t:', 1),\n",
       " ('affect', 3),\n",
       " ('shatter:', 1),\n",
       " ('tank', 1),\n",
       " ('slot-filling', 1),\n",
       " ('affects', 2),\n",
       " ('behind', 1),\n",
       " ('foveated', 1),\n",
       " ('lexically', 2),\n",
       " ('transmot:', 1),\n",
       " ('phraseformer:', 1),\n",
       " ('surveillance', 1),\n",
       " ('double-split', 1),\n",
       " ('signals,', 2),\n",
       " ('kidney', 2),\n",
       " ('(french)', 1),\n",
       " ('geo-localization', 2),\n",
       " ('matching', 22),\n",
       " ('visual', 102),\n",
       " ('spelling', 3),\n",
       " ('current', 28),\n",
       " ('text-to-speech', 2),\n",
       " ('sige', 3),\n",
       " ('them', 1),\n",
       " ('1:', 4),\n",
       " ('patch-based', 2),\n",
       " ('tension', 1),\n",
       " ('receptive', 2),\n",
       " ('nast:', 1),\n",
       " ('quantized', 3),\n",
       " ('preference', 1),\n",
       " ('risks', 2),\n",
       " ('guide', 1),\n",
       " ('binary', 2),\n",
       " ('updates', 2),\n",
       " ('feeding', 1),\n",
       " ('baseline', 1),\n",
       " ('foil', 1),\n",
       " ('jump', 1),\n",
       " ('obfuscated', 1),\n",
       " ('delivery', 1),\n",
       " ('studying', 2),\n",
       " ('offset-attention', 1),\n",
       " ('adns', 1),\n",
       " ('blockwise', 1),\n",
       " ('customer', 1),\n",
       " ('magnetoresistance', 1),\n",
       " ('automatic', 38),\n",
       " ('estimation', 57),\n",
       " ('dialogue', 18),\n",
       " ('nn', 1),\n",
       " ('stformer:', 1),\n",
       " ('through', 26),\n",
       " ('outcome', 2),\n",
       " ('hand', 4),\n",
       " ('enumeration', 1),\n",
       " ('dual-path', 6),\n",
       " ('aircraft', 2),\n",
       " ('sensor', 4),\n",
       " ('single-headed', 1),\n",
       " ('generalizing', 2),\n",
       " ('ultra-high', 1),\n",
       " ('pet', 1),\n",
       " ('computed', 2),\n",
       " ('cloth', 1),\n",
       " ('mt6:', 1),\n",
       " ('force', 2),\n",
       " ('emsvit:', 1),\n",
       " ('sdtp:', 1),\n",
       " ('grapheme-to-phoneme', 2),\n",
       " ('serial-parallel', 1),\n",
       " ('varying', 1),\n",
       " ('lexicon', 1),\n",
       " ('adverse', 2),\n",
       " ('vitae:', 1),\n",
       " ('dyngraphtrans:', 1),\n",
       " ('slu', 1),\n",
       " ('intel.', 1),\n",
       " ('cross-model', 1),\n",
       " ('attention/', 1),\n",
       " ('who', 1),\n",
       " ('contributions', 1),\n",
       " ('consistency', 3),\n",
       " ('high', 20),\n",
       " ('refined', 2),\n",
       " ('armour:', 1),\n",
       " ('fbg-pzt', 1),\n",
       " ('generative', 37),\n",
       " ('gpu', 3),\n",
       " ('encoding-decoding', 1),\n",
       " ('implicitly', 1),\n",
       " ('severity', 2),\n",
       " ('interpretability', 5),\n",
       " ('survey', 9),\n",
       " ('sexist', 1),\n",
       " ('edge-augmented', 1),\n",
       " ('186.5dbc/hz', 1),\n",
       " ('vae', 3),\n",
       " ('reform', 1),\n",
       " ('vidtr:', 1),\n",
       " ('transcribing', 1),\n",
       " ('message-level', 1),\n",
       " ('metric', 2),\n",
       " ('fuseformer:', 1),\n",
       " ('stop-band', 1),\n",
       " ('long-text', 1),\n",
       " ('tale:', 1),\n",
       " ('vitt:', 1),\n",
       " ('win-win', 1),\n",
       " ('phase', 7),\n",
       " ('flow', 13),\n",
       " ('matter:', 1),\n",
       " ('essay', 2),\n",
       " ('south', 1),\n",
       " ('densenet', 1),\n",
       " ('navigate', 1),\n",
       " ('rl', 1),\n",
       " ('rotating', 2),\n",
       " ('need:', 4),\n",
       " ('balanced', 3),\n",
       " ('multidimensional', 2),\n",
       " ('miniature', 1),\n",
       " ('dlsa:', 1),\n",
       " ('abstractive', 6),\n",
       " ('zsi', 1),\n",
       " ('available', 1),\n",
       " ('concrete', 1),\n",
       " ('full-song', 2),\n",
       " ('wug', 1),\n",
       " ('axial', 4),\n",
       " ('patent', 2),\n",
       " ('neuromorphic', 1),\n",
       " ('tube-transformer', 1),\n",
       " ('thermal-fluid', 1),\n",
       " ('dot:', 1),\n",
       " ('full-tilt', 1),\n",
       " ('mt-transunet:', 1),\n",
       " ('occurrence', 1),\n",
       " ('multi-leg', 1),\n",
       " ('u-net', 12),\n",
       " ('field', 9),\n",
       " ('sampling', 7),\n",
       " ('melt', 1),\n",
       " ('cnns', 9),\n",
       " ('programmers', 2),\n",
       " ('shorts', 1),\n",
       " ('security', 2),\n",
       " ('polyu-cbs', 1),\n",
       " ('chords:', 1),\n",
       " ('preprocessing:', 1),\n",
       " ('focal', 2),\n",
       " ('differential-mode', 1),\n",
       " ('strategic', 1),\n",
       " ('smooth', 1),\n",
       " ('histology', 1),\n",
       " ('inflection', 1),\n",
       " ('clone', 1),\n",
       " ('patients', 2),\n",
       " ('throw', 1),\n",
       " ('grid-tied', 1),\n",
       " ('sinusoidal', 1),\n",
       " ('walkable', 1),\n",
       " ('algerian', 1),\n",
       " ('latr:', 1),\n",
       " ('cross-resolution', 1),\n",
       " ('primordial', 1),\n",
       " ('era', 2),\n",
       " ('array-based', 1),\n",
       " ('joint-flexible', 1),\n",
       " ('dct:', 1),\n",
       " ('checkthat!\\xa02021:', 5),\n",
       " ('exploration', 7),\n",
       " ('localizing', 2),\n",
       " ('cotr:', 3),\n",
       " ('classifier', 7),\n",
       " ('stvgbert:', 1),\n",
       " ('well-known', 1),\n",
       " ('(mmc)', 1),\n",
       " ('ecg', 6),\n",
       " ('learnable', 3),\n",
       " ('editable', 1),\n",
       " ('auto-encoderfor', 1),\n",
       " ('claw', 1),\n",
       " ('fpgas', 1),\n",
       " ('variations', 2),\n",
       " ('transcmd:', 1),\n",
       " ('category-level', 1),\n",
       " ('trend', 1),\n",
       " ('classifying', 4),\n",
       " ('anti-noise', 1),\n",
       " ('mlp-mixers', 1),\n",
       " ('low-voltage', 2),\n",
       " ('backdoor', 1),\n",
       " ('crowdsourced', 1),\n",
       " ('usefulness', 1),\n",
       " ('grained', 1),\n",
       " ('outside', 1),\n",
       " ('more', 10),\n",
       " ('path', 7),\n",
       " ('upconverter', 1),\n",
       " ('world', 2),\n",
       " ('dialog', 8),\n",
       " ('very', 3),\n",
       " ('fight', 2),\n",
       " ('topic', 5),\n",
       " ('capacitive', 3),\n",
       " ('remote', 23),\n",
       " ('perceptron', 1),\n",
       " ('instructions', 2),\n",
       " ('crossing', 2),\n",
       " ('text2gestures:', 2),\n",
       " ('query2label:', 1),\n",
       " ('out-of-distribution', 4),\n",
       " ('transformer-transducers', 1),\n",
       " ('skeletal', 2),\n",
       " ('preparation', 1),\n",
       " ('boogie', 1),\n",
       " ('layouts', 1),\n",
       " ('slice', 1),\n",
       " ('fighting', 1),\n",
       " ('pid', 1),\n",
       " ('role-guided', 1),\n",
       " ('abstracted', 1),\n",
       " ('nested-block', 1),\n",
       " ('overlapping', 1),\n",
       " ('phrasing', 1),\n",
       " ('snowflakenet:', 1),\n",
       " ('objectives', 1),\n",
       " ('all', 18),\n",
       " ('shuffle', 4),\n",
       " ('guarantee', 1),\n",
       " ('answer', 4),\n",
       " ('application', 23),\n",
       " ('step-up', 6),\n",
       " ('gestures', 3),\n",
       " ('dpnet:', 1),\n",
       " ('outcomes', 2),\n",
       " ('see', 2),\n",
       " ('gigapixel', 1),\n",
       " ('socio-temporal', 1),\n",
       " ('asymmetric', 3),\n",
       " ('split', 2),\n",
       " ('conformal', 1),\n",
       " ('profiling', 2),\n",
       " ('decoders', 2),\n",
       " ('indigenous', 1),\n",
       " ('transfusion:', 1),\n",
       " ('sml:', 1),\n",
       " ('contactless', 1),\n",
       " ('extremely', 1),\n",
       " ('ammu', 1),\n",
       " ('skip-transformer', 1),\n",
       " ('mobile-friendly', 1),\n",
       " ('sectioned', 1),\n",
       " ('using', 358),\n",
       " ('awake', 1),\n",
       " ('vortx:', 1),\n",
       " ('self-similarity', 1),\n",
       " ('captioning', 25),\n",
       " ('combining', 15),\n",
       " ('au', 2),\n",
       " ('sit:', 1),\n",
       " ('simplified', 2),\n",
       " ('communities', 1),\n",
       " ('result', 1),\n",
       " ('teaching', 1),\n",
       " ('crossformer:', 1),\n",
       " ('hypernetworks', 1),\n",
       " ('octree', 1),\n",
       " ('meta-learning', 3),\n",
       " ('technical', 1),\n",
       " ('input-output', 1),\n",
       " ('cnns:', 2),\n",
       " ('posegate-former:', 1),\n",
       " ('bushing', 1),\n",
       " ('potentials', 1),\n",
       " ('titles', 1),\n",
       " ('fields:', 1),\n",
       " ('traveling', 1),\n",
       " ('edione@lt-edi-eacl2021:', 1),\n",
       " ('light-weight,', 1),\n",
       " ('multi-gpu', 1),\n",
       " ('reveal', 1),\n",
       " ('subformer:', 1),\n",
       " ('aggregating', 1),\n",
       " ('linearly', 1),\n",
       " ('records', 7),\n",
       " ('segmentation', 130),\n",
       " ('disease', 13),\n",
       " ('communication', 6),\n",
       " ('subtypes', 1),\n",
       " ('glaucoma', 1),\n",
       " ('life', 12),\n",
       " ('advance', 1),\n",
       " ('bi-lstm', 3),\n",
       " ('trained', 3),\n",
       " ('ut-atd:', 1),\n",
       " ('certified', 2),\n",
       " ('pluralistic', 1),\n",
       " ('transformation', 4),\n",
       " ('psg@hasoc-dravidian', 1),\n",
       " ('micrographs', 1),\n",
       " ('localisation', 1),\n",
       " ('textcnn', 1),\n",
       " ('prelayernorm', 1),\n",
       " ('tunneling', 1),\n",
       " ('hippocampal', 1),\n",
       " ('onset', 1),\n",
       " ('vsc', 1),\n",
       " ('bat:', 1),\n",
       " ('bilingual', 2),\n",
       " ('h10', 1),\n",
       " ('improvisation:', 1),\n",
       " ('supervising', 1),\n",
       " ('sotr:', 1),\n",
       " ('fits', 1),\n",
       " ('modules', 1),\n",
       " ('trans2seg:', 1),\n",
       " ('dual-mode', 3),\n",
       " ('sexism', 5),\n",
       " ('completion', 13),\n",
       " ('recognize', 1),\n",
       " ('permutation-invariant', 1),\n",
       " ('continuous-time', 2),\n",
       " ('embeddings', 17),\n",
       " ('identifiable', 1),\n",
       " ('alibaba', 1),\n",
       " ('lightgbm', 1),\n",
       " ('self-slimmed', 1),\n",
       " (\"achilles'\", 2),\n",
       " ('hitter:', 1),\n",
       " ('rate', 4),\n",
       " ('speech-to-text', 3),\n",
       " ('sat', 1),\n",
       " ('unbalance', 1),\n",
       " ('end', 7),\n",
       " ('multichannel', 1),\n",
       " ('free,', 1),\n",
       " ('capacitors', 1),\n",
       " ('dual-learning', 1),\n",
       " ('arrangement', 1),\n",
       " ('decoder-end', 1),\n",
       " ('dyadformer:', 1),\n",
       " ('achieving', 1),\n",
       " ('t2t', 1),\n",
       " ('interleaved', 4),\n",
       " ('discrete', 4),\n",
       " ('too', 1),\n",
       " ('guiding', 3),\n",
       " ('forward', 2),\n",
       " ('link', 3),\n",
       " ('pretraining', 13),\n",
       " ('operation', 7),\n",
       " ('tweets', 10),\n",
       " ('60ghz', 1),\n",
       " ('un', 2),\n",
       " ('moving', 2),\n",
       " ('mlp', 4),\n",
       " ('w911nf1910069', 1),\n",
       " ('multiplicative', 1),\n",
       " ('hsan:', 1),\n",
       " ('setting', 3),\n",
       " ('embracing', 1),\n",
       " ('sparsebert:', 1),\n",
       " ('burn-in', 1),\n",
       " ('de', 2),\n",
       " ('bft', 1),\n",
       " ('extraction:', 1),\n",
       " ('anti-spoofing', 1),\n",
       " ('stroke', 2),\n",
       " ('local-feature', 1),\n",
       " ('patch-level', 1),\n",
       " ('fmri', 1),\n",
       " ('gophormer:', 1),\n",
       " ('trial', 2),\n",
       " ('agreement', 3),\n",
       " ('high-impedance', 1),\n",
       " ('right', 2),\n",
       " ('git:', 1),\n",
       " ('spatial', 32),\n",
       " ('making', 2),\n",
       " ('modulation', 7),\n",
       " ('ingredients', 1),\n",
       " ('lenses', 1),\n",
       " ('theme', 1),\n",
       " ('paralinguistic', 1),\n",
       " ('poi', 2),\n",
       " ('shallow', 2),\n",
       " ('reporting', 1),\n",
       " ('therapy', 1),\n",
       " ('mind', 2),\n",
       " ('infer', 1),\n",
       " ('uzh', 1),\n",
       " ('bloomnet:', 1),\n",
       " ('stransgan:', 1),\n",
       " ('improvement', 2),\n",
       " ('traveling-waves-based', 1),\n",
       " ('layer-wise', 1),\n",
       " ('oadtr:', 1),\n",
       " ('sgtr:', 1),\n",
       " ('transzero++:', 1),\n",
       " ('input-aware', 1),\n",
       " ('pnp-detr:', 1),\n",
       " ('grid', 12),\n",
       " ('fine-grained', 28),\n",
       " ('cross-transformer', 1),\n",
       " ('anomaly', 21),\n",
       " ('risc-vtf:', 1),\n",
       " ('simulation', 7),\n",
       " ('family:', 1),\n",
       " ('partitioning', 2),\n",
       " ('multilevel', 5),\n",
       " ('codes', 2),\n",
       " ('dielectric', 5),\n",
       " ('colonoscopy', 1),\n",
       " ('structure?', 1),\n",
       " ('(bert)-based', 1),\n",
       " ('transformer-free', 2),\n",
       " ('nasformer:', 1),\n",
       " ('albums', 1),\n",
       " ('cycle-consistent', 2),\n",
       " ('self-stabilizing', 1),\n",
       " ('enabling', 4),\n",
       " ('propagation-based', 1),\n",
       " ('soft:', 1),\n",
       " ('knowledge-aware', 1),\n",
       " ('boosted', 1),\n",
       " ('technological', 1),\n",
       " ('deephealth:', 1),\n",
       " ('performer', 1),\n",
       " ('multi-branch', 2),\n",
       " ('hitrans:', 1),\n",
       " ('fractional-n', 1),\n",
       " ('top-k', 1),\n",
       " ('certification', 1),\n",
       " ('story-based', 1),\n",
       " ('vaccine', 1),\n",
       " ('controllable', 7),\n",
       " ('new', 24),\n",
       " ('convolution-augmented', 1),\n",
       " ('pitch', 1),\n",
       " ('simple', 19),\n",
       " ('composite', 3),\n",
       " ('pass', 2),\n",
       " ('spacer', 1),\n",
       " ('bossnas:', 1),\n",
       " ('patchout', 1),\n",
       " ('anonymity', 1),\n",
       " ('news:', 1),\n",
       " ('connections', 2),\n",
       " ('influence', 7),\n",
       " ('mltr:', 1),\n",
       " ('vtnet:', 1),\n",
       " ('high-voltage', 4),\n",
       " ('inverters', 2),\n",
       " ('intestine', 1),\n",
       " ('conv-attentional', 1),\n",
       " ('call', 1),\n",
       " ('way', 3),\n",
       " ('change', 3),\n",
       " ('spoken', 3),\n",
       " ('sctn:', 1),\n",
       " ('corticalflow:', 1),\n",
       " ('modetr:', 1),\n",
       " ('half-bridge', 1),\n",
       " ('polynomials', 1),\n",
       " ('array', 1),\n",
       " ('point-wise', 1),\n",
       " ('stst:', 1),\n",
       " ('diformer:', 1),\n",
       " ('ssast:', 1),\n",
       " ('nanocrystalline', 1),\n",
       " ('locformer:', 1),\n",
       " ('semeval-2021', 19),\n",
       " ('beyond:', 1),\n",
       " ('solvers', 1),\n",
       " ('quantization', 6),\n",
       " (\"what's\", 4),\n",
       " ('bias', 13),\n",
       " ('vulnerability', 3),\n",
       " ('particle', 5),\n",
       " ('maddpg', 1),\n",
       " ('interference', 3),\n",
       " ('finite', 3),\n",
       " ('ms-tct:', 1),\n",
       " ('omni-relational', 1),\n",
       " ('genome', 2),\n",
       " ('transgan:', 2),\n",
       " ('association', 3),\n",
       " ('aesthetic', 2),\n",
       " ('battery-grid', 1),\n",
       " ('dv/dt', 1),\n",
       " ('electra', 3),\n",
       " ('non-rigid', 1),\n",
       " ('continuity', 1),\n",
       " ('cluster', 1),\n",
       " ('roberta,', 1),\n",
       " ('power-transformer', 1),\n",
       " ('utnet:', 1),\n",
       " ('ava:', 1),\n",
       " ('are', 23),\n",
       " ('exploring', 27),\n",
       " ('understanding.', 1),\n",
       " ('question', 38),\n",
       " ('sequence:', 1),\n",
       " ('feacuteidir', 1),\n",
       " ('dehazing', 1),\n",
       " ('textcaps', 2),\n",
       " ('frame', 3),\n",
       " ('inheritance', 1),\n",
       " ('loftr:', 1),\n",
       " ('cross-scale', 1),\n",
       " ('anti-aliasing', 1),\n",
       " ('pu-transformer:', 1),\n",
       " ('sharing', 3),\n",
       " ('single-head?', 1),\n",
       " ('neurosymbolic', 1),\n",
       " ('redistribution', 1),\n",
       " ('time-reduction', 1),\n",
       " ('asset', 1),\n",
       " ('agent-aware', 1),\n",
       " ('native', 1),\n",
       " ('training:', 1),\n",
       " ('normalized', 1),\n",
       " ('tcl:', 1),\n",
       " ('dilated', 4),\n",
       " ('@finsim-2:', 1),\n",
       " ('location-guided', 1),\n",
       " ('id', 1),\n",
       " ('wavetransformer:', 1),\n",
       " ('pso', 1),\n",
       " ('capabilities', 2),\n",
       " ('makes', 3),\n",
       " ('early', 6),\n",
       " ('preservation', 1),\n",
       " ('segmentations', 1),\n",
       " ('gn-transformer:', 1),\n",
       " ('learn', 4),\n",
       " ('grid-connected', 7),\n",
       " ('creation', 1),\n",
       " ('key', 2),\n",
       " ('food', 1),\n",
       " ('concatenated', 2),\n",
       " ('prosodic', 1),\n",
       " ('saturation', 2),\n",
       " ('prose', 1),\n",
       " ('displacement', 2),\n",
       " ('ma-bert:', 1),\n",
       " ('astronomy', 1),\n",
       " ('linguistique', 1),\n",
       " ('nvit:', 1),\n",
       " ('transnet:', 1),\n",
       " ('autotrans:', 1),\n",
       " ('describing', 1),\n",
       " ('development', 4),\n",
       " ('quasi-steady-state', 1),\n",
       " ('semg', 1),\n",
       " ('decoder', 13),\n",
       " ('consumer', 5),\n",
       " ('oils', 1),\n",
       " ('asformer:', 1),\n",
       " ('stepping', 1),\n",
       " ('est', 1),\n",
       " ('variant', 2),\n",
       " ('units', 1),\n",
       " ('\"the', 2),\n",
       " ('soe-net:', 1),\n",
       " ('low-dimensional', 3),\n",
       " ('representation?', 2),\n",
       " ('orthogonality', 2),\n",
       " ('conventional', 2),\n",
       " ('opportunities', 1),\n",
       " ('equipped', 1),\n",
       " ('cuk', 1),\n",
       " ('musicoder:', 1),\n",
       " ('assembly', 1),\n",
       " ('mutation', 1),\n",
       " ('minimize', 1),\n",
       " ('legoformer:', 1),\n",
       " ('small-dim', 1),\n",
       " ('linearizer', 1),\n",
       " ('neuro-fuzzy', 1),\n",
       " ('vsec:', 1),\n",
       " ('house', 1),\n",
       " ('conceptual', 1),\n",
       " ('for', 1623),\n",
       " ('summarizers', 1),\n",
       " ('model-based', 2),\n",
       " ('inside', 2),\n",
       " ('multilayer', 2),\n",
       " ('driving', 9),\n",
       " ('switching', 4),\n",
       " ('approximation:', 1),\n",
       " ('fine-tuned', 3),\n",
       " ('non-repetitive', 1),\n",
       " ('joy', 1),\n",
       " ('transport', 1),\n",
       " ('crackformer:', 1),\n",
       " ('multi-scales', 1),\n",
       " ('risc-v', 1),\n",
       " ('in______', 1),\n",
       " ('chronic', 1),\n",
       " ('half', 1),\n",
       " ('been', 1),\n",
       " ('deepprog:', 1),\n",
       " ('times', 1),\n",
       " ('background/foreground', 1),\n",
       " ('dbia:', 1),\n",
       " ('multi-stacked', 1),\n",
       " ('packaging', 1),\n",
       " ('operating', 1),\n",
       " ('explanation', 1),\n",
       " ('vit-p:', 1),\n",
       " ('bi-order-transformer-crf', 1),\n",
       " ('amplifiers', 1),\n",
       " ('ventilation', 1),\n",
       " ('refraction', 1),\n",
       " ('vqgan', 1),\n",
       " ('medication-effect', 1),\n",
       " ('scene', 35),\n",
       " ('sentinel-2', 2),\n",
       " ('universal', 23),\n",
       " ('compensating', 3),\n",
       " ('tracing', 7),\n",
       " ('primates', 1),\n",
       " ('single-inductor', 1),\n",
       " ('persformer:', 1),\n",
       " ('unet-like', 1),\n",
       " ('ultra-compact', 1),\n",
       " ('gpt', 1),\n",
       " ('goal-oriented', 1),\n",
       " ('classification?', 1),\n",
       " ('hot', 2),\n",
       " ('software-equivalent', 1),\n",
       " ('cassava', 1),\n",
       " ('best', 1),\n",
       " ('business', 3),\n",
       " ('accommodating', 1),\n",
       " ('tp-ddi:', 1),\n",
       " ('10:', 1),\n",
       " ('specialized', 1),\n",
       " ('all-pass', 1),\n",
       " ('long-tail', 1),\n",
       " ('syntactic-guided', 1),\n",
       " ('reliability', 1),\n",
       " ('cervical', 1),\n",
       " ('convolution,', 1),\n",
       " ('oximetry', 1),\n",
       " ('nodules', 1),\n",
       " ('asrs', 1),\n",
       " ('wireless', 1),\n",
       " ('inter-resonance', 1),\n",
       " ('engines?', 1),\n",
       " ('trufm:', 1),\n",
       " ('shared', 8),\n",
       " ('evaluating', 8),\n",
       " ('translating', 3),\n",
       " ('attenuation', 1),\n",
       " ('shows', 1),\n",
       " ('hard', 2),\n",
       " ('constraining', 1),\n",
       " ('3d/4d', 1),\n",
       " ('text-transformers', 1),\n",
       " ('healthcare', 3),\n",
       " ('learning-to-rank', 1),\n",
       " ('multi-output', 2),\n",
       " ('humans', 1),\n",
       " ('crisis', 2),\n",
       " ('enables', 1),\n",
       " ('tri-coil', 1),\n",
       " ('meshed', 2),\n",
       " ('cs60075_team2', 1),\n",
       " ('evolution', 1),\n",
       " ('retinopathy-related', 1),\n",
       " ('tera:', 1),\n",
       " ('trseg:', 1),\n",
       " ('ladders', 1),\n",
       " ('updating', 1),\n",
       " ('dqn', 1),\n",
       " ('bootstrapping', 1),\n",
       " ('optimization', 16),\n",
       " ('feature', 36),\n",
       " ('gpt,', 1),\n",
       " ('tag', 1),\n",
       " ('constrained', 5),\n",
       " ('vit:', 2),\n",
       " ('test', 6),\n",
       " ('patnet', 1),\n",
       " ('high-gain', 1),\n",
       " ('query-based', 2),\n",
       " ('recom', 1),\n",
       " ('consistent', 2),\n",
       " ('combinative', 1),\n",
       " ('(okgm)', 1),\n",
       " ('trajectories', 1),\n",
       " ('pairs', 3),\n",
       " ('one-step', 1),\n",
       " ('recipes', 2),\n",
       " ('mixer', 2),\n",
       " ('near', 2),\n",
       " ('rubiks', 1),\n",
       " ('polyp-pvt:', 1),\n",
       " ('criteria', 1),\n",
       " ('resnets', 2),\n",
       " ('plan', 1),\n",
       " ('viewers', 1),\n",
       " ('mutual-relation', 1),\n",
       " ('two-stream', 3),\n",
       " ('repositioning', 1),\n",
       " ('voltage-regulation', 1),\n",
       " ('unknown:', 1),\n",
       " ('medium-', 1),\n",
       " ('pipelined', 1),\n",
       " ('rules', 1),\n",
       " ('analysis', 93),\n",
       " ('convolutions', 9),\n",
       " ('complex', 5),\n",
       " ('imaging', 6),\n",
       " ('generator', 1),\n",
       " ('tt2inet:', 1),\n",
       " ('cyber-physical', 2),\n",
       " ('autoencoders', 2),\n",
       " ('subjected', 1),\n",
       " ('detect', 6),\n",
       " ('sa-hardnest:', 1),\n",
       " ('dependency-scaled', 1),\n",
       " ('boundaries', 1),\n",
       " ('soit:', 1),\n",
       " ('bioasq9b', 1),\n",
       " ('frequency-domain', 2),\n",
       " ('sentences', 2),\n",
       " ('pi+passivity-based', 1),\n",
       " ('insertion-based', 1),\n",
       " ('transformesh:', 1),\n",
       " ('ordering', 1),\n",
       " ('construction', 2),\n",
       " ('side-scan', 1),\n",
       " ('novel', 34),\n",
       " ('mldt:', 1),\n",
       " ('opinion', 6),\n",
       " ('regularization', 2),\n",
       " ('teasel:', 1),\n",
       " ('parameter', 9),\n",
       " ('investigating', 4),\n",
       " ('date:', 2),\n",
       " ('learning-based', 2),\n",
       " ('three-dimensional', 1),\n",
       " ('dissolved', 2),\n",
       " ('cvt', 1),\n",
       " ('statistical', 5),\n",
       " ('try-on', 1),\n",
       " ('attend', 3),\n",
       " ('structext:', 1),\n",
       " ('65-nm', 3),\n",
       " ('out-domain', 1),\n",
       " ('theoretical', 1),\n",
       " ('attentionlite:', 1),\n",
       " ('produce', 1),\n",
       " ('rug:', 1),\n",
       " ('spoiler', 1),\n",
       " ('calligraphic', 1),\n",
       " ('far', 1),\n",
       " ('vertical', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(feature, occ_in_corpus(1+1+1...)) : sum of count of title with feature for each feature (group by feature)\n",
    "reduce2=map4.reduceByKey(lambda x,y:x+y)\n",
    "reduce2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "58352a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 10.100224295874192),\n",
       " ('couplet', 10.685186796595348),\n",
       " ('an', 5.08527395440822),\n",
       " ('2d', 8.685186796595348),\n",
       " ('step', 10.100224295874192),\n",
       " ('quality', 7.363258701707985),\n",
       " ('matters', 10.685186796595348),\n",
       " ('policy', 10.100224295874192),\n",
       " ('carlo', 10.685186796595348),\n",
       " ('cognlp-sheffield', 10.685186796595348),\n",
       " ('solve', 9.363258701707986),\n",
       " ('maritime', 10.685186796595348),\n",
       " ('shell-type', 10.100224295874192),\n",
       " ('temgnet:', 10.685186796595348),\n",
       " ('standards', 10.685186796595348),\n",
       " ('doubler', 10.685186796595348),\n",
       " ('everything', 10.100224295874192),\n",
       " ('asr,', 10.685186796595348),\n",
       " ('plates', 10.685186796595348),\n",
       " ('am-lstm', 10.685186796595348),\n",
       " ('wide-range', 10.685186796595348),\n",
       " ('rooftops', 10.685186796595348),\n",
       " ('process:', 10.685186796595348),\n",
       " ('readonce', 10.685186796595348),\n",
       " ('colorectal', 10.685186796595348),\n",
       " ('orange', 10.685186796595348),\n",
       " ('restaurant', 10.685186796595348),\n",
       " ('cs-um6p', 10.685186796595348),\n",
       " ('sence', 10.685186796595348),\n",
       " ('unsupervised', 6.730990486208472),\n",
       " ('how', 8.100224295874192),\n",
       " ('media', 8.22575517795805),\n",
       " ('two-way', 10.685186796595348),\n",
       " ('leakage', 8.515261795153036),\n",
       " ('lm', 10.685186796595348),\n",
       " ('representational', 10.100224295874192),\n",
       " ('icd-10', 10.100224295874192),\n",
       " ('speeding', 10.685186796595348),\n",
       " ('ufo-vit:', 10.685186796595348),\n",
       " ('integrating', 8.877831874537744),\n",
       " ('task:', 8.685186796595348),\n",
       " ('marbert:', 10.685186796595348),\n",
       " ('nearest', 10.685186796595348),\n",
       " ('pilot:', 10.685186796595348),\n",
       " ('cosformer:', 10.685186796595348),\n",
       " ('soccer', 10.685186796595348),\n",
       " ('co-segmentation', 10.685186796595348),\n",
       " ('knn', 10.685186796595348),\n",
       " ('leads', 10.685186796595348),\n",
       " ('generic', 10.685186796595348),\n",
       " ('s2s-ft:', 10.685186796595348),\n",
       " ('reordering', 10.685186796595348),\n",
       " ('crops', 10.685186796595348),\n",
       " ('communicative', 10.100224295874192),\n",
       " ('entity-and-relation', 10.685186796595348),\n",
       " ('retraining', 10.685186796595348),\n",
       " ('japanese', 10.685186796595348),\n",
       " ('updet:', 10.100224295874192),\n",
       " ('exist2021:', 10.685186796595348),\n",
       " ('ct-cad:', 10.685186796595348),\n",
       " ('network-driven', 10.685186796595348),\n",
       " ('re-interpreting', 10.685186796595348),\n",
       " ('what,', 10.685186796595348),\n",
       " ('distributional,', 10.685186796595348),\n",
       " ('faces', 10.685186796595348),\n",
       " ('cpus', 10.685186796595348),\n",
       " ('demystify', 10.685186796595348),\n",
       " ('voltage', 6.730990486208472),\n",
       " ('cooperative', 10.685186796595348),\n",
       " ('dc', 8.22575517795805),\n",
       " ('hybrid', 6.193333700265673),\n",
       " ('unwanted', 10.685186796595348),\n",
       " ('diabetic', 9.100224295874192),\n",
       " ('ndt-transformer:', 10.685186796595348),\n",
       " ('sports', 10.685186796595348),\n",
       " ('tabtransformer', 10.685186796595348),\n",
       " ('tricks', 10.100224295874192),\n",
       " ('karl', 10.685186796595348),\n",
       " ('synthesizing', 9.685186796595348),\n",
       " ('math', 10.100224295874192),\n",
       " ('emotive', 10.100224295874192),\n",
       " ('distance-aware', 10.685186796595348),\n",
       " ('versus', 10.685186796595348),\n",
       " ('ruite:', 10.685186796595348),\n",
       " ('pushing', 10.100224295874192),\n",
       " ('regulators', 10.685186796595348),\n",
       " ('formation', 10.100224295874192),\n",
       " ('rediscover', 10.685186796595348),\n",
       " ('perturbations', 10.100224295874192),\n",
       " ('analysing', 10.100224295874192),\n",
       " ('paratope', 10.685186796595348),\n",
       " ('long-read', 10.685186796595348),\n",
       " ('(shl)', 10.685186796595348),\n",
       " ('diode', 10.685186796595348),\n",
       " ('version', 10.685186796595348),\n",
       " ('coordinated', 10.685186796595348),\n",
       " ('cnn-self-attention', 10.685186796595348),\n",
       " ('stand-alone', 10.685186796595348),\n",
       " ('end-to-end,', 10.100224295874192),\n",
       " ('decoder-only', 10.685186796595348),\n",
       " ('speed,', 10.685186796595348),\n",
       " ('poat-net:', 10.685186796595348),\n",
       " ('energy', 7.984747078454255),\n",
       " ('correction', 8.22575517795805),\n",
       " ('channel', 9.100224295874192),\n",
       " ('deepanis:', 10.685186796595348),\n",
       " ('shifter', 10.100224295874192),\n",
       " ('multi-instance', 10.100224295874192),\n",
       " ('arbitrary', 9.685186796595348),\n",
       " ('concept', 9.685186796595348),\n",
       " ('separable', 10.100224295874192),\n",
       " ('collider', 10.685186796595348),\n",
       " ('synchronous', 9.685186796595348),\n",
       " ('adjustable', 10.685186796595348),\n",
       " ('definition', 10.685186796595348),\n",
       " ('semask:', 10.685186796595348),\n",
       " ('m6:', 10.685186796595348),\n",
       " ('visualizing', 10.100224295874192),\n",
       " ('it', 10.100224295874192),\n",
       " ('lcl', 10.685186796595348),\n",
       " ('deep3dranker:', 10.685186796595348),\n",
       " ('blind', 9.363258701707986),\n",
       " ('context-dependent', 10.685186796595348),\n",
       " ('sub-graph', 10.685186796595348),\n",
       " ('clothing', 10.100224295874192),\n",
       " ('surprise', 10.685186796595348),\n",
       " ('protagonist-aware', 10.685186796595348),\n",
       " ('numerical', 10.100224295874192),\n",
       " ('$\\\\mathcal{laja}{-}$', 10.685186796595348),\n",
       " ('margins', 10.685186796595348),\n",
       " ('hat-net:', 10.685186796595348),\n",
       " ('loss', 8.363258701707986),\n",
       " ('measure', 9.685186796595348),\n",
       " ('marathi', 9.685186796595348),\n",
       " ('text-to-text', 7.597723955345009),\n",
       " ('losses', 10.100224295874192),\n",
       " ('retrosynthesis', 10.100224295874192),\n",
       " ('iiitt@lt-edi-eacl2021-hope', 10.685186796595348),\n",
       " ('imagery', 9.363258701707986),\n",
       " ('size', 9.100224295874192),\n",
       " ('retinopathy', 9.685186796595348),\n",
       " ('effective', 7.597723955345009),\n",
       " ('liquids', 10.685186796595348),\n",
       " ('...', 10.685186796595348),\n",
       " ('vqa', 10.100224295874192),\n",
       " ('flux', 10.685186796595348),\n",
       " ('distress', 10.100224295874192),\n",
       " ('sam-gan:', 10.685186796595348),\n",
       " ('turn', 10.100224295874192),\n",
       " ('enlivening', 10.685186796595348),\n",
       " ('paragraph-level', 10.100224295874192),\n",
       " ('nystroumlmformer:', 10.685186796595348),\n",
       " ('zero-resource', 10.685186796595348),\n",
       " ('java', 10.685186796595348),\n",
       " ('paragraph', 10.685186796595348),\n",
       " ('got', 10.685186796595348),\n",
       " ('aligning', 10.685186796595348),\n",
       " ('humourous', 10.685186796595348),\n",
       " ('transformer-xl', 10.100224295874192),\n",
       " ('chip', 10.100224295874192),\n",
       " ('character-level', 10.100224295874192),\n",
       " ('performing', 10.685186796595348),\n",
       " ('dance', 9.685186796595348),\n",
       " ('multi-band', 10.685186796595348),\n",
       " ('semi-structured', 10.685186796595348),\n",
       " ('multiport', 10.685186796595348),\n",
       " ('3m-transformers', 10.685186796595348),\n",
       " ('25.4%', 10.685186796595348),\n",
       " ('ouvert', 10.685186796595348),\n",
       " ('structures:', 10.685186796595348),\n",
       " ('sparsely', 10.685186796595348),\n",
       " ('transduction', 10.685186796595348),\n",
       " ('competing', 10.100224295874192),\n",
       " ('cooking', 10.685186796595348),\n",
       " ('chemical', 9.685186796595348),\n",
       " ('ofhands', 10.685186796595348),\n",
       " ('graph-augmented', 10.685186796595348),\n",
       " ('hcit:', 10.685186796595348),\n",
       " ('k-nn', 10.685186796595348),\n",
       " ('bash', 10.685186796595348),\n",
       " ('microcontroller', 10.685186796595348),\n",
       " ('interpret:', 10.685186796595348),\n",
       " ('ucatr:', 10.685186796595348),\n",
       " ('question-aware', 10.685186796595348),\n",
       " ('panoptic', 10.100224295874192),\n",
       " ('eliza?', 10.685186796595348),\n",
       " ('me:', 10.685186796595348),\n",
       " ('foundation', 10.685186796595348),\n",
       " ('codemixfire2021:', 10.685186796595348),\n",
       " ('xlnet', 10.100224295874192),\n",
       " ('contextualised', 10.685186796595348),\n",
       " ('scaffold', 10.685186796595348),\n",
       " ('image', 3.9236355641508682),\n",
       " ('vision-language', 9.363258701707986),\n",
       " ('attngan', 10.685186796595348),\n",
       " ('android', 10.685186796595348),\n",
       " ('monocular', 9.100224295874192),\n",
       " ('cause', 9.685186796595348),\n",
       " ('pvg', 10.685186796595348),\n",
       " ('equal', 10.685186796595348),\n",
       " ('questions', 8.685186796595348),\n",
       " ('min-cost', 10.685186796595348),\n",
       " ('self-attentional', 10.100224295874192),\n",
       " ('speech-to-animation', 10.685186796595348),\n",
       " ('manufacturing', 10.685186796595348),\n",
       " ('compensation', 10.100224295874192),\n",
       " ('relapse', 10.685186796595348),\n",
       " ('intrusion', 10.685186796595348),\n",
       " ('solution', 10.100224295874192),\n",
       " ('fed', 9.685186796595348),\n",
       " ('receptor', 10.685186796595348),\n",
       " ('lithuanian', 10.685186796595348),\n",
       " ('sur', 10.685186796595348),\n",
       " ('let:', 10.685186796595348),\n",
       " ('more:', 10.685186796595348),\n",
       " ('notch', 10.685186796595348),\n",
       " ('prevent', 10.685186796595348),\n",
       " ('esters', 10.685186796595348),\n",
       " ('salience', 10.685186796595348),\n",
       " ('system', 6.13059794491771),\n",
       " ('hope', 8.515261795153036),\n",
       " ('probability', 10.685186796595348),\n",
       " ('roma', 10.685186796595348),\n",
       " ('tables', 10.100224295874192),\n",
       " ('electronic', 7.877831874537744),\n",
       " ('models:', 9.100224295874192),\n",
       " ('platforms', 10.100224295874192),\n",
       " ('convtransformer', 10.100224295874192),\n",
       " ('element', 9.363258701707986),\n",
       " ('in-phase', 10.685186796595348),\n",
       " ('visualization', 8.877831874537744),\n",
       " ('informer,', 10.685186796595348),\n",
       " ('punctuation,', 10.685186796595348),\n",
       " ('dealing', 10.685186796595348),\n",
       " ('asag', 10.685186796595348),\n",
       " ('patterns', 9.685186796595348),\n",
       " ('tweet', 10.685186796595348),\n",
       " ('ar-t:', 10.685186796595348),\n",
       " ('affect', 9.685186796595348),\n",
       " ('shatter:', 10.685186796595348),\n",
       " ('tank', 10.685186796595348),\n",
       " ('slot-filling', 10.685186796595348),\n",
       " ('affects', 10.100224295874192),\n",
       " ('behind', 10.685186796595348),\n",
       " ('foveated', 10.685186796595348),\n",
       " ('lexically', 10.100224295874192),\n",
       " ('transmot:', 10.685186796595348),\n",
       " ('phraseformer:', 10.685186796595348),\n",
       " ('surveillance', 10.685186796595348),\n",
       " ('double-split', 10.685186796595348),\n",
       " ('signals,', 10.100224295874192),\n",
       " ('kidney', 10.100224295874192),\n",
       " ('(french)', 10.685186796595348),\n",
       " ('geo-localization', 10.100224295874192),\n",
       " ('matching', 7.161624840538335),\n",
       " ('visual', 4.998686269412129),\n",
       " ('spelling', 9.685186796595348),\n",
       " ('current', 6.827205801467775),\n",
       " ('text-to-speech', 10.100224295874192),\n",
       " ('sige', 9.685186796595348),\n",
       " ('them', 10.685186796595348),\n",
       " ('1:', 9.363258701707986),\n",
       " ('patch-based', 10.100224295874192),\n",
       " ('tension', 10.685186796595348),\n",
       " ('receptive', 10.100224295874192),\n",
       " ('nast:', 10.685186796595348),\n",
       " ('quantized', 9.685186796595348),\n",
       " ('preference', 10.685186796595348),\n",
       " ('risks', 10.100224295874192),\n",
       " ('guide', 10.685186796595348),\n",
       " ('binary', 10.100224295874192),\n",
       " ('updates', 10.100224295874192),\n",
       " ('feeding', 10.685186796595348),\n",
       " ('baseline', 10.685186796595348),\n",
       " ('foil', 10.685186796595348),\n",
       " ('jump', 10.685186796595348),\n",
       " ('obfuscated', 10.685186796595348),\n",
       " ('delivery', 10.685186796595348),\n",
       " ('studying', 10.100224295874192),\n",
       " ('offset-attention', 10.685186796595348),\n",
       " ('adns', 10.685186796595348),\n",
       " ('blockwise', 10.685186796595348),\n",
       " ('customer', 10.685186796595348),\n",
       " ('magnetoresistance', 10.685186796595348),\n",
       " ('automatic', 6.399784577733099),\n",
       " ('estimation', 5.827205801467775),\n",
       " ('dialogue', 7.4372592831517625),\n",
       " ('nn', 10.685186796595348),\n",
       " ('stformer:', 10.685186796595348),\n",
       " ('through', 6.9302992944318795),\n",
       " ('outcome', 10.100224295874192),\n",
       " ('hand', 9.363258701707986),\n",
       " ('enumeration', 10.685186796595348),\n",
       " ('dual-path', 8.877831874537744),\n",
       " ('aircraft', 10.100224295874192),\n",
       " ('sensor', 9.363258701707986),\n",
       " ('single-headed', 10.685186796595348),\n",
       " ('generalizing', 10.100224295874192),\n",
       " ('ultra-high', 10.685186796595348),\n",
       " ('pet', 10.685186796595348),\n",
       " ('computed', 10.100224295874192),\n",
       " ('cloth', 10.685186796595348),\n",
       " ('mt6:', 10.685186796595348),\n",
       " ('force', 10.100224295874192),\n",
       " ('emsvit:', 10.685186796595348),\n",
       " ('sdtp:', 10.685186796595348),\n",
       " ('grapheme-to-phoneme', 10.100224295874192),\n",
       " ('serial-parallel', 10.685186796595348),\n",
       " ('varying', 10.685186796595348),\n",
       " ('lexicon', 10.685186796595348),\n",
       " ('adverse', 10.100224295874192),\n",
       " ('vitae:', 10.685186796595348),\n",
       " ('dyngraphtrans:', 10.685186796595348),\n",
       " ('slu', 10.685186796595348),\n",
       " ('intel.', 10.685186796595348),\n",
       " ('cross-model', 10.685186796595348),\n",
       " ('attention/', 10.685186796595348),\n",
       " ('who', 10.685186796595348),\n",
       " ('contributions', 10.685186796595348),\n",
       " ('consistency', 9.685186796595348),\n",
       " ('high', 7.292869373816587),\n",
       " ('refined', 10.100224295874192),\n",
       " ('armour:', 10.685186796595348),\n",
       " ('fbg-pzt', 10.685186796595348),\n",
       " ('generative', 6.4372592831517625),\n",
       " ('gpu', 9.685186796595348),\n",
       " ('encoding-decoding', 10.685186796595348),\n",
       " ('implicitly', 10.685186796595348),\n",
       " ('severity', 10.100224295874192),\n",
       " ('interpretability', 9.100224295874192),\n",
       " ('survey', 8.363258701707986),\n",
       " ('sexist', 10.685186796595348),\n",
       " ('edge-augmented', 10.685186796595348),\n",
       " ('186.5dbc/hz', 10.685186796595348),\n",
       " ('vae', 9.685186796595348),\n",
       " ('reform', 10.685186796595348),\n",
       " ('vidtr:', 10.685186796595348),\n",
       " ('transcribing', 10.685186796595348),\n",
       " ('message-level', 10.685186796595348),\n",
       " ('metric', 10.100224295874192),\n",
       " ('fuseformer:', 10.685186796595348),\n",
       " ('stop-band', 10.685186796595348),\n",
       " ('long-text', 10.685186796595348),\n",
       " ('tale:', 10.685186796595348),\n",
       " ('vitt:', 10.685186796595348),\n",
       " ('win-win', 10.685186796595348),\n",
       " ('phase', 8.685186796595348),\n",
       " ('flow', 7.877831874537744),\n",
       " ('matter:', 10.685186796595348),\n",
       " ('essay', 10.100224295874192),\n",
       " ('south', 10.685186796595348),\n",
       " ('densenet', 10.685186796595348),\n",
       " ('navigate', 10.685186796595348),\n",
       " ('rl', 10.685186796595348),\n",
       " ('rotating', 10.100224295874192),\n",
       " ('need:', 9.363258701707986),\n",
       " ('balanced', 9.685186796595348),\n",
       " ('multidimensional', 10.100224295874192),\n",
       " ('miniature', 10.685186796595348),\n",
       " ('dlsa:', 10.685186796595348),\n",
       " ('abstractive', 8.877831874537744),\n",
       " ('zsi', 10.685186796595348),\n",
       " ('available', 10.685186796595348),\n",
       " ('concrete', 10.685186796595348),\n",
       " ('full-song', 10.100224295874192),\n",
       " ('wug', 10.685186796595348),\n",
       " ('axial', 9.363258701707986),\n",
       " ('patent', 10.100224295874192),\n",
       " ('neuromorphic', 10.685186796595348),\n",
       " ('tube-transformer', 10.685186796595348),\n",
       " ('thermal-fluid', 10.685186796595348),\n",
       " ('dot:', 10.685186796595348),\n",
       " ('full-tilt', 10.685186796595348),\n",
       " ('mt-transunet:', 10.685186796595348),\n",
       " ('occurrence', 10.685186796595348),\n",
       " ('multi-leg', 10.685186796595348),\n",
       " ('u-net', 7.984747078454255),\n",
       " ('field', 8.363258701707986),\n",
       " ('sampling', 8.685186796595348),\n",
       " ('melt', 10.685186796595348),\n",
       " ('cnns', 8.363258701707986),\n",
       " ('programmers', 10.100224295874192),\n",
       " ('shorts', 10.685186796595348),\n",
       " ('security', 10.100224295874192),\n",
       " ('polyu-cbs', 10.685186796595348),\n",
       " ('chords:', 10.685186796595348),\n",
       " ('preprocessing:', 10.685186796595348),\n",
       " ('focal', 10.100224295874192),\n",
       " ('differential-mode', 10.685186796595348),\n",
       " ('strategic', 10.685186796595348),\n",
       " ('smooth', 10.685186796595348),\n",
       " ('histology', 10.685186796595348),\n",
       " ('inflection', 10.685186796595348),\n",
       " ('clone', 10.685186796595348),\n",
       " ('patients', 10.100224295874192),\n",
       " ('throw', 10.685186796595348),\n",
       " ('grid-tied', 10.685186796595348),\n",
       " ('sinusoidal', 10.685186796595348),\n",
       " ('walkable', 10.685186796595348),\n",
       " ('algerian', 10.685186796595348),\n",
       " ('latr:', 10.685186796595348),\n",
       " ('cross-resolution', 10.685186796595348),\n",
       " ('primordial', 10.685186796595348),\n",
       " ('era', 10.100224295874192),\n",
       " ('array-based', 10.685186796595348),\n",
       " ('joint-flexible', 10.685186796595348),\n",
       " ('dct:', 10.685186796595348),\n",
       " ('checkthat!\\xa02021:', 9.100224295874192),\n",
       " ('exploration', 8.685186796595348),\n",
       " ('localizing', 10.100224295874192),\n",
       " ('cotr:', 9.685186796595348),\n",
       " ('classifier', 8.685186796595348),\n",
       " ('stvgbert:', 10.685186796595348),\n",
       " ('well-known', 10.685186796595348),\n",
       " ('(mmc)', 10.685186796595348),\n",
       " ('ecg', 8.877831874537744),\n",
       " ('learnable', 9.685186796595348),\n",
       " ('editable', 10.685186796595348),\n",
       " ('auto-encoderfor', 10.685186796595348),\n",
       " ('claw', 10.685186796595348),\n",
       " ('fpgas', 10.685186796595348),\n",
       " ('variations', 10.100224295874192),\n",
       " ('transcmd:', 10.685186796595348),\n",
       " ('category-level', 10.685186796595348),\n",
       " ('trend', 10.685186796595348),\n",
       " ('classifying', 9.363258701707986),\n",
       " ('anti-noise', 10.685186796595348),\n",
       " ('mlp-mixers', 10.685186796595348),\n",
       " ('low-voltage', 10.100224295874192),\n",
       " ('backdoor', 10.685186796595348),\n",
       " ('crowdsourced', 10.685186796595348),\n",
       " ('usefulness', 10.685186796595348),\n",
       " ('grained', 10.685186796595348),\n",
       " ('outside', 10.685186796595348),\n",
       " ('more', 8.22575517795805),\n",
       " ('path', 8.685186796595348),\n",
       " ('upconverter', 10.685186796595348),\n",
       " ('world', 10.100224295874192),\n",
       " ('dialog', 8.515261795153036),\n",
       " ('very', 9.685186796595348),\n",
       " ('fight', 10.100224295874192),\n",
       " ('topic', 9.100224295874192),\n",
       " ('capacitive', 9.685186796595348),\n",
       " ('remote', 7.100224295874192),\n",
       " ('perceptron', 10.685186796595348),\n",
       " ('instructions', 10.100224295874192),\n",
       " ('crossing', 10.100224295874192),\n",
       " ('text2gestures:', 10.100224295874192),\n",
       " ('query2label:', 10.685186796595348),\n",
       " ('out-of-distribution', 9.363258701707986),\n",
       " ('transformer-transducers', 10.685186796595348),\n",
       " ('skeletal', 10.100224295874192),\n",
       " ('preparation', 10.685186796595348),\n",
       " ('boogie', 10.685186796595348),\n",
       " ('layouts', 10.685186796595348),\n",
       " ('slice', 10.685186796595348),\n",
       " ('fighting', 10.685186796595348),\n",
       " ('pid', 10.685186796595348),\n",
       " ('role-guided', 10.685186796595348),\n",
       " ('abstracted', 10.685186796595348),\n",
       " ('nested-block', 10.685186796595348),\n",
       " ('overlapping', 10.685186796595348),\n",
       " ('phrasing', 10.685186796595348),\n",
       " ('snowflakenet:', 10.685186796595348),\n",
       " ('objectives', 10.685186796595348),\n",
       " ('all', 7.4372592831517625),\n",
       " ('shuffle', 9.363258701707986),\n",
       " ('guarantee', 10.685186796595348),\n",
       " ('answer', 9.363258701707986),\n",
       " ('application', 7.100224295874192),\n",
       " ('step-up', 8.877831874537744),\n",
       " ('gestures', 9.685186796595348),\n",
       " ('dpnet:', 10.685186796595348),\n",
       " ('outcomes', 10.100224295874192),\n",
       " ('see', 10.100224295874192),\n",
       " ('gigapixel', 10.685186796595348),\n",
       " ('socio-temporal', 10.685186796595348),\n",
       " ('asymmetric', 9.685186796595348),\n",
       " ('split', 10.100224295874192),\n",
       " ('conformal', 10.685186796595348),\n",
       " ('profiling', 10.100224295874192),\n",
       " ('decoders', 10.100224295874192),\n",
       " ('indigenous', 10.685186796595348),\n",
       " ('transfusion:', 10.685186796595348),\n",
       " ('sml:', 10.685186796595348),\n",
       " ('contactless', 10.685186796595348),\n",
       " ('extremely', 10.685186796595348),\n",
       " ('ammu', 10.685186796595348),\n",
       " ('skip-transformer', 10.685186796595348),\n",
       " ('mobile-friendly', 10.685186796595348),\n",
       " ('sectioned', 10.685186796595348),\n",
       " ('using', 3.197346762772296),\n",
       " ('awake', 10.685186796595348),\n",
       " ('vortx:', 10.685186796595348),\n",
       " ('self-similarity', 10.685186796595348),\n",
       " ('captioning', 6.984747078454255),\n",
       " ('combining', 7.685186796595348),\n",
       " ('au', 10.100224295874192),\n",
       " ('sit:', 10.685186796595348),\n",
       " ('simplified', 10.100224295874192),\n",
       " ('communities', 10.685186796595348),\n",
       " ('result', 10.685186796595348),\n",
       " ('teaching', 10.685186796595348),\n",
       " ('crossformer:', 10.685186796595348),\n",
       " ('hypernetworks', 10.685186796595348),\n",
       " ('octree', 10.685186796595348),\n",
       " ('meta-learning', 9.685186796595348),\n",
       " ('technical', 10.685186796595348),\n",
       " ('input-output', 10.685186796595348),\n",
       " ('cnns:', 10.100224295874192),\n",
       " ('posegate-former:', 10.685186796595348),\n",
       " ('bushing', 10.685186796595348),\n",
       " ('potentials', 10.685186796595348),\n",
       " ('titles', 10.685186796595348),\n",
       " ('fields:', 10.685186796595348),\n",
       " ('traveling', 10.685186796595348),\n",
       " ('edione@lt-edi-eacl2021:', 10.685186796595348),\n",
       " ('light-weight,', 10.685186796595348),\n",
       " ('multi-gpu', 10.685186796595348),\n",
       " ('reveal', 10.685186796595348),\n",
       " ('subformer:', 10.685186796595348),\n",
       " ('aggregating', 10.685186796595348),\n",
       " ('linearly', 10.685186796595348),\n",
       " ('records', 8.685186796595348),\n",
       " ('segmentation', 4.651763795057898),\n",
       " ('disease', 7.877831874537744),\n",
       " ('communication', 8.877831874537744),\n",
       " ('subtypes', 10.685186796595348),\n",
       " ('glaucoma', 10.685186796595348),\n",
       " ('life', 7.984747078454255),\n",
       " ('advance', 10.685186796595348),\n",
       " ('bi-lstm', 9.685186796595348),\n",
       " ('trained', 9.685186796595348),\n",
       " ('ut-atd:', 10.685186796595348),\n",
       " ('certified', 10.100224295874192),\n",
       " ('pluralistic', 10.685186796595348),\n",
       " ('transformation', 9.363258701707986),\n",
       " ('psg@hasoc-dravidian', 10.685186796595348),\n",
       " ('micrographs', 10.685186796595348),\n",
       " ('localisation', 10.685186796595348),\n",
       " ('textcnn', 10.685186796595348),\n",
       " ('prelayernorm', 10.685186796595348),\n",
       " ('tunneling', 10.685186796595348),\n",
       " ('hippocampal', 10.685186796595348),\n",
       " ('onset', 10.685186796595348),\n",
       " ('vsc', 10.685186796595348),\n",
       " ('bat:', 10.685186796595348),\n",
       " ('bilingual', 10.100224295874192),\n",
       " ('h10', 10.685186796595348),\n",
       " ('improvisation:', 10.685186796595348),\n",
       " ('supervising', 10.685186796595348),\n",
       " ('sotr:', 10.685186796595348),\n",
       " ('fits', 10.685186796595348),\n",
       " ('modules', 10.685186796595348),\n",
       " ('trans2seg:', 10.685186796595348),\n",
       " ('dual-mode', 9.685186796595348),\n",
       " ('sexism', 9.100224295874192),\n",
       " ('completion', 7.877831874537744),\n",
       " ('recognize', 10.685186796595348),\n",
       " ('permutation-invariant', 10.685186796595348),\n",
       " ('continuous-time', 10.100224295874192),\n",
       " ('embeddings', 7.515261795153036),\n",
       " ('identifiable', 10.685186796595348),\n",
       " ('alibaba', 10.685186796595348),\n",
       " ('lightgbm', 10.685186796595348),\n",
       " ('self-slimmed', 10.685186796595348),\n",
       " (\"achilles'\", 10.100224295874192),\n",
       " ('hitter:', 10.685186796595348),\n",
       " ('rate', 9.363258701707986),\n",
       " ('speech-to-text', 9.685186796595348),\n",
       " ('sat', 10.685186796595348),\n",
       " ('unbalance', 10.685186796595348),\n",
       " ('end', 8.685186796595348),\n",
       " ('multichannel', 10.685186796595348),\n",
       " ('free,', 10.685186796595348),\n",
       " ('capacitors', 10.685186796595348),\n",
       " ('dual-learning', 10.685186796595348),\n",
       " ('arrangement', 10.685186796595348),\n",
       " ('decoder-end', 10.685186796595348),\n",
       " ('dyadformer:', 10.685186796595348),\n",
       " ('achieving', 10.685186796595348),\n",
       " ('t2t', 10.685186796595348),\n",
       " ('interleaved', 9.363258701707986),\n",
       " ('discrete', 9.363258701707986),\n",
       " ('too', 10.685186796595348),\n",
       " ('guiding', 9.685186796595348),\n",
       " ('forward', 10.100224295874192),\n",
       " ('link', 9.685186796595348),\n",
       " ('pretraining', 7.877831874537744),\n",
       " ('operation', 8.685186796595348),\n",
       " ('tweets', 8.22575517795805),\n",
       " ('60ghz', 10.685186796595348),\n",
       " ('un', 10.100224295874192),\n",
       " ('moving', 10.100224295874192),\n",
       " ('mlp', 9.363258701707986),\n",
       " ('w911nf1910069', 10.685186796595348),\n",
       " ('multiplicative', 10.685186796595348),\n",
       " ('hsan:', 10.685186796595348),\n",
       " ('setting', 9.685186796595348),\n",
       " ('embracing', 10.685186796595348),\n",
       " ('sparsebert:', 10.685186796595348),\n",
       " ('burn-in', 10.685186796595348),\n",
       " ('de', 10.100224295874192),\n",
       " ('bft', 10.685186796595348),\n",
       " ('extraction:', 10.685186796595348),\n",
       " ('anti-spoofing', 10.685186796595348),\n",
       " ('stroke', 10.100224295874192),\n",
       " ('local-feature', 10.685186796595348),\n",
       " ('patch-level', 10.685186796595348),\n",
       " ('fmri', 10.685186796595348),\n",
       " ('gophormer:', 10.685186796595348),\n",
       " ('trial', 10.100224295874192),\n",
       " ('agreement', 9.685186796595348),\n",
       " ('high-impedance', 10.685186796595348),\n",
       " ('right', 10.100224295874192),\n",
       " ('git:', 10.685186796595348),\n",
       " ('spatial', 6.640792677236894),\n",
       " ('making', 10.100224295874192),\n",
       " ('modulation', 8.685186796595348),\n",
       " ('ingredients', 10.685186796595348),\n",
       " ('lenses', 10.685186796595348),\n",
       " ('theme', 10.685186796595348),\n",
       " ('paralinguistic', 10.685186796595348),\n",
       " ('poi', 10.100224295874192),\n",
       " ('shallow', 10.100224295874192),\n",
       " ('reporting', 10.685186796595348),\n",
       " ('therapy', 10.685186796595348),\n",
       " ('mind', 10.100224295874192),\n",
       " ('infer', 10.685186796595348),\n",
       " ('uzh', 10.685186796595348),\n",
       " ('bloomnet:', 10.685186796595348),\n",
       " ('stransgan:', 10.685186796595348),\n",
       " ('improvement', 10.100224295874192),\n",
       " ('traveling-waves-based', 10.685186796595348),\n",
       " ('layer-wise', 10.685186796595348),\n",
       " ('oadtr:', 10.685186796595348),\n",
       " ('sgtr:', 10.685186796595348),\n",
       " ('transzero++:', 10.685186796595348),\n",
       " ('input-aware', 10.685186796595348),\n",
       " ('pnp-detr:', 10.685186796595348),\n",
       " ('grid', 7.984747078454255),\n",
       " ('fine-grained', 6.827205801467775),\n",
       " ('cross-transformer', 10.685186796595348),\n",
       " ('anomaly', 7.2257551779580504),\n",
       " ('risc-vtf:', 10.685186796595348),\n",
       " ('simulation', 8.685186796595348),\n",
       " ('family:', 10.685186796595348),\n",
       " ('partitioning', 10.100224295874192),\n",
       " ('multilevel', 9.100224295874192),\n",
       " ('codes', 10.100224295874192),\n",
       " ('dielectric', 9.100224295874192),\n",
       " ('colonoscopy', 10.685186796595348),\n",
       " ('structure?', 10.685186796595348),\n",
       " ('(bert)-based', 10.685186796595348),\n",
       " ('transformer-free', 10.100224295874192),\n",
       " ('nasformer:', 10.685186796595348),\n",
       " ('albums', 10.685186796595348),\n",
       " ('cycle-consistent', 10.100224295874192),\n",
       " ('self-stabilizing', 10.685186796595348),\n",
       " ('enabling', 9.363258701707986),\n",
       " ('propagation-based', 10.685186796595348),\n",
       " ('soft:', 10.685186796595348),\n",
       " ('knowledge-aware', 10.685186796595348),\n",
       " ('boosted', 10.685186796595348),\n",
       " ('technological', 10.685186796595348),\n",
       " ('deephealth:', 10.685186796595348),\n",
       " ('performer', 10.685186796595348),\n",
       " ('multi-branch', 10.100224295874192),\n",
       " ('hitrans:', 10.685186796595348),\n",
       " ('fractional-n', 10.685186796595348),\n",
       " ('top-k', 10.685186796595348),\n",
       " ('certification', 10.685186796595348),\n",
       " ('story-based', 10.685186796595348),\n",
       " ('vaccine', 10.685186796595348),\n",
       " ('controllable', 8.685186796595348),\n",
       " ('new', 7.0413306068206225),\n",
       " ('convolution-augmented', 10.685186796595348),\n",
       " ('pitch', 10.685186796595348),\n",
       " ('simple', 7.363258701707985),\n",
       " ('composite', 9.685186796595348),\n",
       " ('pass', 10.100224295874192),\n",
       " ('spacer', 10.685186796595348),\n",
       " ('bossnas:', 10.685186796595348),\n",
       " ('patchout', 10.685186796595348),\n",
       " ('anonymity', 10.685186796595348),\n",
       " ('news:', 10.685186796595348),\n",
       " ('connections', 10.100224295874192),\n",
       " ('influence', 8.685186796595348),\n",
       " ('mltr:', 10.685186796595348),\n",
       " ('vtnet:', 10.685186796595348),\n",
       " ('high-voltage', 9.363258701707986),\n",
       " ('inverters', 10.100224295874192),\n",
       " ('intestine', 10.685186796595348),\n",
       " ('conv-attentional', 10.685186796595348),\n",
       " ('call', 10.685186796595348),\n",
       " ('way', 9.685186796595348),\n",
       " ('change', 9.685186796595348),\n",
       " ('spoken', 9.685186796595348),\n",
       " ('sctn:', 10.685186796595348),\n",
       " ('corticalflow:', 10.685186796595348),\n",
       " ('modetr:', 10.685186796595348),\n",
       " ('half-bridge', 10.685186796595348),\n",
       " ('polynomials', 10.685186796595348),\n",
       " ('array', 10.685186796595348),\n",
       " ('point-wise', 10.685186796595348),\n",
       " ('stst:', 10.685186796595348),\n",
       " ('diformer:', 10.685186796595348),\n",
       " ('ssast:', 10.685186796595348),\n",
       " ('nanocrystalline', 10.685186796595348),\n",
       " ('locformer:', 10.685186796595348),\n",
       " ('semeval-2021', 7.363258701707985),\n",
       " ('beyond:', 10.685186796595348),\n",
       " ('solvers', 10.685186796595348),\n",
       " ('quantization', 8.877831874537744),\n",
       " (\"what's\", 9.363258701707986),\n",
       " ('bias', 7.877831874537744),\n",
       " ('vulnerability', 9.685186796595348),\n",
       " ('particle', 9.100224295874192),\n",
       " ('maddpg', 10.685186796595348),\n",
       " ('interference', 9.685186796595348),\n",
       " ('finite', 9.685186796595348),\n",
       " ('ms-tct:', 10.685186796595348),\n",
       " ('omni-relational', 10.685186796595348),\n",
       " ('genome', 10.100224295874192),\n",
       " ('transgan:', 10.100224295874192),\n",
       " ('association', 9.685186796595348),\n",
       " ('aesthetic', 10.100224295874192),\n",
       " ('battery-grid', 10.685186796595348),\n",
       " ('dv/dt', 10.685186796595348),\n",
       " ('electra', 9.685186796595348),\n",
       " ('non-rigid', 10.685186796595348),\n",
       " ('continuity', 10.685186796595348),\n",
       " ('cluster', 10.685186796595348),\n",
       " ('roberta,', 10.685186796595348),\n",
       " ('power-transformer', 10.685186796595348),\n",
       " ('utnet:', 10.685186796595348),\n",
       " ('ava:', 10.685186796595348),\n",
       " ('are', 7.100224295874192),\n",
       " ('exploring', 6.877831874537744),\n",
       " ('understanding.', 10.685186796595348),\n",
       " ('question', 6.399784577733099),\n",
       " ('sequence:', 10.685186796595348),\n",
       " ('feacuteidir', 10.685186796595348),\n",
       " ('dehazing', 10.685186796595348),\n",
       " ('textcaps', 10.100224295874192),\n",
       " ('frame', 9.685186796595348),\n",
       " ('inheritance', 10.685186796595348),\n",
       " ('loftr:', 10.685186796595348),\n",
       " ('cross-scale', 10.685186796595348),\n",
       " ('anti-aliasing', 10.685186796595348),\n",
       " ('pu-transformer:', 10.685186796595348),\n",
       " ('sharing', 9.685186796595348),\n",
       " ('single-head?', 10.685186796595348),\n",
       " ('neurosymbolic', 10.685186796595348),\n",
       " ('redistribution', 10.685186796595348),\n",
       " ('time-reduction', 10.685186796595348),\n",
       " ('asset', 10.685186796595348),\n",
       " ('agent-aware', 10.685186796595348),\n",
       " ('native', 10.685186796595348),\n",
       " ('training:', 10.685186796595348),\n",
       " ('normalized', 10.685186796595348),\n",
       " ('tcl:', 10.685186796595348),\n",
       " ('dilated', 9.363258701707986),\n",
       " ('@finsim-2:', 10.685186796595348),\n",
       " ('location-guided', 10.685186796595348),\n",
       " ('id', 10.685186796595348),\n",
       " ('wavetransformer:', 10.685186796595348),\n",
       " ('pso', 10.685186796595348),\n",
       " ('capabilities', 10.100224295874192),\n",
       " ('makes', 9.685186796595348),\n",
       " ('early', 8.877831874537744),\n",
       " ('preservation', 10.685186796595348),\n",
       " ('segmentations', 10.685186796595348),\n",
       " ('gn-transformer:', 10.685186796595348),\n",
       " ('learn', 9.363258701707986),\n",
       " ('grid-connected', 8.685186796595348),\n",
       " ('creation', 10.685186796595348),\n",
       " ('key', 10.100224295874192),\n",
       " ('food', 10.685186796595348),\n",
       " ('concatenated', 10.100224295874192),\n",
       " ('prosodic', 10.685186796595348),\n",
       " ('saturation', 10.100224295874192),\n",
       " ('prose', 10.685186796595348),\n",
       " ('displacement', 10.100224295874192),\n",
       " ('ma-bert:', 10.685186796595348),\n",
       " ('astronomy', 10.685186796595348),\n",
       " ('linguistique', 10.685186796595348),\n",
       " ('nvit:', 10.685186796595348),\n",
       " ('transnet:', 10.685186796595348),\n",
       " ('autotrans:', 10.685186796595348),\n",
       " ('describing', 10.685186796595348),\n",
       " ('development', 9.363258701707986),\n",
       " ('quasi-steady-state', 10.685186796595348),\n",
       " ('semg', 10.685186796595348),\n",
       " ('decoder', 7.877831874537744),\n",
       " ('consumer', 9.100224295874192),\n",
       " ('oils', 10.685186796595348),\n",
       " ('asformer:', 10.685186796595348),\n",
       " ('stepping', 10.685186796595348),\n",
       " ('est', 10.685186796595348),\n",
       " ('variant', 10.100224295874192),\n",
       " ('units', 10.685186796595348),\n",
       " ('\"the', 10.100224295874192),\n",
       " ('soe-net:', 10.685186796595348),\n",
       " ('low-dimensional', 9.685186796595348),\n",
       " ('representation?', 10.100224295874192),\n",
       " ('orthogonality', 10.100224295874192),\n",
       " ('conventional', 10.100224295874192),\n",
       " ('opportunities', 10.685186796595348),\n",
       " ('equipped', 10.685186796595348),\n",
       " ('cuk', 10.685186796595348),\n",
       " ('musicoder:', 10.685186796595348),\n",
       " ('assembly', 10.685186796595348),\n",
       " ('mutation', 10.685186796595348),\n",
       " ('minimize', 10.685186796595348),\n",
       " ('legoformer:', 10.685186796595348),\n",
       " ('small-dim', 10.685186796595348),\n",
       " ('linearizer', 10.685186796595348),\n",
       " ('neuro-fuzzy', 10.685186796595348),\n",
       " ('vsec:', 10.685186796595348),\n",
       " ('house', 10.685186796595348),\n",
       " ('conceptual', 10.685186796595348),\n",
       " ('for', 1.0198508794101715),\n",
       " ('summarizers', 10.685186796595348),\n",
       " ('model-based', 10.100224295874192),\n",
       " ('inside', 10.100224295874192),\n",
       " ('multilayer', 10.100224295874192),\n",
       " ('driving', 8.363258701707986),\n",
       " ('switching', 9.363258701707986),\n",
       " ('approximation:', 10.685186796595348),\n",
       " ('fine-tuned', 9.685186796595348),\n",
       " ('non-repetitive', 10.685186796595348),\n",
       " ('joy', 10.685186796595348),\n",
       " ('transport', 10.685186796595348),\n",
       " ('crackformer:', 10.685186796595348),\n",
       " ('multi-scales', 10.685186796595348),\n",
       " ('risc-v', 10.685186796595348),\n",
       " ('in______', 10.685186796595348),\n",
       " ('chronic', 10.685186796595348),\n",
       " ('half', 10.685186796595348),\n",
       " ('been', 10.685186796595348),\n",
       " ('deepprog:', 10.685186796595348),\n",
       " ('times', 10.685186796595348),\n",
       " ('background/foreground', 10.685186796595348),\n",
       " ('dbia:', 10.685186796595348),\n",
       " ('multi-stacked', 10.685186796595348),\n",
       " ('packaging', 10.685186796595348),\n",
       " ('operating', 10.685186796595348),\n",
       " ('explanation', 10.685186796595348),\n",
       " ('vit-p:', 10.685186796595348),\n",
       " ('bi-order-transformer-crf', 10.685186796595348),\n",
       " ('amplifiers', 10.685186796595348),\n",
       " ('ventilation', 10.685186796595348),\n",
       " ('refraction', 10.685186796595348),\n",
       " ('vqgan', 10.685186796595348),\n",
       " ('medication-effect', 10.685186796595348),\n",
       " ('scene', 6.515261795153036),\n",
       " ('sentinel-2', 10.100224295874192),\n",
       " ('universal', 7.100224295874192),\n",
       " ('compensating', 9.685186796595348),\n",
       " ('tracing', 8.685186796595348),\n",
       " ('primates', 10.685186796595348),\n",
       " ('single-inductor', 10.685186796595348),\n",
       " ('persformer:', 10.685186796595348),\n",
       " ('unet-like', 10.685186796595348),\n",
       " ('ultra-compact', 10.685186796595348),\n",
       " ('gpt', 10.685186796595348),\n",
       " ('goal-oriented', 10.685186796595348),\n",
       " ('classification?', 10.685186796595348),\n",
       " ('hot', 10.100224295874192),\n",
       " ('software-equivalent', 10.685186796595348),\n",
       " ('cassava', 10.685186796595348),\n",
       " ('best', 10.685186796595348),\n",
       " ('business', 9.685186796595348),\n",
       " ('accommodating', 10.685186796595348),\n",
       " ('tp-ddi:', 10.685186796595348),\n",
       " ('10:', 10.685186796595348),\n",
       " ('specialized', 10.685186796595348),\n",
       " ('all-pass', 10.685186796595348),\n",
       " ('long-tail', 10.685186796595348),\n",
       " ('syntactic-guided', 10.685186796595348),\n",
       " ('reliability', 10.685186796595348),\n",
       " ('cervical', 10.685186796595348),\n",
       " ('convolution,', 10.685186796595348),\n",
       " ('oximetry', 10.685186796595348),\n",
       " ('nodules', 10.685186796595348),\n",
       " ('asrs', 10.685186796595348),\n",
       " ('wireless', 10.685186796595348),\n",
       " ('inter-resonance', 10.685186796595348),\n",
       " ('engines?', 10.685186796595348),\n",
       " ('trufm:', 10.685186796595348),\n",
       " ('shared', 8.515261795153036),\n",
       " ('evaluating', 8.515261795153036),\n",
       " ('translating', 9.685186796595348),\n",
       " ('attenuation', 10.685186796595348),\n",
       " ('shows', 10.685186796595348),\n",
       " ('hard', 10.100224295874192),\n",
       " ('constraining', 10.685186796595348),\n",
       " ('3d/4d', 10.685186796595348),\n",
       " ('text-transformers', 10.685186796595348),\n",
       " ('healthcare', 9.685186796595348),\n",
       " ('learning-to-rank', 10.685186796595348),\n",
       " ('multi-output', 10.100224295874192),\n",
       " ('humans', 10.685186796595348),\n",
       " ('crisis', 10.100224295874192),\n",
       " ('enables', 10.685186796595348),\n",
       " ('tri-coil', 10.685186796595348),\n",
       " ('meshed', 10.100224295874192),\n",
       " ('cs60075_team2', 10.685186796595348),\n",
       " ('evolution', 10.685186796595348),\n",
       " ('retinopathy-related', 10.685186796595348),\n",
       " ('tera:', 10.685186796595348),\n",
       " ('trseg:', 10.685186796595348),\n",
       " ('ladders', 10.685186796595348),\n",
       " ('updating', 10.685186796595348),\n",
       " ('dqn', 10.685186796595348),\n",
       " ('bootstrapping', 10.685186796595348),\n",
       " ('optimization', 7.597723955345009),\n",
       " ('feature', 6.475733430966398),\n",
       " ('gpt,', 10.685186796595348),\n",
       " ('tag', 10.685186796595348),\n",
       " ('constrained', 9.100224295874192),\n",
       " ('vit:', 10.100224295874192),\n",
       " ('test', 8.877831874537744),\n",
       " ('patnet', 10.685186796595348),\n",
       " ('high-gain', 10.685186796595348),\n",
       " ('query-based', 10.100224295874192),\n",
       " ('recom', 10.685186796595348),\n",
       " ('consistent', 10.100224295874192),\n",
       " ('combinative', 10.685186796595348),\n",
       " ('(okgm)', 10.685186796595348),\n",
       " ('trajectories', 10.685186796595348),\n",
       " ('pairs', 9.685186796595348),\n",
       " ('one-step', 10.685186796595348),\n",
       " ('recipes', 10.100224295874192),\n",
       " ('mixer', 10.100224295874192),\n",
       " ('near', 10.100224295874192),\n",
       " ('rubiks', 10.685186796595348),\n",
       " ('polyp-pvt:', 10.685186796595348),\n",
       " ('criteria', 10.685186796595348),\n",
       " ('resnets', 10.100224295874192),\n",
       " ('plan', 10.685186796595348),\n",
       " ('viewers', 10.685186796595348),\n",
       " ('mutual-relation', 10.685186796595348),\n",
       " ('two-stream', 9.685186796595348),\n",
       " ('repositioning', 10.685186796595348),\n",
       " ('voltage-regulation', 10.685186796595348),\n",
       " ('unknown:', 10.685186796595348),\n",
       " ('medium-', 10.685186796595348),\n",
       " ('pipelined', 10.685186796595348),\n",
       " ('rules', 10.685186796595348),\n",
       " ('analysis', 5.13059794491771),\n",
       " ('convolutions', 8.363258701707986),\n",
       " ('complex', 9.100224295874192),\n",
       " ('imaging', 8.877831874537744),\n",
       " ('generator', 10.685186796595348),\n",
       " ('tt2inet:', 10.685186796595348),\n",
       " ('cyber-physical', 10.100224295874192),\n",
       " ('autoencoders', 10.100224295874192),\n",
       " ('subjected', 10.685186796595348),\n",
       " ('detect', 8.877831874537744),\n",
       " ('sa-hardnest:', 10.685186796595348),\n",
       " ('dependency-scaled', 10.685186796595348),\n",
       " ('boundaries', 10.685186796595348),\n",
       " ('soit:', 10.685186796595348),\n",
       " ('bioasq9b', 10.685186796595348),\n",
       " ('frequency-domain', 10.100224295874192),\n",
       " ('sentences', 10.100224295874192),\n",
       " ('pi+passivity-based', 10.685186796595348),\n",
       " ('insertion-based', 10.685186796595348),\n",
       " ('transformesh:', 10.685186796595348),\n",
       " ('ordering', 10.685186796595348),\n",
       " ('construction', 10.100224295874192),\n",
       " ('side-scan', 10.685186796595348),\n",
       " ('novel', 6.555903779650381),\n",
       " ('mldt:', 10.685186796595348),\n",
       " ('opinion', 8.877831874537744),\n",
       " ('regularization', 10.100224295874192),\n",
       " ('teasel:', 10.685186796595348),\n",
       " ('parameter', 8.363258701707986),\n",
       " ('investigating', 9.363258701707986),\n",
       " ('date:', 10.100224295874192),\n",
       " ('learning-based', 10.100224295874192),\n",
       " ('three-dimensional', 10.685186796595348),\n",
       " ('dissolved', 10.100224295874192),\n",
       " ('cvt', 10.685186796595348),\n",
       " ('statistical', 9.100224295874192),\n",
       " ('try-on', 10.685186796595348),\n",
       " ('attend', 9.685186796595348),\n",
       " ('structext:', 10.685186796595348),\n",
       " ('65-nm', 9.685186796595348),\n",
       " ('out-domain', 10.685186796595348),\n",
       " ('theoretical', 10.685186796595348),\n",
       " ('attentionlite:', 10.685186796595348),\n",
       " ('produce', 10.685186796595348),\n",
       " ('rug:', 10.685186796595348),\n",
       " ('spoiler', 10.685186796595348),\n",
       " ('calligraphic', 10.685186796595348),\n",
       " ('far', 10.685186796595348),\n",
       " ('vertical', 10.685186796595348),\n",
       " ...]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "#(feature, idf)\n",
    "totalcount = dblp_tfidf7.collect()[0][0]\n",
    "idf=reduce2.map(lambda x: (x[0],math.log2((1+totalcount)/(1+x[1]))))\n",
    "idf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4774bf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10',\n",
       "  (('indt5: a text-to-text transformer for 10 indigenous languages', 1),\n",
       "   10.100224295874192)),\n",
       " ('10',\n",
       "  (('analysis of the influence of the breaking radiation magnetic field of a 10 kv intelligent circuit breaker on an electronic transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('couplet',\n",
       "  (('transcouplet: transformer based chinese couplet generation', 1),\n",
       "   10.685186796595348)),\n",
       " ('2d',\n",
       "  (('a transformer architecture based on bert and 2d convolutional neural network to identify dna enhancers from sequence information',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('2d',\n",
       "  (('boxer: box-attention for 2d and 3d transformers', 1), 8.685186796595348)),\n",
       " ('2d',\n",
       "  (('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('2d',\n",
       "  (('portfolio optimization with 2d relative-attentional gated transformer',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('2d',\n",
       "  (('combining a parallel 2d cnn with a self-attention dilated residual network for ctc-based discrete speech emotion recognition',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('2d',\n",
       "  (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('2d',\n",
       "  (('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('step',\n",
       "  (('cass-nat: ctc alignment-based single step non-autoregressive transformer for speech recognition',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('step',\n",
       "  (('an improved single step non-autoregressive transformer for automatic speech recognition',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('matters',\n",
       "  (('scaled relu matters for training vision transformers', 1),\n",
       "   10.685186796595348)),\n",
       " ('policy',\n",
       "  (('updet: universal multi-agent rl via policy decoupling with transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('policy',\n",
       "  (('updet: universal multi-agent reinforcement learning via policy decoupling with transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('carlo',\n",
       "  (('monte carlo denoising via auxiliary feature guided self-attention', 1),\n",
       "   10.685186796595348)),\n",
       " ('solve',\n",
       "  (('cubetr: learning to solve the rubiks cube using transformers', 1),\n",
       "   9.363258701707986)),\n",
       " ('solve',\n",
       "  (('learning to iteratively solve routing problems with dual-aspect collaborative transformer',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('solve',\n",
       "  (('making transformers solve compositional tasks', 1), 9.363258701707986)),\n",
       " ('solve',\n",
       "  (('transformers solve the limited receptive field for monocular depth prediction',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('temgnet:',\n",
       "  (('temgnet: deep transformer-based decoding of upperlimb semg for hand gestures recognition',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('standards',\n",
       "  (('instrument transformers for power quality measurements: a review of literature and standards',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('doubler',\n",
       "  (('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('asr,',\n",
       "  (('simultaneous speech-to-speech translation system with transformer-based incremental asr, mt, and tts',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('wide-range',\n",
       "  (('wide-range digital-analog mixed calibration technology of a dc instrument transformer test set',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('readonce',\n",
       "  (('readonce transformers: reusable representations of text for transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('leakage',\n",
       "  (('h9 and h10 transformer-less solar photovoltaic inverters for leakage current suppression and harmonic current reduction',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('the role of diodes in the leakage current suppression mechanism of decoupling transformerless pv inverter topologies',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('electric transformer oil leakage visual detection as service based on lstm and genetic algorithm',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('on-line method for high-sensitivity leakage current measurement of converter-connected transformers in microgrids',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('leakage current suppression of single-phase five-level inverter for transformerless photovoltaic system',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('breadth-first search leakage tolerant commutation method for matrix converters in three-phase solid state transformers',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('an accurate analytical method for leakage inductance calculation of shell-type transformers with rectangular windings',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('leakage',\n",
       "  (('an accurate method for leakage inductance calculation of shell-type multi core-segment transformers with circular windings',\n",
       "    1),\n",
       "   8.515261795153036)),\n",
       " ('lm',\n",
       "  (('history utterance embedding transformer lm for speech recognition', 1),\n",
       "   10.685186796595348)),\n",
       " ('representational',\n",
       "  (('shifted chunk transformer for spatio-temporal representational learning',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('representational',\n",
       "  (('all bark and no bite: rogue dimensions in transformer language models obscure representational quality',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('icd-10',\n",
       "  (('automatic assignment of icd-10 codes to diagnostic texts using transformers based techniques',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('icd-10',\n",
       "  (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('ufo-vit:',\n",
       "  (('ufo-vit: high performance linear vision transformer without softmax', 1),\n",
       "   10.685186796595348)),\n",
       " ('nearest',\n",
       "  (('learnable compression network with transformer for approximate nearest neighbor search',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('pilot:',\n",
       "  (('pilot: introducing transformers for probabilistic sound event localization',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('cosformer:',\n",
       "  (('cosformer: detecting co-salient object with transformers', 1),\n",
       "   10.685186796595348)),\n",
       " ('knn',\n",
       "  (('accuracy improvement of power transformer faults diagnostic using knn classifier with decision tree principle',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('generic',\n",
       "  (('generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('crops',\n",
       "  (('vision transformers for weeds and crops classification of high resolution uav images',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('communicative',\n",
       "  (('learning attributed graph representations with communicative message passing transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('communicative',\n",
       "  (('learning attributed graph representation with communicative message passing transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('entity-and-relation',\n",
       "  (('transrefer3d: entity-and-relation aware transformer for fine-grained 3d visual grounding',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('retraining',\n",
       "  (('fq-vit: fully quantized vision transformer without retraining', 1),\n",
       "   10.685186796595348)),\n",
       " ('japanese',\n",
       "  (('empirical analysis of training strategies of transformer-based japanese chit-chat systems',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('updet:',\n",
       "  (('updet: universal multi-agent reinforcement learning via policy decoupling with transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('updet:',\n",
       "  (('updet: universal multi-agent rl via policy decoupling with transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('ct-cad:',\n",
       "  (('ct-cad: context-aware transformers for end-to-end chest abnormality detection on x-rays',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('network-driven',\n",
       "  (('neuromorphic camera denoising using graph neural network-driven transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('re-interpreting',\n",
       "  (('convolutions and self-attention: re-interpreting relative positions in pre-trained language models',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('what,',\n",
       "  (('umuteam at haha 2021: linguistic features and transformers for analysing spanish humor. the what, the how, and to whom',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('distributional,',\n",
       "  (('polyu-cbs at the finsim-2 task: combining distributional, string-based and transformers-based features for hypernymy detection in the financial domain',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('cpus',\n",
       "  (('optimizing inference performance of transformers on cpus', 1),\n",
       "   10.685186796595348)),\n",
       " ('voltage',\n",
       "  (('backstepping controller design for the medium and low voltage stages of smart transformer',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "    2),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('calculation of error of multi-winding voltage transformer under arbitrary secondary load by determinant method',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('current and voltage model predictive control for a three-stage smart transformer',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('self-detecting the measurement error of electronic voltage transformer based on principal component analysis-wavelet packet decomposition',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('a transformer-less voltage equalizer for energy storage cells based on double-tiered multi-stacked converters',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('operator-adapted evolutionary large-scale multiobjective optimization for voltage transformer ratio error estimation',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('black-hole optimization applied to the parametric estimation in distribution transformers considering voltage and current measures',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('regenerative active electronic load with current, voltage and frequency control for power transformer testing',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('transformer secondary voltage based resonant frequency tracking for llc converter',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('an automatic data acquisition device for transformer oscillating switching impulse voltage tests',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('the development of precision 500/√3-kv two-stage voltage transformer with high-voltage excitation',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('breakdown voltage of transformer oil containing cellulose particle contamination with and without bridge formation under lightning impulse stress',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('measuring harmonics with inductive voltage transformers in presence of subharmonics',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('harmonic synchrophasors measurement algorithms with embedded compensation of voltage transformer frequency response',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('transformerless high step-up dc-dc converter with low voltage stress for fuel cells',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('a novel interleaved high step-up converter with built-in transformer voltage multiplier cell',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('multi-input multi-phase transformerless large voltage conversion ratio dc/dc converter',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('synchronization of low voltage grids fed by smart and conventional transformers',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('transformation of transient overvoltages by inductive voltage transformers',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('modeling capacitive low-power voltage transformer behavior over temperature and frequency',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('voltage dependence of the reference system in medium- and high-voltage current transformer calibrations',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('reduced dc voltage fed grid connected transformer-less shunt compensator with ac-side impedance-source configuration',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('optical voltage transformer based on fbg-pzt for power quality measurement',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('comparison of convexificated sqcqp and pso for the optimal transmission system operation based on incremental in-phase and quadrature voltage controlled transformers',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('the principle of intelligent switch composition and algorithm of the built-in electronic voltage transformer',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('voltage',\n",
       "  (('an average voltage approach to control energy storage device and tap changing transformers under high distributed generation',\n",
       "    1),\n",
       "   6.730990486208472)),\n",
       " ('cooperative',\n",
       "  (('sa-matd3: self-attention-based multi-agent continuous control method in cooperative environments',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('dc',\n",
       "  (('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('reduced dc voltage fed grid connected transformer-less shunt compensator with ac-side impedance-source configuration',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('calculation and analysis of dc magnetic bias current of urban main transformer under the action of stray current',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('tunneling magnetoresistance dc current transformer for ion beam diagnostics',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('component-level thermo-electromagnetic nonlinear transient finite element modeling of solid-state transformer for dc grid studies',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('multitime scale frequency regulation of a general resonant dc transformer in a hybrid ac/dc microgrid',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('temperature rise test and thermal-fluid coupling simulation of an oil-immersed autotransformer under dc bias',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('wide-range digital-analog mixed calibration technology of a dc instrument transformer test set',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('dc',\n",
       "  (('state identification of transformer under dc bias based on wavelet singular entropy',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('hybrid',\n",
       "  (('smart transformer-enabled meshed hybrid distribution grid', 1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('impact of optimal control of distributed generation converters in smart transformer based meshed hybrid distribution network',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a multi-input multi-output transformer-based hybrid neural network for multi-class privacy disclosure detection',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('comformer: code comment generation via transformer and fusion method-based hybrid code representation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid chinese grammar error checking model based on transformer', 1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('msht: multi-stage hybrid transformer for the rose image analysis of pancreatic cancer',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a multi-branch hybrid transformer network for corneal endothelial cell segmentation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('trans-svnet: accurate phase recognition from surgical videos via hybrid embedding aggregation transformer',\n",
       "    2),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid local-global transformer for image dehazing', 1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('an end-to-end speech accent recognition method based on hybrid ctc/attention transformer asr',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid vision transformer for domain adaptable person re-identification',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid cnn-gru framework with integrated pre-trained language transformer for sms phishing detection',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid model for network anomaly detection with gradient boosting decision trees and tabtransformer',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('high gain and low noise wideband folded-switching mixer employing transformer and complimentary cs/cg hybrid topology',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('multi-scale hybrid transformer networks: application to prostate disease classification',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('ddostc: a transformer-based network attack detection hybrid mechanism in sdn',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid encoder: towards efficient and precise native adsrecommendation via hybrid transformer encoding networks',\n",
       "    2),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('novel topology of modular-matrix-converter-based smart transformer for hybrid microgrid',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hcit: deepfake video detection using a hybrid model of cnn features and vision transformer',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('ressanet: a hybrid backbone of residual block and self-attention module for masked face recognition',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('bossnas: exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search',\n",
       "    2),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('discrete-state event-driven numerical prototyping of megawatt solid-state transformers and ac/dc hybrid microgrids',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hformer: hybrid cnn-transformer for fringe order prediction in phase unwrapping of fringe projection',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('utnet: a hybrid transformer architecture for medical image segmentation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('enhancing local dependencies for transformer-based text-to-speech via hybrid lightweight convolution',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid lstm self-attention mechanism model for forecasting the reform of scientific research in morocco',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('transformerless ups system based on the half-bridge hybrid switched-capacitor operating as ac-dc and dc-dc converter',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('hybrid self-attention neat: a novel evolutionary approach to improve the neat algorithm',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('extracting relational facts based on hybrid syntax-guided transformer and pointer network',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('da-detr: domain adaptive detection transformer by hybrid attention', 1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('leveraging text data using hybrid transformer-lstm based end-to-end asr in transfer learning',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a new method of hybrid time window embedding with transformer-based traffic data classification in iot-networked environment',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('efficient hybrid transformer: learning global-local context for urban sence segmentation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('research on hybrid feature selection method of power transformer based on fuzzy information entropy',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('reversible wideband hybrid model of two-winding transformer including the core nonlinearity and emtp implementation',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a transformer fault diagnosis method based on parameters optimization of hybrid kernel extreme learning machine',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('a transformerless dc-dc modular multilevel converter for hybrid interconnections in hvdc',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('hybrid',\n",
       "  (('multitime scale frequency regulation of a general resonant dc transformer in a hybrid ac/dc microgrid',\n",
       "    1),\n",
       "   6.193333700265673)),\n",
       " ('unwanted',\n",
       "  (('bert prescriptions to avoid unwanted headaches: a comparison of transformer architectures for adverse drug event detection',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('diabetic',\n",
       "  (('lesion-aware transformers for diabetic retinopathy grading', 1),\n",
       "   9.100224295874192)),\n",
       " ('diabetic',\n",
       "  (('convolutional nets versus vision transformers for diabetic foot ulcer classification',\n",
       "    2),\n",
       "   9.100224295874192)),\n",
       " ('diabetic',\n",
       "  (('a multi-scale self-attention network for diabetic retinopathy retrieval',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('diabetic',\n",
       "  (('identify diabetic retinopathy-related clinical concepts using transformer-based natural language processing methods',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('diabetic',\n",
       "  (('diabetic retinopathy detection using cnn, transformer and mlp based architectures',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('sports',\n",
       "  (('learning unbiased transformer for long-tail sports action classification',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('karl',\n",
       "  (('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('synthesizing',\n",
       "  (('synthesizing abstract transformers', 1), 9.685186796595348)),\n",
       " ('synthesizing',\n",
       "  (('synthesizing object state transformers for dynamic software updates', 1),\n",
       "   9.685186796595348)),\n",
       " ('synthesizing',\n",
       "  (('pasta: synthesizing object state transformers for dynamic software updates',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('math',\n",
       "  (('a transformer-based math language model for handwritten math expression recognition',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('math',\n",
       "  (('math word problem solver based on text-to-text transformer model', 1),\n",
       "   10.100224295874192)),\n",
       " ('versus',\n",
       "  (('convolutional nets versus vision transformers for diabetic foot ulcer classification',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('pushing',\n",
       "  (('pushing the limits of rule reasoning in transformers through natural language satisfiability',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('pushing',\n",
       "  (('pushing on text readability assessment: a transformer meets handcrafted linguistic features',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('formation',\n",
       "  (('breakdown voltage of transformer oil containing cellulose particle contamination with and without bridge formation under lightning impulse stress',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('formation',\n",
       "  (('relating transformers to models and neural representations of the hippocampal formation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('rediscover',\n",
       "  (('translation transformers rediscover inherent data domains', 1),\n",
       "   10.685186796595348)),\n",
       " ('perturbations',\n",
       "  (('inheritance attention matrix-based universal adversarial perturbations on vision transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('perturbations',\n",
       "  (('robustness of smart transformer based-on sliding mode controller under grid perturbations',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('long-read',\n",
       "  (('lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('diode',\n",
       "  (('luminance-degradation compensation based on multistream self-attention to address thin-film transistor-organic light emitting diode burn-in',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('cnn-self-attention',\n",
       "  (('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('speed,',\n",
       "  (('transportation monitoring of geo-location, speed, vibration, and shock acceleration for 110-kv vehicular mobile transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('poat-net:',\n",
       "  (('poat-net: parallel offset-attention assisted transformer for 3d object detection for autonomous driving',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('energy',\n",
       "  (('irene-viz: visualizing energy consumption of transformer models', 1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('impact of battery energy storage system fed super grid transformer on distance protection',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('irene: interpretable energy prediction for transformers', 1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('a modular multilevel converter (mmc) based solid-state transformer (sst) topology with simplified energy conversion process and magnetic integration',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('a transformer-less voltage equalizer for energy storage cells based on double-tiered multi-stacked converters',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('research on residual flux density measurement for single-phase transformer core based on energy changes',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('an average voltage approach to control energy storage device and tap changing transformers under high distributed generation',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('a pi+passivity-based control of a wind energy conversion system enabled with a solid-state transformer',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('control of soft switching solid state transformer based on lyapunov energy function for three-phase ac-ac power conversion',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('energy',\n",
       "  (('miniaturized magnetic energy harvester: lightweight and safe transformer design',\n",
       "    1),\n",
       "   7.984747078454255)),\n",
       " ('shifter',\n",
       "  (('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('shifter',\n",
       "  (('all-pass network and transformer based sige bicmos phase shifter for multi-band arrays',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('multi-instance',\n",
       "  (('end-to-end trainable multi-instance pose estimation with transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('multi-instance',\n",
       "  (('dt-mil: deformable transformer for multi-instance learning on histopathological image',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('arbitrary',\n",
       "  (('spine-transformers: vertebra detection and localization in arbitrary field-of-view spine ct with transformers',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('arbitrary',\n",
       "  (('streamult: streaming multimodal transformer for heterogeneous and arbitrary long sequential data',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('arbitrary',\n",
       "  (('calculation of error of multi-winding voltage transformer under arbitrary secondary load by determinant method',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('separable',\n",
       "  (('melody structure transfer network: generating music with separable self-attention',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('separable',\n",
       "  (('ssan: separable self-attention network for video representation learning',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('synchronous',\n",
       "  (('streaming transformer asr with blockwise synchronous beam search', 1),\n",
       "   9.685186796595348)),\n",
       " ('synchronous',\n",
       "  (('evaluation of static synchronous compensator and rail power conditioner in electrified railway systems using v/v and scott power transformers',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('synchronous',\n",
       "  (('synchronous syntactic attention for transformer neural machine translation',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('adjustable',\n",
       "  (('an ultrawide output range ${llc}$ resonant converter based on adjustable turns ratio transformer and reconfigurable bridge',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('semask:',\n",
       "  (('semask: semantically masked transformers for semantic segmentation', 1),\n",
       "   10.685186796595348)),\n",
       " ('visualizing',\n",
       "  (('irene-viz: visualizing energy consumption of transformer models', 1),\n",
       "   10.100224295874192)),\n",
       " ('visualizing',\n",
       "  ((\"show me what you're looking for visualizing abstracted transformer attention for enhancing their local interpretability on time series data\",\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('context-dependent',\n",
       "  (('mutformer: a context-dependent transformer-based model to predict pathogenic missense mutations',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('clothing',\n",
       "  ((\"levit: a vision transformer in convnet's clothing for faster inference\",\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('clothing',\n",
       "  (('research on clothing patterns generation based on multi-scales self-attention improved generative adversarial network',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('surprise',\n",
       "  (('emotion transformer fusion: complementary representation properties of eeg and eye movements on recognizing anger and surprise',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('protagonist-aware',\n",
       "  (('zero-shot video emotion recognition via multimodal protagonist-aware transformer network',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('numerical',\n",
       "  (('numerical and experimental evaluation and heat transfer characteristics of a soft magnetic transformer built from laminated steel plates',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('numerical',\n",
       "  (('discrete-state event-driven numerical prototyping of megawatt solid-state transformers and ac/dc hybrid microgrids',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('$\\\\mathcal{laja}{-}$',\n",
       "  (('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('hat-net:',\n",
       "  (('hat-net: a hierarchical transformer graph neural network for grading of colorectal cancer histology images',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('loss',\n",
       "  (('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('transformer-ic: the solution to information loss', 1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('regression loss in transformer-based supervised neural machine translation',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('transient finite element method for computing and analyzing the effect of harmonics on hysteresis and eddy current loss of distribution transformer',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('a transformer district line loss anomaly discrimination model incorporating cross-attention and deep learning algorithm',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('tvqvc: transformer based vector quantized variational autoencoder with ctc loss for voice conversion',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('assessing the impact of high penetration pv on the power transformer loss of life on a distribution system',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('auxiliary loss of transformer with residual connection for end-to-end speaker diarization',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('loss',\n",
       "  (('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "    1),\n",
       "   8.363258701707986)),\n",
       " ('measure',\n",
       "  (('can transformer models measure coherence in text? re-thinking the shuffle test',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('measure',\n",
       "  (('can transformer models measure coherence in text: re-thinking the shuffle test',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('measure',\n",
       "  (('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('marathi',\n",
       "  (('fine-tuning of pre-trained transformers for hate, offensive, and profane content detection in english and marathi',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('marathi',\n",
       "  (('transformer models for offensive language identification in marathi', 1),\n",
       "   9.685186796595348)),\n",
       " ('marathi',\n",
       "  (('fine-tuning of pre-trained transformers for hate offensive and profane content detection in english and marathi',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('losses',\n",
       "  (('decoupling the role of data, attention, and losses in multimodal transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('losses',\n",
       "  (('improving power losses and thermal management in switch mode power converters using multiple transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('retrosynthesis',\n",
       "  (('valid, plausible, and diverse retrosynthesis using tied two-way transformers with latent variables',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('retrosynthesis',\n",
       "  (('molecular graph enhanced transformer for retrosynthesis prediction', 1),\n",
       "   10.100224295874192)),\n",
       " ('iiitt@lt-edi-eacl2021-hope',\n",
       "  (('iiitt@lt-edi-eacl2021-hope speech detection: there is always hope in transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('imagery',\n",
       "  (('adt-det: adaptive dynamic refined single-stage transformer detector for arbitrary-oriented object detection in satellite optical imagery',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('imagery',\n",
       "  (('domain-adversarial training of self-attention-based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('imagery',\n",
       "  (('the channel-spatial attention-based vision transformer network for automated, accurate prediction of crop nitrogen status from uav imagery',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('imagery',\n",
       "  (('domain-adversarial training of self-attention based networks for land cover classification using multi-temporal sentinel-2 satellite imagery',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('size',\n",
       "  (('presize: predicting size in e-commerce using transformers', 1),\n",
       "   9.100224295874192)),\n",
       " ('size',\n",
       "  (('is image size important? a robustness comparison of deep learning methods for multi-scale cell image classification tasks: from convolutional neural networks to visual transformers',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('size',\n",
       "  (('on the effects of transformer size on in- and out-of-domain calibration',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('size',\n",
       "  (('empirical evaluation of pre-trained transformers for human-level nlp: the role of sample size and dimensionality',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('size',\n",
       "  (('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('retinopathy',\n",
       "  (('diabetic retinopathy detection using cnn, transformer and mlp based architectures',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('retinopathy',\n",
       "  (('lesion-aware transformers for diabetic retinopathy grading', 1),\n",
       "   9.685186796595348)),\n",
       " ('retinopathy',\n",
       "  (('a multi-scale self-attention network for diabetic retinopathy retrieval',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('...',\n",
       "  (('large scale audio understanding without transformers/ convolutions/ berts/ mixers/ attention/ rnns or ...',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('vqa',\n",
       "  (('latr: layout-aware transformer for scene-text vqa', 1),\n",
       "   10.100224295874192)),\n",
       " ('vqa',\n",
       "  (('a transformer-based cross-modal fusion model with adversarial training for vqa challenge 2021',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('enlivening',\n",
       "  (('enlivening redundant heads in multi-head self-attention for machine translation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('paragraph-level',\n",
       "  (('paragraph-level commonsense transformers with recurrent memory', 1),\n",
       "   10.100224295874192)),\n",
       " ('paragraph-level',\n",
       "  (('simplifying paragraph-level question generation via transformer language models',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('nystroumlmformer:',\n",
       "  (('nystroumlmformer: a nystroumlm-based algorithm for approximating self-attention',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('java',\n",
       "  (('javabert: training a transformer-based model for the java programming language',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('humourous',\n",
       "  (('iiith at semeval-2021 task 7: leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('transformer-xl',\n",
       "  (('transformer-xl with graph neural network for source code summarization',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('transformer-xl',\n",
       "  (('retrieval-augmented transformer-xl for close-domain dialog generation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('chip',\n",
       "  (('fully integrated transformer less floating gate driver for 3d power supply on chip',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('chip',\n",
       "  (('uhf rfid chip impedance and sensitivity measurement using a transmission line transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('character-level',\n",
       "  (('applying the transformer to character-level transduction', 1),\n",
       "   10.100224295874192)),\n",
       " ('character-level',\n",
       "  (('quasi character-level transformers to improve neural machine translation on small datasets',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('semi-structured',\n",
       "  (('nxmtransformer: semi-structured sparsification for natural language understanding via admm',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('25.4%',\n",
       "  (('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('ouvert',\n",
       "  ((\"interaction retardeacutee dans l'encodeur du transformer pour reacutepondre efficacement aux questions dans un domaine ouvert\",\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('structures:',\n",
       "  (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('sparsely',\n",
       "  (('taming sparsely activated transformer with stochastic experts', 1),\n",
       "   10.685186796595348)),\n",
       " ('competing',\n",
       "  (('stochastic transformer networks with linear competing units: application to end-to-end sl translation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('competing',\n",
       "  (('survtrace: transformers for survival analysis with competing events', 1),\n",
       "   10.100224295874192)),\n",
       " ('cooking',\n",
       "  (('recipebowl: a cooking recommender for ingredients and recipes using set transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('ofhands',\n",
       "  (('handsformer: keypoint transformer for monocular 3d pose estimation ofhands and object in interaction',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('graph-augmented',\n",
       "  (('element graph-augmented abstractive summarization for legal public opinion news with graph transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('hcit:',\n",
       "  (('hcit: deepfake video detection using a hybrid model of cnn features and vision transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('k-nn',\n",
       "  (('kvt: k-nn attention for boosting vision transformers', 1),\n",
       "   10.685186796595348)),\n",
       " ('interpret:',\n",
       "  (('interpret: an interactive visualization tool for interpreting transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('ucatr:',\n",
       "  (('ucatr: based on cnn and transformer encoding and cross-attention decoding for lesion segmentation of acute ischemic stroke in non-contrast computed tomography images',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('question-aware',\n",
       "  (('question-aware transformer models for consumer health question summarization',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('panoptic',\n",
       "  (('an end-to-end trainable video panoptic segmentation method usingtransformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('panoptic',\n",
       "  (('max-deeplab: end-to-end panoptic segmentation with mask transformers', 1),\n",
       "   10.100224295874192)),\n",
       " ('eliza?',\n",
       "  (('are transformers a modern version of eliza? observations on french object verb agreement',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('foundation',\n",
       "  (('towards a unified foundation model: jointly pre-training transformers on unpaired images and text',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('codemixfire2021:',\n",
       "  (('psg@hasoc-dravidian codemixfire2021: pretrained transformers for offensive language identification in tanglish',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('xlnet',\n",
       "  (('exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('xlnet',\n",
       "  (('exploring transformers in natural language generation: gpt, bert, and xlnet',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('attngan',\n",
       "  (('transformer models for enhancing attngan based text to image generation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('android',\n",
       "  (('heterogeneous temporal graph transformer: an intelligent system for evolving android malware detection',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('monocular',\n",
       "  (('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('monocular',\n",
       "  (('transformers solve the limited receptive field for monocular depth prediction',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('monocular',\n",
       "  (('transformerfusion: monocular rgb scene reconstruction using transformers',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('monocular',\n",
       "  (('handsformer: keypoint transformer for monocular 3d pose estimation ofhands and object in interaction',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('monocular',\n",
       "  (('transformer-based monocular depth estimation with attention supervision',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('equal',\n",
       "  (('research on 110kv oil impregnated paper capac-itance graded transformer bushings based on the design principle of equal capacitance and steps',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('questions',\n",
       "  (('bilingual self-attention network: generating headlines for online linguistic questions',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  (('answering fill-in-the-blank questions in portuguese with transformer language models',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  (('wbi at mediqa 2021: summarizing consumer health questions with generative transformers',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  (('on the application of transformers for estimating the difficulty of multiple-choice questions from text',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  (('incorporating domain knowledge into language transformers for multi-label classification of chinese medical questions',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  ((\"interaction retardeacutee dans l'encodeur du transformer pour reacutepondre efficacement aux questions dans un domaine ouvert\",\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('questions',\n",
       "  (('using transformers to improve answer retrieval for legal questions', 1),\n",
       "   8.685186796595348)),\n",
       " ('speech-to-animation',\n",
       "  (('transformer-s2a: robust and efficient speech-to-animation', 1),\n",
       "   10.685186796595348)),\n",
       " ('intrusion',\n",
       "  (('an efficient intrusion detection model based on convolutional neural network and transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('fed',\n",
       "  (('synchronization of low voltage grids fed by smart and conventional transformers',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('fed',\n",
       "  (('impact of battery energy storage system fed super grid transformer on distance protection',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('fed',\n",
       "  (('reduced dc voltage fed grid connected transformer-less shunt compensator with ac-side impedance-source configuration',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('receptor',\n",
       "  (('trp-bert: discrimination of transient receptor potential (trp) channels using contextual representations from deep bidirectional transformer based on bert',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('notch',\n",
       "  (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('esters',\n",
       "  (('effect of iron/titania-based nanomaterials on the dielectric properties of mineral oil, natural and synthetic esters as transformers insulating fluid',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('salience',\n",
       "  (('enjoy the salience: towards better transformer-based faithful explanations with word salience',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('system',\n",
       "  (('a pi+passivity-based control of a wind energy conversion system enabled with a solid-state transformer',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('impact of battery energy storage system fed super grid transformer on distance protection',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('dissolved gas analysis for transformer fault based on learning spiking neural p system with belief adaboost',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('an improved speech recognition system based on transformer language model',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('design of online monitoring system for distribution transformer based on cloud side end collaboration of internet of things',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('att-net: enhanced emotion recognition system using lightweight self-attention module',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('a new harmonic mitigation system with double balanced impedance filtering power transformer for multistage distribution network',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('leakage current suppression of single-phase five-level inverter for transformerless photovoltaic system',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('sbilsan: stacked bidirectional self-attention lstm network for anomaly detection and diagnosis from system logs',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('cltr: an end-to-end, transformer-based system for cell-level table retrieval and table question answering',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('optimized active power management in solar pv-fed transformerless grid-connected system for rural electrified microgrid',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('a novel rule-based evolving fuzzy system applied to the thermal modeling of power transformers',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('design and optimization of 3-kw inductive power transfer charging system with compact asymmetric loosely coupled transformer for special applications',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('multi-aspect controlled response generation in a multimodal dialogue system using hierarchical transformer network',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('design of insulation tape tension control system of transformer winding machine based on fuzzy pid',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('system description for exist shared task at iberlef 2021: automatic misogyny identification using pretrained transformers',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('image transformer for explainable autonomous driving system', 1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('turbotransformers: an efficient gpu serving system for transformer models',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('assessing the impact of high penetration pv on the power transformer loss of life on a distribution system',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('cltr: an end-to-end, transformer-based system for cell level table retrieval and table question answering',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('dielectric response of the oil-paper insulation system in nanofluid-based transformers',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('voltage dependence of the reference system in medium- and high-voltage current transformer calibrations',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('finetuning transformer models to build asag system', 1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformerless ups system based on the half-bridge hybrid switched-capacitor operating as ac-dc and dc-dc converter',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('self-attentive ensemble transformer: representing ensemble interactions in neural networks for earth system models',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('optimal sizing of energy storage system to reduce impacts of transportation electrification on power distribution transformers integrated with photovoltaic',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformer and node-compressed dnn based dual-path system for manipulated face detection',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformer ensemble system for detection of offensive content in dravidian languages',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformer based automatic covid-19 fake news detection system', 1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformer oil-paper insulation aging evaluation system based on different aging characteristics',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('power transformer fault diagnosis system based on internet of things', 1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('a novel leakage-current-based online insulation monitoring strategy for converter transformers using common-mode and differential-mode harmonics in vsc system',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('comparison of convexificated sqcqp and pso for the optimal transmission system operation based on incremental in-phase and quadrature voltage controlled transformers',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('effectiveness of decoder transformer network in breaking low-resource real-time text captcha system',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('incorporating distinct translation system outputs into statistical and transformer model',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('knowledge enhanced transformers system for claim stance classification',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('transformer-based banking products recommender system', 1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('wide voltage-regulation range tap-changing transformer model for power system studies',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('intelligent detection system of transformer winding temperature based on distributed optical fiber',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('discrimination of internal faults and other transients in an interconnected system with power transformers and phase angle regulators',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('dealing with data uncertainty for transformer insulation system health index',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('study of unbalance reduction in 25kv ac traction system by different transformer configurations',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('heterogeneous temporal graph transformer: an intelligent system for evolving android malware detection',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('system',\n",
       "  (('simultaneous speech-to-speech translation system with transformer-based incremental asr, mt, and tts',\n",
       "    1),\n",
       "   6.13059794491771)),\n",
       " ('tables',\n",
       "  (('dot: an efficient double transformer for nlp tasks with tables', 2),\n",
       "   10.100224295874192)),\n",
       " ('tables',\n",
       "  (('capturing row and column semantics in transformer based question answering over tables',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('electronic',\n",
       "  (('transformer-based multi-target regression on electronic health records for primordial prevention of cardiovascular disease',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('bidirectional representation learning from transformers using multimodal electronic health record data to predict depression',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('self-detecting the measurement error of electronic voltage transformer based on principal component analysis-wavelet packet decomposition',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('design and implementation of novel power electronic transformer for smart grid',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('the principle of intelligent switch composition and algorithm of the built-in electronic voltage transformer',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('analysis of the influence of the breaking radiation magnetic field of a 10 kv intelligent circuit breaker on an electronic transformer',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('identification of dietary supplement use from electronic health records using transformer-based language models',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('a mmc-based multiport power electronic transformer with shared medium-frequency transformer',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('apehr: automated prognosis in electronic health records using multi-head self-attention',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('hi-behrt: hierarchical transformer-based model for accurate prediction of clinical events using multimodal longitudinal electronic health records',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('power electronic transformer design with dual-pwm based on matlab/simulink',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('regenerative active electronic load with current, voltage and frequency control for power transformer testing',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('electronic',\n",
       "  (('medical sansformers: training self-supervised transformers without attention for electronic medical records',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('models:',\n",
       "  (('accounting for agreement phenomena in sentence comprehension with transformer language models: effects of similarity-based interference on surprisal and attention',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('models:',\n",
       "  (('reasoning with transformer-based models: deep learning, but shallow reasoning',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('models:',\n",
       "  (('compressing large-scale transformer-based models: a case study on bert',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('models:',\n",
       "  (('transformer-based korean pretrained language models: a survey on three years of progress',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('models:',\n",
       "  (('detecting gender bias in transformer-based models: a case study on bert',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('platforms',\n",
       "  (('latte: lstm self-attention based anomaly detection in embedded automotive platforms',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('platforms',\n",
       "  (('latte: lstm self-attention based anomaly detection in e mbedded automotive platforms',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('element',\n",
       "  (('component-level thermo-electromagnetic nonlinear transient finite element modeling of solid-state transformer for dc grid studies',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('element',\n",
       "  (('transient finite element method for computing and analyzing the effect of harmonics on hysteresis and eddy current loss of distribution transformer',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('element',\n",
       "  (('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('element',\n",
       "  (('element graph-augmented abstractive summarization for legal public opinion news with graph transformer',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('in-phase',\n",
       "  (('comparison of convexificated sqcqp and pso for the optimal transmission system operation based on incremental in-phase and quadrature voltage controlled transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('informer,',\n",
       "  (('informer, an information organization transformer architecture', 1),\n",
       "   10.685186796595348)),\n",
       " ('punctuation,',\n",
       "  (('what helps transformers recognize conversational structure? importance of context, punctuation, and labels in dialog act recognition',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('asag',\n",
       "  (('finetuning transformer models to build asag system', 1),\n",
       "   10.685186796595348)),\n",
       " ('shatter:',\n",
       "  (('shatter: an efficient transformer encoder with single-headed self-attention and relative sequence partitioning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('slot-filling',\n",
       "  (('a transformer based multi-task model for domain classification, intent detection and slot-filling',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('foveated',\n",
       "  (('foveater: foveated transformer for image classification', 1),\n",
       "   10.685186796595348)),\n",
       " ('transmot:',\n",
       "  (('transmot: spatial-temporal graph transformer for multiple object tracking',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('phraseformer:',\n",
       "  (('phraseformer: multimodal key-phrase extraction using transformer and graph embedding',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('surveillance',\n",
       "  (('unsupervised person re-identification with transformer-based network for intelligent surveillance systems',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('double-split',\n",
       "  (('the dual-mode combined control strategy for centralized photovoltaic grid-connected inverters based on double-split transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('signals,',\n",
       "  (('short-circuited turn fault diagnosis in transformers by using vibration signals, statistical time features, and support vector machines on fpga',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('signals,',\n",
       "  (('mcl@iitk at semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation using augmented data, signals, and transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('matching',\n",
       "  (('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('cotr: correspondence transformer for matching across images', 1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('visualsparta: sparse transformer fragment-level matching for large-scale text-to-image search',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('match-ignition: plugging pagerank into transformer for long-form text matching',\n",
       "    2),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('generalized decision transformer for offline hindsight information matching',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('transformer-based map matching model with limited ground-truth data using transfer-learning approach',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('self-attention based text matching model with generative pre-training',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('crossmodal matching transformer based x-ray and ct image registration for tevar',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('transmatcher: deep image matching through transformers for generalizable person re-identification',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('self-attention guided representation learning for image-text matching',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('transformer-based deep image matching for generalizable person re-identification',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('a mm-wave gm-assisted transformer-based matching network 2x2 phased-array receiver for 5g communication and radar systems',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('self-supervised learning for semantic sentence matching with dense transformer inference network',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('key point matching with transformers', 1), 7.161624840538335)),\n",
       " ('matching',\n",
       "  (('metric learning based vision transformer for product matching', 1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('the animation transformer: visual correspondence via segment matching',\n",
       "    2),\n",
       "   7.161624840538335)),\n",
       " ('matching', (('matching with transformers in melt', 1), 7.161624840538335)),\n",
       " ('matching',\n",
       "  (('let: linguistic knowledge enhanced graph transformer for chinese short text matching',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('sparta: efficient open-domain question answering via sparse transformer matching retrieval',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('loftr: detector-free local feature matching with transformers', 1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "    1),\n",
       "   7.161624840538335)),\n",
       " ('matching',\n",
       "  (('sentence matching with deep self-attention and co-attention features', 1),\n",
       "   7.161624840538335)),\n",
       " ('text-to-speech',\n",
       "  (('enhancing local dependencies for transformer-based text-to-speech via hybrid lightweight convolution',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('text-to-speech',\n",
       "  (('fine-grained style control in transformer-based text-to-speech synthesis',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('them',\n",
       "  (('motion planning transformers: one model to plan them all', 1),\n",
       "   10.685186796595348)),\n",
       " ('1:',\n",
       "  (('cs-um6p at semeval-2021 task 1: a deep learning model-based pre-trained transformer encoder for lexical complexity',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('1:',\n",
       "  (('iapucp at semeval-2021 task 1: stacking fine-tuned transformers is almost all you need for lexical complexity prediction',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('1:',\n",
       "  (('systems at sdu-2021 task 1: transformers for sentence level sequence label',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('1:',\n",
       "  (('csecu-dsg at semeval-2021 task 1: fusion of transformer models for lexical complexity prediction',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('patch-based',\n",
       "  (('dpt: deformable patch-based transformer for visual recognition', 1),\n",
       "   10.100224295874192)),\n",
       " ('patch-based',\n",
       "  (('understanding and improving robustness of vision transformers through patch-based negative augmentation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('tension',\n",
       "  (('design of insulation tape tension control system of transformer winding machine based on fuzzy pid',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('receptive',\n",
       "  (('paying attention to varying receptive fields: object detection with atrous filters and vision transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('receptive',\n",
       "  (('transformers solve the limited receptive field for monocular depth prediction',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('nast:',\n",
       "  (('nast: non-autoregressive spatial-temporal transformer for time series forecasting',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('quantized',\n",
       "  (('tvqvc: transformer based vector quantized variational autoencoder with ctc loss for voice conversion',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('quantized',\n",
       "  (('extractive opinion summarization in quantized transformer spaces', 1),\n",
       "   9.685186796595348)),\n",
       " ('quantized',\n",
       "  (('fq-vit: fully quantized vision transformer without retraining', 1),\n",
       "   9.685186796595348)),\n",
       " ('foil',\n",
       "  (('research on copper foil winding of transformer surface defect detection based on machine vision',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('obfuscated',\n",
       "  (('detection and identification of obfuscated obscene language with character level transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('offset-attention',\n",
       "  (('poat-net: parallel offset-attention assisted transformer for 3d object detection for autonomous driving',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('blockwise',\n",
       "  (('streaming transformer asr with blockwise synchronous beam search', 1),\n",
       "   10.685186796595348)),\n",
       " ('estimation',\n",
       "  (('test-time personalization with a transformer for human pose estimation',\n",
       "    2),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('nlpandir@uned at checkthat!\\xa02021: check-worthiness estimation and fake news detection using transformer models',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('dprost: 6-dof object pose estimation using space carving and dynamic projective spatial transformer',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('fds measurement-based moisture estimation model for transformer oil-paper insulation including the aging effect',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('an estimation method for real-time thermal capacity of traction transformers under unbalanced loads',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('black-hole optimization applied to the parametric estimation in distribution transformers considering voltage and current measures',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('residual life estimation of power transformer based on karl fischer and adaptive neuro-fuzzy interference system',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('tfpose: direct human pose estimation with transformers', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('cetransformer: casual effect estimation via transformer based representation learning',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('transcamp: graph transformer for 6-dof camera pose estimation', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('illuminant estimation error detection for outdoor scenes using transformers',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('global-local transformer for brain age estimation', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('transfusion: cross-view fusion with transformer for 3d human pose estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('handsformer: keypoint transformer for monocular 3d pose estimation ofhands and object in interaction',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('a new head pose estimation method using vision transformer model', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('end-to-end trainable multi-instance pose estimation with transformers',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('3d human pose estimation with spatial and temporal transformers', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('a deep attention transformer network for pain estimation with facial expression video',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('depth estimation using sparse depth and transformer', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('estimation of life cycle of distribution transformer in context to furan content formation, pollution index, and dielectric strength',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('graformer: graph convolution transformer for 3d pose estimation', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('improving 360 monocular depth estimation via non-local dense prediction transformer and joint supervised and self-supervised learning',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('pe-former: pose estimation transformer', 1), 5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('headposr: end-to-end trainable head pose estimation using transformer encoders',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('posegate-former: transformer encoder with trainable gate for 3d human pose estimation using weakly supervised learning',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('revisiting stereo depth estimation from a sequence-to-sequence perspective with transformers',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('incorporating transformer and lstm to kalman filter with em algorithm for state estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('transformer uncertainty estimation with hierarchical stochastic attention',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('3d human texture estimation from a single image with transformers', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('adaptively multi-view and temporal fusing transformer for 3d human pose estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('lifting transformer for 3d human pose estimation in video', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('ultrasound video transformers for cardiac ejection fraction estimation',\n",
       "    2),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('towards the application of calibrated transformers to the unsupervised estimation of question difficulty from text',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('erratum: rodrigo-mor et al. principles of charge estimation methods using high-frequency current transformer sensors in partial discharge measurements. sensors 2020, 20, 2520',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('gaze estimation via self-attention augmented convolutions', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('reverse graph self-attention for target-directed atomic importance estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('nlytics at checkthat!\\xa02021: check-worthiness estimation as a regression problem on transformers',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('operator-adapted evolutionary large-scale multiobjective optimization for voltage transformer ratio error estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('remaining useful life estimation for turbofan engine with transformer-based deep architecture',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('improving accuracy of respiratory rate estimation by restoring high resolution features with transformers and recursive convolutional models',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('transformer-based monocular depth estimation with attention supervision',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('localtrans: a multiscale local transformer network for cross-resolution homography estimation',\n",
       "    2),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('sctn: sparse convolution-transformer network for scene flow estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('multi-scale spatial-temporal transformer for 3d human pose estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('mhformer: multi-hypothesis transformer for 3d human pose estimation', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('multi-modal adaptive fusion transformer network for the estimation of depression level',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('remaining useful life estimation of aircraft engines using a joint deep learning model based on tcnn and transformer',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('two-hand pose estimation from the non-cropped rgb image with self-attention based network',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation', (('gaze estimation using transformer', 1), 5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('an exploratory analysis of multilingual word-level quality estimation with cross-lingual transformers',\n",
       "    2),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('skeletor: skeletal transformers for robust body-pose estimation', 2),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('posegtac: graph transformer encoder-decoder with atrous convolution for 3d human pose estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('spatial-temporal-spectral transformer for 3d human pose estimation', 1),\n",
       "   5.827205801467775)),\n",
       " ('estimation',\n",
       "  (('scat: stride consistency with auto-regressive regressor and transformer for hand pose estimation',\n",
       "    1),\n",
       "   5.827205801467775)),\n",
       " ('stformer:',\n",
       "  (('stformer: a noise-aware efficient spatio-temporal transformer architecture for traffic forecasting',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('outcome',\n",
       "  ((\"bloomnet: a robust transformer based model for bloom's learning outcome classification\",\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('outcome',\n",
       "  (('decoder transformer for temporally-embedded health outcome predictions',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('hand',\n",
       "  (('scat: stride consistency with auto-regressive regressor and transformer for hand pose estimation',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('hand',\n",
       "  (('waveglove: transformer-based hand gesture recognition using multiple inertial sensors',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('hand',\n",
       "  (('dynamic hand gesture recognition in in-vehicle environment based on fmcw radar and transformer',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('hand',\n",
       "  (('temgnet: deep transformer-based decoding of upperlimb semg for hand gestures recognition',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('enumeration',\n",
       "  (('towards vulnerability types classification using pure self-attention: a common weakness enumeration based approach',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('dual-path',\n",
       "  (('dpt-fsnet: dual-path transformer based full-band and sub-band fusion network for speech enhancement',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('dual-path',\n",
       "  (('transformer and node-compressed dnn based dual-path system for manipulated face detection',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('dual-path',\n",
       "  (('dual-path transformer for machine condition monitoring', 1),\n",
       "   8.877831874537744)),\n",
       " ('dual-path',\n",
       "  (('dual-path deep supervision network with self-attention for visible-infrared person re-identification',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('dual-path',\n",
       "  (('dpnet: dual-path network for efficient object detectioj with lightweight self-attention',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('dual-path',\n",
       "  (('transct: dual-path transformer for low dose computed tomography', 1),\n",
       "   8.877831874537744)),\n",
       " ('aircraft',\n",
       "  (('remaining useful life estimation of aircraft engines using a joint deep learning model based on tcnn and transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('aircraft',\n",
       "  (('on the analysis and design of high-frequency transformers for dual and triple active bridge converters in more electric aircraft',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('single-headed',\n",
       "  (('shatter: an efficient transformer encoder with single-headed self-attention and relative sequence partitioning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('generalizing',\n",
       "  (('generalizing rnn-transducer to out-domain audio via sparse self-attention layers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('generalizing',\n",
       "  (('latent space transformers for generalizing deep networks', 1),\n",
       "   10.100224295874192)),\n",
       " ('pet',\n",
       "  (('3d transformer-gan for high-quality pet reconstruction', 1),\n",
       "   10.685186796595348)),\n",
       " ('sdtp:',\n",
       "  (('sdtp: semantic-aware decoupled transformer pyramid for dense image prediction',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('grapheme-to-phoneme',\n",
       "  (('t5g2p: using text-to-text transfer transformer for grapheme-to-phoneme conversion',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('grapheme-to-phoneme',\n",
       "  (('grapheme-to-phoneme transformer model for transfer learning dialects', 1),\n",
       "   10.100224295874192)),\n",
       " ('lexicon',\n",
       "  (('turkish text classification: from lexicon analysis to bidirectional transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('adverse',\n",
       "  (('transweather: transformer-based restoration of images degraded by adverse weather conditions',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('adverse',\n",
       "  (('bert prescriptions to avoid unwanted headaches: a comparison of transformer architectures for adverse drug event detection',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('vitae:',\n",
       "  (('vitae: vision transformer advanced by exploring intrinsic inductive bias',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('dyngraphtrans:',\n",
       "  (('dyngraphtrans: dynamic graph embedding via modified universal transformer networks for financial transaction data',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('slu',\n",
       "  (('n-best asr transformer: enhancing slu performance using multiple asr hypotheses',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('intel.',\n",
       "  (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents**this work has been supported in part by aro grants w911nf1910069 and w911nf1910315, and intel. code and additional materials available at: https: //gamma.umd.edu/t2g',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('attention/',\n",
       "  (('large scale audio understanding without transformers/ convolutions/ berts/ mixers/ attention/ rnns or ...',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('who',\n",
       "  (('attend to who you are: supervising self-attention for keypoint detection and instance-aware association',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('contributions',\n",
       "  (('contributions of transformer attention heads in multi- and cross-lingual tasks',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('high',\n",
       "  (('impact of geomagnetically induced currents on high voltage transformers in malaysian power network and its mitigation',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('a transformer with high coupling coefficient and small area based on tsv',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('effects of spike voltages coupling with high dv/dt square wave on dielectric loss and electric-thermal field of high-frequency transformer',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('lightseq: a high performance inference library for transformers', 1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('high generalization performance structured self-attention model for knapsack problem',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('best of both worlds: making high accuracy non-incremental transformer-based disfluency detection incremental',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('modelling of high frequency coreless planar transformer with twr hexagonal winding',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('analysis and design of an integrated magnetics planar transformer for high power density llc resonant converter',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('vision transformers for weeds and crops classification of high resolution uav images',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('assessing the impact of high penetration pv on the power transformer loss of life on a distribution system',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('transformerless high step-up dc-dc converter with low voltage stress for fuel cells',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('an average voltage approach to control energy storage device and tap changing transformers under high distributed generation',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('improving accuracy of respiratory rate estimation by restoring high resolution features with transformers and recursive convolutional models',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('a novel interleaved high step-up converter with built-in transformer voltage multiplier cell',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('grid partitioned attention: efficient transformerapproximation with inductive bias for high resolution detail generation',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('optimal dispatch with transformer dynamic thermal rating in adns incorporating high pv penetration',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('high gain and low noise wideband folded-switching mixer employing transformer and complimentary cs/cg hybrid topology',\n",
       "    1),\n",
       "   7.292869373816587)),\n",
       " ('high',\n",
       "  (('ufo-vit: high performance linear vision transformer without softmax', 1),\n",
       "   7.292869373816587)),\n",
       " ('fbg-pzt',\n",
       "  (('optical voltage transformer based on fbg-pzt for power quality measurement',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('gpu',\n",
       "  (('autogtco: graph and tensor co-optimize for image recognition with transformers on gpu',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('gpu',\n",
       "  (('hmc-tran: a tensor-core inspired hierarchical model compression for transformer-based dnns on gpu',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('gpu',\n",
       "  (('turbotransformers: an efficient gpu serving system for transformer models',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('encoding-decoding',\n",
       "  (('encoding-decoding network with pyramid self-attention module for retinal vessel segmentation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('severity',\n",
       "  (('vision transformer using low-level chest x-ray feature corpus for covid-19 diagnosis and severity quantification',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('severity',\n",
       "  (('severity quantification and lesion localization of covid-19 on cxr using vision transformer',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('sexist',\n",
       "  (('umuteam at exist 2021: sexist language identification based on linguistic features and transformers in spanish and english',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('reform',\n",
       "  (('hybrid lstm self-attention mechanism model for forecasting the reform of scientific research in morocco',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('vidtr:',\n",
       "  (('vidtr: video transformer without convolutions', 2), 10.685186796595348)),\n",
       " ('message-level',\n",
       "  (('melt: message-level transformer with masked document representations as pre-training for stance detection',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('long-text',\n",
       "  (('hetformer: heterogeneous transformer with sparse attention for long-text extractive summarization',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('matter:',\n",
       "  (('all tokens matter: token labeling for training better vision transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('essay',\n",
       "  (('automated essay scoring using transformer models', 1),\n",
       "   10.100224295874192)),\n",
       " ('essay',\n",
       "  (('automated essay scoring using efficient transformer-based language models',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('south',\n",
       "  (('improving transformer model translation for low resource south african languages using bert',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('rl',\n",
       "  (('updet: universal multi-agent rl via policy decoupling with transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('need:',\n",
       "  (('cross-attention is all you need: adapting pretrained transformers for machine translation',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('need:',\n",
       "  (('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('need:',\n",
       "  (('transformer is all you need: multimodal multitask learning with a unified transformer',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('need:',\n",
       "  (('data movement is all you need: a case study on optimizing transformers',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('balanced',\n",
       "  (('a new harmonic mitigation system with double balanced impedance filtering power transformer for multistage distribution network',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('balanced',\n",
       "  (('accelerating transformer-based deep learning models on fpgas using column balanced block pruning',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('balanced',\n",
       "  (('accommodating transformer onto fpga: coupling the balanced model compression and fpga-implementation optimization',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('multidimensional',\n",
       "  (('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('multidimensional',\n",
       "  (('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('abstractive',\n",
       "  (('d-mmt: a concise decoder-only multi-modal transformer for abstractive summarization in videos',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('abstractive',\n",
       "  (('generating abstractive summaries of lithuanian news articles using a transformer model',\n",
       "    2),\n",
       "   8.877831874537744)),\n",
       " ('abstractive',\n",
       "  (('domain adaptation with pre-trained transformers for query focused abstractive text summarization',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('abstractive',\n",
       "  (('enriching transformers with structured tensor-product representations for abstractive summarization',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('abstractive',\n",
       "  (('highlight-transformer: leveraging key phrase aware attention to improve abstractive multi-document summarization',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('abstractive',\n",
       "  (('element graph-augmented abstractive summarization for legal public opinion news with graph transformer',\n",
       "    1),\n",
       "   8.877831874537744)),\n",
       " ('zsi', (('quasi-clamped zsi with two transformers', 1), 10.685186796595348)),\n",
       " ('available',\n",
       "  (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents**this work has been supported in part by aro grants w911nf1910069 and w911nf1910315, and intel. code and additional materials available at: https: //gamma.umd.edu/t2g',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('concrete',\n",
       "  (('identification of three-dimensional defect topology in concrete structures based on self-attention network using hammering response data',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('patent',\n",
       "  (('a multi-task approach to neural multi-label hierarchical patent classification using transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('patent',\n",
       "  (('improving patent mining and relevance classification using transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('thermal-fluid',\n",
       "  (('temperature rise test and thermal-fluid coupling simulation of an oil-immersed autotransformer under dc bias',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('mt-transunet:',\n",
       "  (('mt-transunet: mediating multi-task tokens in transformers for skin lesion segmentation and classification',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('occurrence',\n",
       "  (('prevent the occurrence of false signals in the power transformer internal protection in substation to improve reliability with differential operational amplifier safety',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('multi-leg',\n",
       "  (('combining rnn with transformer for modeling multi-leg trips', 1),\n",
       "   10.685186796595348)),\n",
       " ('melt', (('matching with transformers in melt', 1), 10.685186796595348)),\n",
       " ('programmers',\n",
       "  (('going beyond linear transformers with recurrent fast weight programmers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('programmers',\n",
       "  (('linear transformers are secretly fast weight programmers', 1),\n",
       "   10.100224295874192)),\n",
       " ('shorts',\n",
       "  (('diagnosis of inter-turn shorts of loaded transformer under various load currents and power factors; impulse voltage-based frequency response approach',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('security',\n",
       "  (('security threat modeling for power transformers in cyber-physical environments',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('security',\n",
       "  (('security requirements classification into groups using nlp transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('polyu-cbs',\n",
       "  (('polyu-cbs at the finsim-2 task: combining distributional, string-based and transformers-based features for hypernymy detection in the financial domain',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('differential-mode',\n",
       "  (('a novel leakage-current-based online insulation monitoring strategy for converter transformers using common-mode and differential-mode harmonics in vsc system',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('sinusoidal',\n",
       "  (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('algerian',\n",
       "  (('power transformer faults diagnosis using undestructive methods (roger and iec) and artificial neural network for dissolved gas analysis applied on the functional transformer in the algerian north-eastern: a comparative study',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('latr:',\n",
       "  (('latr: layout-aware transformer for scene-text vqa', 1),\n",
       "   10.685186796595348)),\n",
       " ('cross-resolution',\n",
       "  (('localtrans: a multiscale local transformer network for cross-resolution homography estimation',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('primordial',\n",
       "  (('transformer-based multi-target regression on electronic health records for primordial prevention of cardiovascular disease',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('array-based',\n",
       "  (('beamtransformer: microphone array-based overlapping speech detection', 1),\n",
       "   10.685186796595348)),\n",
       " ('dct:',\n",
       "  (('dct: dynamic compressive transformer for modeling unbounded sequence', 1),\n",
       "   10.685186796595348)),\n",
       " ('exploration',\n",
       "  (('exploration of effective attention strategies for neural automatic post-editing with transformer',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('self-attention-based temporary curiosity in reinforcement learning exploration',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('tx$^2$: transformer explainability and exploration', 1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('chasing sparsity in vision transformers: an end-to-end exploration', 1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('exploration of a novel hts thin-film device combined with roles of transformer and overcurrent limiter',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('generative pre-trained transformer for design concept generation: an exploration',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('exploration',\n",
       "  (('glimpse-attend-and-explore: self-attention for active visual exploration',\n",
       "    2),\n",
       "   8.685186796595348)),\n",
       " ('cotr:',\n",
       "  (('cotr: convolution in transformer network for end to end polyp detection',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('cotr:',\n",
       "  (('cotr: efficiently bridging cnn and transformer for 3d medical image segmentation',\n",
       "    2),\n",
       "   9.685186796595348)),\n",
       " ('cotr:',\n",
       "  (('cotr: correspondence transformer for matching across images', 1),\n",
       "   9.685186796595348)),\n",
       " ('well-known',\n",
       "  (('un modegravele transformer geacuteneacuteratif preacute-entraineacute pour le______ franccedilais (generative pre-trained transformer in______ (french) we introduce a french adaptation from the well-known gpt model)',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('learnable',\n",
       "  (('learnable compression network with transformer for approximate nearest neighbor search',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('learnable',\n",
       "  (('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('learnable',\n",
       "  (('smart bird: learnable sparse attention for efficient and effective transformer',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('editable',\n",
       "  (('controllable and editable neural story plot generation via control-and-edit transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('variations',\n",
       "  (('ensemble of one model: creating model variations for transformer with layer permutation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('variations',\n",
       "  (('faketransformer: exposing face forgery from spatial-temporal representation modeled by facial pixel variations',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('transcmd:',\n",
       "  (('transcmd: cross-modal decoder equipped with transformer for rgb-d salient object detection',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('category-level',\n",
       "  (('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('trend',\n",
       "  (('incorporating sentimental trend into gated mechanism based transformer network for story ending generation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('classifying',\n",
       "  (('temporal convolutional networks and transformers for classifying the sleep stage in awake or asleep using pulse oximetry signals',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('classifying',\n",
       "  (('classifying long clinical documents with pre-trained transformers', 1),\n",
       "   9.363258701707986)),\n",
       " ('classifying',\n",
       "  (('classifying scientific publications with bert - is self-attention a feature selection method?',\n",
       "    2),\n",
       "   9.363258701707986)),\n",
       " ('classifying',\n",
       "  (('a transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain mri images',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('anti-noise',\n",
       "  (('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('mlp-mixers',\n",
       "  (('exploring corruption robustness: inductive biases in vision transformers and mlp-mixers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('low-voltage',\n",
       "  (('study on operation parameter characteristics of induction filter distribution transformer in low-voltage distribution network',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('low-voltage',\n",
       "  (('low-voltage ride through strategy for mmc with y₀/y₀ arrangement transformer under single-line-to-ground fault',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('backdoor',\n",
       "  (('dbia: data-free backdoor injection attack against transformer networks',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('crowdsourced',\n",
       "  (('nisqa: a deep cnn-self-attention model for multidimensional speech quality prediction with crowdsourced datasets',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('grained',\n",
       "  (('dynamic grained encoder for vision transformers', 1),\n",
       "   10.685186796595348)),\n",
       " ('outside',\n",
       "  (('looking outside the window: wider-context transformer for the semantic segmentation of high-resolution remote sensing images',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('more', (('are transformers more robust than cnns?', 1), 8.22575517795805)),\n",
       " ('more',\n",
       "  (('single-layer vision transformers for more accurate early exits with less overhead',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('more than encoder: introducing transformer decoder to upsample', 1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('towards more efficient insertion transformer with fractional positional encoding',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('more identifiable yet equally performant transformers for text classification',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('are convolutional neural networks or transformers more like human vision?',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('convnets vs. transformers: whose visual representations are more transferable?',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('hierarchical transformers are more efficient language models', 1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('on the analysis and design of high-frequency transformers for dual and triple active bridge converters in more electric aircraft',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('more',\n",
       "  (('dudotrans: dual-domain transformer provides more attention for sinogram restoration in sparse-view ct reconstruction',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('world',\n",
       "  (('trans4trans: efficient transformer for transparent object segmentation to help visually impaired people navigate in the real world',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('world',\n",
       "  (('ar-t: temporal relation embedded transformer for the real world activity recognition',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('very',\n",
       "  (('measurement of very fast transient overvoltages in current transformers at open air hv substations',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('very',\n",
       "  (('transformer meets convolution: a bilateral awareness net-work for semantic segmentation of very fine resolution ur-ban scene images',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('very',\n",
       "  (('transformer meets convolution: a bilateral awareness network for semantic segmentation of very fine resolution urban scene images',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('fight',\n",
       "  (('can multilingual transformers fight the covid-19 infodemic?', 1),\n",
       "   10.100224295874192)),\n",
       " ('fight',\n",
       "  (('transformers to fight the covid-19 infodemic', 1), 10.100224295874192)),\n",
       " ('topic',\n",
       "  (('transformer over pre-trained transformer for neural text segmentation with enhanced topic coherence',\n",
       "    2),\n",
       "   9.100224295874192)),\n",
       " ('topic',\n",
       "  (('empirical study of tweets topic classification using transformer-based language models',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('topic',\n",
       "  (('improving keyword-based topic classification in cancer patient forums with multilingual transformers',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('topic',\n",
       "  (('topic classification of electric vehicle consumer experiences with transformer-based deep learning',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('topic',\n",
       "  (('civic-upm at checkthat!\\xa02021: integration of transformers in misinformation detection and topic classification',\n",
       "    1),\n",
       "   9.100224295874192)),\n",
       " ('instructions',\n",
       "  (('case relation transformer: a crossmodal language generation model for fetching instructions',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('instructions',\n",
       "  (('hierarchical task learning from language instructions with unified transformers and self-monitoring',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('text2gestures:',\n",
       "  (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents**this work has been supported in part by aro grants w911nf1910069 and w911nf1910315, and intel. code and additional materials available at: https: //gamma.umd.edu/t2g',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('text2gestures:',\n",
       "  (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('out-of-distribution',\n",
       "  (('oodformer: out-of-distribution detection transformer', 1),\n",
       "   9.363258701707986)),\n",
       " ('out-of-distribution',\n",
       "  (('self-supervised medical out-of-distribution using u-net vision transformers',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('out-of-distribution',\n",
       "  (('learning numerosity representations with transformers: number generation tasks and out-of-distribution generalization',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('out-of-distribution',\n",
       "  (('contrastive out-of-distribution detection for pretrained transformers',\n",
       "    2),\n",
       "   9.363258701707986)),\n",
       " ('transformer-transducers',\n",
       "  (('transformer-transducers for code-switched speech recognition', 1),\n",
       "   10.685186796595348)),\n",
       " ('skeletal',\n",
       "  (('skeletal graph self-attention: embedding a skeleton inductive bias into sign language production',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('skeletal',\n",
       "  (('skeletor: skeletal transformers for robust body-pose estimation', 2),\n",
       "   10.100224295874192)),\n",
       " ('boogie',\n",
       "  (('going full-tilt boogie on document understanding with text-image-layout transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('layouts',\n",
       "  (('pq-transformer: jointly parsing 3d objects and layouts from point clouds',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('fighting',\n",
       "  (('a transformer based approach for fighting covid-19 fake news', 1),\n",
       "   10.685186796595348)),\n",
       " ('pid',\n",
       "  (('design of insulation tape tension control system of transformer winding machine based on fuzzy pid',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('role-guided',\n",
       "  (('multi-head self-attention with role-guided masks', 1),\n",
       "   10.685186796595348)),\n",
       " ('nested-block',\n",
       "  (('nested-block self-attention for robust radiotherapy planning segmentation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('phrasing',\n",
       "  (('human and transformer-based prosodic phrasing in two speech genres', 1),\n",
       "   10.685186796595348)),\n",
       " ('snowflakenet:',\n",
       "  (('snowflakenet: point cloud completion by snowflake point deconvolution with skip-transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('answer',\n",
       "  (('recursive tree-structured self-attention for answer sentence selection',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('answer',\n",
       "  (('answer sentence selection using local and global context in transformer models',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('answer',\n",
       "  (('towards improving open student answer assessment using pretrained transformers',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('answer',\n",
       "  (('using transformers to improve answer retrieval for legal questions', 1),\n",
       "   9.363258701707986)),\n",
       " ('application',\n",
       "  (('design and adaptive control of matrix transformer based indirect converter for large-capacity circuit breaker testing application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('how does a pre-trained transformer integrate contextual keywords? application to humanitarian computing',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('application of deep self-attention in knowledge tracing', 1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('application of particle swarm optimization for optimal setting of phase shifting transformers to minimize unscheduled active power flows',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('msa-regularized protein sequence transformer toward predicting genome-wide chemical-protein interactions: application to gpcrome deorphanization',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('stochastic transformer networks with linear competing units: application to end-to-end sl translation',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('comparison of different multi-winding transformer models in multi-port ac-coupled converter application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('a novel application of the cross-capacitive sensor in real-time condition monitoring of transformer oil',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('attention distillation for detection transformers: application to real-time video object detection in ultrasound',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('using transformers to provide teachers with personalized feedback on their classroom discourse: the talkmoves application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('an efficient approach with application of linear and nonlinear models for evaluation of power transformer health index',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('application of solely self-attention mechanism in csi-fingerprinting-based indoor localization',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('towards the application of calibrated transformers to the unsupervised estimation of question difficulty from text',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('gaussian kernelized self-attention for long sequence data and its application to ctc-based speech recognition',\n",
       "    2),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('self-attention convlstm and its application in rul prediction of rolling bearings',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('multi-scale hybrid transformer networks: application to prostate disease classification',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('lipschitz normalization for self-attention layers with application to graph neural networks',\n",
       "    2),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('nahuatl neural machine translation using attention based architectures: a comparative analysis for rnns and transformers as a mobile application service',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('a new transformerless ultra high gain dc-dc converter for dc microgrid application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('on the application of transformers for estimating the difficulty of multiple-choice questions from text',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('application',\n",
       "  (('a novel time-frequency transformer and its application in fault diagnosis of rolling bearings',\n",
       "    1),\n",
       "   7.100224295874192)),\n",
       " ('gigapixel',\n",
       "  (('multimodal co-attention transformer for survival prediction in gigapixel whole slide images',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('asymmetric',\n",
       "  (('boosting salient object detection with transformer-based asymmetric bilateral u-net',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('asymmetric',\n",
       "  (('design and optimization of 3-kw inductive power transfer charging system with compact asymmetric loosely coupled transformer for special applications',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('asymmetric',\n",
       "  (('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('split',\n",
       "  (('federated split vision transformer for covid-19 cxr diagnosis using task-agnostic training',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('split',\n",
       "  (('federated split task-agnostic vision transformer for covid-19 cxr diagnosis',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('transfusion:',\n",
       "  (('transfusion: cross-view fusion with transformer for 3d human pose estimation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('sml:',\n",
       "  (('sml: a new semantic embedding alignment transformer for efficient cross-lingual natural language inference',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('contactless',\n",
       "  (('how geometry affects sensitivity of a differential transformer for contactless characterization of liquids',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('ammu',\n",
       "  (('ammu - a survey of transformer-based biomedical pretrained language models',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('skip-transformer',\n",
       "  (('snowflakenet: point cloud completion by snowflake point deconvolution with skip-transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('sectioned',\n",
       "  (('method for internal fault testing of instrument transformers with sectioned active parts',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('self-similarity',\n",
       "  (('eegdnet: fusing non-local and local self-similarity for 1-d eeg signal denoising with 2-d transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('sit:',\n",
       "  (('sit: self-supervised vision transformer', 1), 10.685186796595348)),\n",
       " ('communities',\n",
       "  (('llod-driven bilingual word embeddings rivaling cross-lingual transformers in quality of life concept detection from french online health communities',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('result',\n",
       "  (('introduce the result into self-attention', 1), 10.685186796595348)),\n",
       " ('teaching',\n",
       "  (('semi-supervised medical image segmentation via cross teaching between cnn and transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('hypernetworks',\n",
       "  (('parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('octree',\n",
       "  (('octree transformer: autoregressive 3d shape generation on hierarchically structured sequences',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('input-output',\n",
       "  (('self-attention between datapoints: going beyond individual input-output pairs in deep learning',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('cnns:',\n",
       "  (('transformer-based cnns: mining temporal context information for multi-sound covid-19 diagnosis',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('cnns:',\n",
       "  (('transformed cnns: recasting pre-trained convolutional layers with self-attention',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('posegate-former:',\n",
       "  (('posegate-former: transformer encoder with trainable gate for 3d human pose estimation using weakly supervised learning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('fields:',\n",
       "  (('paying attention to varying receptive fields: object detection with atrous filters and vision transformers',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('multi-gpu',\n",
       "  (('performance profile of transformer fine-tuning in multi-gpu cloud environments',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('aggregating', (('aggregating nested transformers', 1), 10.685186796595348)),\n",
       " ('segmentation',\n",
       "  (('spectr: spectral transformer for hyperspectral pathology image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('pyramid medical transformer for medical image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('bitr-unet: a cnn-transformer combined network for mri brain tumor segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('spatial context-aware self-attention model for multi-organ segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('a multi-branch hybrid transformer networkfor corneal endothelial cell segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('cac-emvt: efficient coronary artery calcium segmentation with multi-scale vision transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('a simple single-scale vision transformer for object localization and instance segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('stable self-attention adversarial learning for semi-supervised semantic image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('offroadtranseg: semi-supervised segmentation using transformers on offroad environments',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('simpler is better: few-shot semantic segmentation with classifier weight transformer',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('hepatic vessel segmentation based on 3d swin-transformer with inductive biased multi-head self-attention',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('emsvit: efficient multi scale vision transformer for biomedical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('wildfire segmentation using deep vision transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transclaw u-net: claw u-net with transformers for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transvos: video object segmentation with transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('swin unetr: swin transformers for semantic segmentation of brain tumors in mri images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('associating objects with transformers for video object segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('tsnet: three-stream self-attention network for rgb-d indoor semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('canonical segmentation using affix characters as a unit on transformer for javanese language',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('mt-transunet: mediating multi-task tokens in transformers for skin lesion segmentation and classification',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('trans4trans: efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('medical transformer: gated axial-attention for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('vision-language transformer and query generation for referring segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('combining cnns with transformer for multimodal 3d mri brain tumor segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transbts: multimodal brain tumor segmentation using transformer', 2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('w-core transformer model for chinese word segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('isegformer: interactive image segmentation with transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('stransfuse: fusing swin transformer and convolutional neural network for remote sensing image semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('semi-supervised medical image segmentation via cross teaching between cnn and transformer',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('missformer: an effective medical image segmentation transformer', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('litetrans: reconstruct transformer with convolution for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('tfnet: transformer fusion network for ultrasound image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('polyp-pvt: polyp segmentation with pyramid vision transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer meets convolution: a bilateral awareness net-work for semantic segmentation of very fine resolution ur-ban scene images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('action segmentation on representations of skeleton sequences using transformer networks',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('automatic lung segmentation on chest x-rays using self-attention deep neural network',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('end-to-end video instance segmentation with transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('covariance self-attention dual path unet for rectal tumor segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('medical image segmentation using squeeze-and-expansion transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer meets convolution: a bilateral awareness network for semantic segmentation of very fine resolution urban scene images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('swin-unet: unet-like pure transformer for medical image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('real-time semantic segmentation with dual encoder and self-attention mechanism for autonomous driving',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('flying guide dog: walkable path discovery for the visually impaired utilizing drones and transformer-based semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('sa-hardnest: a self-attention network for polyp segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('t-automl: automated machine learning for lesion segmentation using transformers in 3d medical imaging',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('ucatr: based on cnn and transformer encoding and cross-attention decoding for lesion segmentation of acute ischemic stroke in non-contrast computed tomography images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('semantic segmentation on vspw dataset through aggregation of transformer models',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('a multi-branch hybrid transformer network for corneal endothelial cell segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('double-stream segmentation network with temporal self-attention for deepfake video detection',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('utnet: a hybrid transformer architecture for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('vitbis: vision transformer for biomedical image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('u-shaped network based on transformer for 3d point clouds semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('evaluating transformer based semantic segmentation networks for pathological image segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('nnformer: interleaved transformer for volumetric segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('combining cnns with transformer for multimodal 3d mri brain tumor segmentation with self-supervised pretraining',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('few-shot segmentation via cycle-consistent transformer', 2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('convolution-free medical image segmentation using transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('progressively normalized self-attention network for video polyp segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('unetr: transformers for 3d medical image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('video instance segmentation using inter-frame communication transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('instance sequence queries for video instance segmentation with transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('encoding-decoding network with pyramid self-attention module for retinal vessel segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('referring segmentation in images and videos with cross-modal self-attention network',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transunet: transformers make strong encoders for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('multiple self-attention network for intracranial vessel segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('trans4trans: efficient transformer for transparent object segmentation to help visually impaired people navigate in the real world',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('fully transformer networks for semantic image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('self-attention in reconstruction bias u-net for semantic segmentation of building rooftops in optical remote sensing images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer-based decoder designs for semantic segmentation on remotely sensed images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('automated kidney tumor segmentation with convolution and transformer network',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('ect-nas: searching efficient cnn-transformers architecture for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('multi-scale high-resolution vision transformer for semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('self-attention feature fusion network for semantic segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('tempera: spatial transformer feature pyramid network for cardiac mri segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('pyramid self-attention for semantic segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('masked-attention mask transformer for universal image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transattunet: multi-level attention-guided u-net with transformer for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('boosting few-shot semantic segmentation with transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transbridge: a lightweight transformer for left ventricle segmentation in echocardiography',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('efficient hybrid transformer: learning global-local context for urban sence segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('levit-unet: make faster encoders with transformer for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('istr: end-to-end instance segmentation with transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('boundary-aware transformers for skin lesion segmentation', 2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('after-unet: axial fusion transformer unet for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transfuse: fusing transformers and cnns for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('nested-block self-attention for robust radiotherapy planning segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('mssa-net: multi-scale self-attention network for breast ultrasound image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('getam: gradient-weighted element-wise transformer attention map for weakly-supervised semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('contour transformer network for one-shot segmentation of anatomical structures',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('cotr: efficiently bridging cnn and transformer for 3d medical image segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('gt u-net: a u-net like group transformer network for tooth root segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('a volumetric transformer for accurate 3d tumor segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('ds-transunet: dual swin transformer u-net for medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('multi-scale hierarchical transformer structure for 3d medical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('weakly supervised action segmentation with effective use of attention and self-attention',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('segmenter: transformer for semantic segmentation', 2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('an end-to-end trainable video panoptic segmentation method usingtransformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('end-to-end referring video object segmentation with multimodal transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('mixed transformer u-net for medical image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer over pre-trained transformer for neural text segmentation with enhanced topic coherence',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('an improved swin transformer-based model for remote sensing object detection and instance segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('semask: semantically masked transformers for semantic segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('siamese network with interactive transformer for video object segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('hierarchical self-attention embedded neural network with dense connection for remote-sensing image semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('spatio-temporal multi-task learning transformer for joint moving object detection and segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer meets dcfam: a novel semantic segmentation scheme for fine-resolution remote sensing images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('trseg: transformer for semantic segmentation', 1), 4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('efficient transformer for remote sensing image segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('video semantic segmentation via sparse temporal transformer', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('lavt: language-aware vision transformer for referring image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('federated learning for brain tumor segmentation using mri and transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('u-net transformer: self and cross attention for medical image segmentation',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('memory-augmented transformer for remote sensing image semantic segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('sstvos: sparse spatiotemporal transformers for video object segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('segformer: simple and efficient design for semantic segmentation with transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('rethinking semantic segmentation from a sequence-to-sequence perspective with transformers',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('research on uyghur-chinese neural machine translation based on the transformer at multistrategy segmentation granularity',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('geo-spatial market segmentation and characterization exploiting user generated text through transformers and density-based clustering',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transformer assisted convolutional network for cell instance segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('asformer: transformer for action segmentation', 1), 4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('a unified efficient pyramid transformer for semantic segmentation', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('max-deeplab: end-to-end panoptic segmentation with mask transformers', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('looking outside the window: wider-context transformer for the semantic segmentation of high-resolution remote sensing images',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('trans2seg: transparent object segmentation with transformer', 1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('transgsnet: transformer-embedded ground segmentation of point cloud for rough roads',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('multi-compound transformer for accurate biomedical image segmentation',\n",
       "    1),\n",
       "   4.651763795057898)),\n",
       " ('segmentation',\n",
       "  (('unsupervised brain anomaly detection and segmentation with transformers',\n",
       "    2),\n",
       "   4.651763795057898)),\n",
       " ('subtypes',\n",
       "  (('gene transformer: transformers for the gene expression-based classification of cancer subtypes',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('trained',\n",
       "  (('handwritten mathematical expression recognition with bidirectionally trained transformer',\n",
       "    2),\n",
       "   9.685186796595348)),\n",
       " ('trained',\n",
       "  (('jointly trained transformers models for spoken language translation', 1),\n",
       "   9.685186796595348)),\n",
       " ('trained',\n",
       "  (('cross-domain generalization and knowledge transfer in transformers trained on legal data',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('pluralistic',\n",
       "  (('high-fidelity pluralistic image completion with transformers', 2),\n",
       "   10.685186796595348)),\n",
       " ('transformation',\n",
       "  (('transformation of transient overvoltages by inductive voltage transformers',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('transformation',\n",
       "  (('multi-scale gradients self-attention residual learning for face photo-sketch transformation',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('transformation',\n",
       "  (('ppdtsa: privacy-preserving deep transformation self-attention framework for object detection',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('transformation',\n",
       "  (('multi-head self-attention transformation networks for aspect-based sentiment analysis',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('psg@hasoc-dravidian',\n",
       "  (('psg@hasoc-dravidian codemixfire2021: pretrained transformers for offensive language identification in tanglish',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('micrographs',\n",
       "  (('transpicker: a transformer-based framework for particle picking in cryoem micrographs',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('localisation',\n",
       "  (('ndt-transformer: large-scale 3d point cloud localisation using the normal distribution transform representation',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('prelayernorm',\n",
       "  (('improved robustness of vision transformer via prelayernorm in patch embedding',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('tunneling',\n",
       "  (('tunneling magnetoresistance dc current transformer for ion beam diagnostics',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('bilingual',\n",
       "  (('llod-driven bilingual word embeddings rivaling cross-lingual transformers in quality of life concept detection from french online health communities',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('bilingual',\n",
       "  (('bilingual self-attention network: generating headlines for online linguistic questions',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('h10',\n",
       "  (('h9 and h10 transformer-less solar photovoltaic inverters for leakage current suppression and harmonic current reduction',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('supervising',\n",
       "  (('attend to who you are: supervising self-attention for keypoint detection and instance-aware association',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('fits',\n",
       "  (('which transformer architecture fits my data? a vocabulary bottleneck in self-attention',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('modules',\n",
       "  (('analysis and implementation of a single-stage transformer-less converter with high step-down voltage gain for voltage regulator modules',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('completion',\n",
       "  (('pctma-net: point cloud transformer with morphing atlas-based point generation network for dense point cloud completion',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('an empirical study on the usage of transformer models for code completion',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('tfill: image completion via a transformer-based architecture', 1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('layouttransformer: layout generation and completion with self-attention',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('single-shot motion completion with transformer', 1), 7.877831874537744)),\n",
       " ('completion',\n",
       "  (('ipe transformer for depth completion with input-aware positional embeddings',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('pointr: diverse point cloud completion with geometry-aware transformers',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('self-attention implicit function networks for 3d dental data completion',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('embodied bert: a transformer model for embodied, language-guided visual task completion',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('transsc: transformer-based shape completion for grasp evaluation', 1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('snowflakenet: point cloud completion by snowflake point deconvolution with skip-transformer',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('siamese pre-trained transformer encoder for knowledge base completion',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('completion',\n",
       "  (('high-fidelity pluralistic image completion with transformers', 2),\n",
       "   7.877831874537744)),\n",
       " ('permutation-invariant',\n",
       "  (('the sensory neuron as a transformer: permutation-invariant neural networks for reinforcement learning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('identifiable',\n",
       "  (('more identifiable yet equally performant transformers for text classification',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('alibaba',\n",
       "  (('from known to unknown: knowledge-guided transformer for time-series sales forecasting in alibaba',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('self-slimmed',\n",
       "  (('self-slimmed vision transformer', 1), 10.685186796595348)),\n",
       " ('unbalance',\n",
       "  (('study of unbalance reduction in 25kv ac traction system by different transformer configurations',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('multichannel',\n",
       "  (('self-attention channel combinator frontend for end-to-end multichannel far-field speech recognition',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('capacitors',\n",
       "  (('transformerless three-level flying-capacitor step-up pv micro-inverter without electrolytic capacitors',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('dual-learning',\n",
       "  (('dlsa: dual-learning based on self-attention for rating prediction', 1),\n",
       "   10.685186796595348)),\n",
       " ('decoder-end',\n",
       "  (('transformer-based online speech recognition with decoder-end adaptive computation steps',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('dyadformer:',\n",
       "  (('dyadformer: a multi-modal transformer for long-range modeling of dyadic interactions',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('t2t',\n",
       "  (('ted-net: convolution-free t2t vision transformer-based encoder-decoder dilation network for low-dose ct denoising',\n",
       "    2),\n",
       "   10.685186796595348)),\n",
       " ('interleaved',\n",
       "  (('a novel interleaved transformerless ultra-high step-up dc/dc converter',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('interleaved',\n",
       "  (('a two-phase interleaved high-voltage gain dc-dc converter with coupled inductor and built-in transformer for photovoltaic applications',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('interleaved',\n",
       "  (('a novel interleaved high step-up converter with built-in transformer voltage multiplier cell',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('interleaved',\n",
       "  (('nnformer: interleaved transformer for volumetric segmentation', 1),\n",
       "   9.363258701707986)),\n",
       " ('guiding',\n",
       "  (('guiding query position and performing similar attention for transformer-based detection heads',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('guiding',\n",
       "  (('enhancing transformer with horizontal and vertical guiding mechanisms for neural language modeling',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('guiding',\n",
       "  (('captioning transformer with scene graph guiding', 1), 9.685186796595348)),\n",
       " ('forward',\n",
       "  (('paint transformer: feed forward neural painting with stroke prediction',\n",
       "    2),\n",
       "   10.100224295874192)),\n",
       " ('forward',\n",
       "  (('label-synchronous speech-to-text alignment for asr using forward and backward transformers',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('link',\n",
       "  (('self-attention presents low-dimensional knowledge graph embeddings for link prediction',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('link',\n",
       "  (('an efficient link prediction model in dynamic heterogeneous information networks based on multiple self-attention',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('link',\n",
       "  (('modulation and control of a dc-ac converter with high-frequency link transformer for grid-connected applications',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('pretraining',\n",
       "  (('task adaptive pretraining of transformers for hostility detection', 1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('iiith at semeval-2021 task 7: leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('normformer: improved transformer pretraining with extra normalization',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('when vision transformers outperform resnets without pretraining or strong data augmentations',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('bevt: bert pretraining of video transformers', 1), 7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('combining cnns with transformer for multimodal 3d mri brain tumor segmentation with self-supervised pretraining',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('self-supervised pretraining of transformers for satellite image time series classification',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('tunet: a block-online bandwidth extension model based on transformers and self-supervised pretraining',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('wangchanberta: pretraining transformer-based thai language models', 1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('billion-scale pretraining with vision transformers for multi-task visual representations',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('script: self-critic pretraining of transformers', 1), 7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('pretraining',\n",
       "  (('m6: multi-modality-to-multi-modality multitask mega-transformer for unified pretraining',\n",
       "    1),\n",
       "   7.877831874537744)),\n",
       " ('tweets',\n",
       "  (('detection of threat records by analyzing the tweets in urdu language exploring deep learning transformer - based models',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('empirical study of tweets topic classification using transformer-based language models',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('covid-19 tweets analysis through transformer language models', 1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('bch-nlp at biocreative vii track 3: medications detection in tweets using transformer networks and multi-task learning',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('bert transformer model for detecting arabic gpt2 auto-generated tweets',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('detection of abusive records by analyzing the tweets in urdu language exploring transformer based models',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "    2),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('analyzing covid-19 tweets with transformer-based language models', 1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('fine-tuning transformers for identifying self-reporting potential cases and symptoms of covid-19 in tweets',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('tweets',\n",
       "  (('leveraging transformers for hate speech detection in conversational code-mixed tweets',\n",
       "    1),\n",
       "   8.22575517795805)),\n",
       " ('60ghz',\n",
       "  (('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('mlp',\n",
       "  (('diabetic retinopathy detection using cnn, transformer and mlp based architectures',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('mlp',\n",
       "  (('uninet: unified architecture search with convolution, transformer, and mlp',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('mlp',\n",
       "  (('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('mlp',\n",
       "  (('sparse mlp for image recognition: is self-attention really necessary?',\n",
       "    1),\n",
       "   9.363258701707986)),\n",
       " ('w911nf1910069',\n",
       "  (('text2gestures: a transformer-based network for generating emotive body gestures for virtual agents**this work has been supported in part by aro grants w911nf1910069 and w911nf1910315, and intel. code and additional materials available at: https: //gamma.umd.edu/t2g',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('setting',\n",
       "  (('lightweight transformer in federated setting for human activity recognition',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('setting',\n",
       "  (('boosting transformers for job expression extraction and classification in a low-resource setting',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('setting',\n",
       "  (('application of particle swarm optimization for optimal setting of phase shifting transformers to minimize unscheduled active power flows',\n",
       "    1),\n",
       "   9.685186796595348)),\n",
       " ('sparsebert:',\n",
       "  (('sparsebert: rethinking the importance analysis in self-attention', 2),\n",
       "   10.685186796595348)),\n",
       " ('extraction:',\n",
       "  (('transforming term extraction: transformer-based approaches to multilingual term extraction across domains',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('anti-spoofing',\n",
       "  (('on the effectiveness of vision transformers for zero-shot face anti-spoofing',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('fmri',\n",
       "  (('pre-training and fine-tuning transformers for fmri prediction tasks', 1),\n",
       "   10.685186796595348)),\n",
       " ('git:',\n",
       "  (('git: graph interactive transformer for vehicle re-identification', 1),\n",
       "   10.685186796595348)),\n",
       " ('spatial',\n",
       "  (('rethinking spatial dimensions of vision transformers', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('learning with self-attention for rental market spatial dynamics in the atlanta metropolitan area',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('spatial self-attention network with self-attention distillation for fine-grained image recognition',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('sparse spatial transformers for few-shot learning', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('spatial transformer network-based automatic modulation recognition of blind signals',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('shuffle transformer: rethinking spatial shuffle for vision transformer',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('cross-view gait recognition using pairwise spatial transformer networks',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('spatial generation of molecules with transformers', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('spatial transformer networks for curriculum learning', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('discovering spatial relationships by transformers for domain generalization',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('tempera: spatial transformer feature pyramid network for cardiac mri segmentation',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('pose discrepancy spatial transformer based feature disentangling for partial aspect angles sar target recognition',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('towards physically consistent data-driven weather forecasting: integrating data assimilation with equivariance-preserving deep spatial transformers',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('differentiable spatial planning using transformers', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('detectornet: transformer-enhanced spatial temporal graph neural network for traffic prediction',\n",
       "    2),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('single- and cross-modality near duplicate image pairs detection via spatial transformer comparing cnn',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('multi-scale spatial transformer network for lidar-camera 3d object detection',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('a reinforcement learning approach for sequential spatial transformer networks',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('spatial context-aware self-attention model for multi-organ segmentation',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('pedestrian trajectory prediction via spatial interaction transformer network',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('looking beyond two frames: end-to-end multi-object tracking using spatial and temporal transformers',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('learning cross-domain descriptors for 2d-3d matching with hard triplet loss and spatial transformer network',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('skeleton-based action recognition via spatial and temporal transformer networks',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('twins: revisiting the design of spatial attention in vision transformers',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('layouttransformer: scene layout generation with conceptual and spatial diversity',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('teds-net: enforcing diffeomorphisms in spatial transformers to guarantee topology preservation in segmentations',\n",
       "    2),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('3d human pose estimation with spatial and temporal transformers', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('twins: revisiting spatial attention design in vision transformers', 1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('mist: multiple instance spatial transformer', 1), 6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('msg-transformer: exchanging local spatial information by manipulating messenger tokens',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('spatial',\n",
       "  (('dprost: 6-dof object pose estimation using space carving and dynamic projective spatial transformer',\n",
       "    1),\n",
       "   6.640792677236894)),\n",
       " ('making',\n",
       "  (('making transformers solve compositional tasks', 1), 10.100224295874192)),\n",
       " ('making',\n",
       "  (('best of both worlds: making high accuracy non-incremental transformer-based disfluency detection incremental',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('modulation',\n",
       "  (('modulation and control of a dc-ac converter with high-frequency link transformer for grid-connected applications',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('automatic modulation classification based on improved r-transformer', 1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('modulation strategy and control of modular cascade h-bridge converters as input-side of a multi-port smart transformer',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('mcformer: a transformer based deep neural network for automatic modulation classification',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('multilevel inverter with a new modulation method applied to solid-state transformer in pv applications',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('programmable integrated microwave photonic filter using a modulation transformer and a double-injection ring resonator',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('modulation',\n",
       "  (('spatial transformer network-based automatic modulation recognition of blind signals',\n",
       "    1),\n",
       "   8.685186796595348)),\n",
       " ('ingredients',\n",
       "  (('recipebowl: a cooking recommender for ingredients and recipes using set transformer',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('lenses',\n",
       "  (('finding strong gravitational lenses through self-attention', 1),\n",
       "   10.685186796595348)),\n",
       " ('paralinguistic',\n",
       "  (('transcribing paralinguistic acoustic cues to target language text in transformer-based speech-to-text translation',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('poi',\n",
       "  (('transformer-based multi-task learning for queuing time aware next poi recommendation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('poi',\n",
       "  (('mgsan: a multi-granularity self-attention network for next poi recommendation',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('shallow',\n",
       "  (('reasoning with transformer-based models: deep learning, but shallow reasoning',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('shallow',\n",
       "  (('shallow convolution-augmented transformer with differentiable neural computer for low-complexity classification of variable-length acoustic scene',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('bloomnet:',\n",
       "  ((\"bloomnet: a robust transformer based model for bloom's learning outcome classification\",\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('stransgan:',\n",
       "  (('stransgan: an empirical study on transformer in gans', 1),\n",
       "   10.685186796595348)),\n",
       " ('improvement',\n",
       "  (('accuracy improvement of power transformer faults diagnostic using knn classifier with decision tree principle',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('improvement',\n",
       "  (('a tag-based transformer community question answering learning-to-rank model in the home improvement domain',\n",
       "    1),\n",
       "   10.100224295874192)),\n",
       " ('traveling-waves-based',\n",
       "  (('wide-band current transformers for traveling-waves-based protection applications',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('oadtr:',\n",
       "  (('oadtr: online action detection with transformers', 1),\n",
       "   10.685186796595348)),\n",
       " ('sgtr:',\n",
       "  (('sgtr: end-to-end scene graph generation with transformer', 1),\n",
       "   10.685186796595348)),\n",
       " ('transzero++:',\n",
       "  (('transzero++: cross attribute-guided transformer for zero-shot learning',\n",
       "    1),\n",
       "   10.685186796595348)),\n",
       " ('pnp-detr:',\n",
       "  (('pnp-detr: towards efficient visual analysis with transformers', 2),\n",
       "   10.685186796595348)),\n",
       " ('anomaly',\n",
       "  (('sss-ae: anomaly detection using self-attention based sequence-to-sequence auto-encoder in smd assembly machine sound',\n",
       "    1),\n",
       "   7.2257551779580504)),\n",
       " ...]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(feature, TF, idf)\n",
    "rdd=tf.join(idf)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "60e280f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('icd-10', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('$\\\\mathcal{laja}{-}$', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('unstructured', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('architectures', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('coding', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('notes', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('attention', 1, 4.707906873095431, 4.707906873095431)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('label', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('$\\\\mathcal{laja}{-}$ label attention transformer architectures for icd-10 coding of unstructured clinical notes',\n",
       "  ('clinical', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('segmentation', 1, 4.651763795057898, 4.651763795057898)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('point', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('cloud', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('1d', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('lidar', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('semantic', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('omnidirectional', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('1d self-attention network for point cloud semantic segmentation using omnidirectional lidar',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('complex', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('efficiency', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('26.5', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('quadrature', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('domain', 1, 6.399784577733099, 6.399784577733099)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('reconfigurable', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('watt-level', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('self-coupling', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('switched/floated-capacitor', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('back-off', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('canceling', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('enhancement', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('26.5 a watt-level quadrature switched/floated-capacitor power amplifier with back-off efficiency enhancement in complex domain using reconfigurable self-coupling canceling transformer',\n",
       "  ('amplifier', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('hybrid', 1, 6.193333700265673, 6.193333700265673)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('asymmetric', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('power-splitting-', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('varactors', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('65nm', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('upconverter', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('mos', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('double-balanced', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('parametric', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('270-to-300ghz double-balanced parametric upconverter using asymmetric mos varactors and a power-splitting- transformer hybrid in 65nm cmos',\n",
       "  ('270-to-300ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('2d', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('recurrent', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('text', 1, 5.055830176515738, 5.055830176515738)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('handwritten', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('convolutional', 1, 5.418400255900446, 5.418400255900446)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('offline', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('2d self-attention convolutional recurrent network for offline handwritten text recognition',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('2d', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('sinusoidal', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('learnable', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('scene', 1, 6.515261795153036, 6.515261795153036)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('text', 1, 5.055830176515738, 5.055830176515738)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('2lspe:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('encoding', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('positional', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('2lspe: 2d learnable sinusoidal positional encoding using transformer for scene text recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('3-d', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('algorithms', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('patrol', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('localization', 1, 7.100224295874192, 7.100224295874192)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('emd', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('phat-β', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('ultrasonic', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('3-d ultrasonic localization of transformer patrol robot based on emd and phat-β algorithms',\n",
       "  ('robot', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('segmentation', 1, 4.651763795057898, 4.651763795057898)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('attentive', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('volume', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('tumor', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('u-net', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('automated', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('breast', 2, 9.100224295874192, 18.200448591748383)),\n",
       " ('3d deep attentive u-net with transformer for breast tumor segmentation from automated breast volume scanner',\n",
       "  ('scanner', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('estimation', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('spatial', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('temporal', 1, 6.161624840538335, 6.161624840538335)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('human', 1, 6.363258701707985, 6.363258701707985)),\n",
       " ('3d human pose estimation with spatial and temporal transformers',\n",
       "  ('pose', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('estimation', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('texture', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('human', 1, 6.363258701707985, 6.363258701707985)),\n",
       " ('3d human texture estimation from a single image with transformers',\n",
       "  ('single', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('point', 2, 6.4372592831517625, 12.874518566303525)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('introducing', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('attention', 1, 4.707906873095431, 4.707906873095431)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('cloud', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('convolution', 1, 6.984747078454255, 6.984747078454255)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('analysis', 1, 5.13059794491771, 5.13059794491771)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('medical', 2, 5.957266342032148, 11.914532684064296)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('transformer:', 1, 5.730990486208472, 5.730990486208472)),\n",
       " ('3d medical point transformer: introducing convolution to attention networks for medical point cloud analysis',\n",
       "  ('networks', 1, 4.629904361094158, 4.629904361094158)),\n",
       " ('3d object tracking with transformer',\n",
       "  ('tracking', 1, 6.9302992944318795, 6.9302992944318795)),\n",
       " ('3d object tracking with transformer',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d object tracking with transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3d object tracking with transformer',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d object tracking with transformer',\n",
       "  ('object', 1, 5.327634791977264, 5.327634791977264)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('pet', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('transformer-gan', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('high-quality', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d transformer-gan for high-quality pet reconstruction',\n",
       "  ('reconstruction', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('v2:', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('automatically', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('module', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('3d-anas', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('grafting', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('convnet', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('designed', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('3d-anas v2: grafting transformer module on automatically designed convnet for hyperspectral image classification',\n",
       "  ('hyperspectral', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('3d-retr:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('end-to-end', 1, 5.515261795153036, 5.515261795153036)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('reconstruction', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('single', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('3d-retr: end-to-end single and multi-view 3d reconstruction with transformers',\n",
       "  ('multi-view', 1, 7.778296200986829, 7.778296200986829)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('space', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('3d-transformer:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('molecular', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('3d-transformer: molecular representation with transformer in 3d space',\n",
       "  ('representation', 1, 5.707906873095431, 5.707906873095431)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('3dmet:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('cartilage', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('assessment', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('knee', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('3d', 1, 5.310147365248423, 5.310147365248423)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('medical', 1, 5.957266342032148, 5.957266342032148)),\n",
       " ('3dmet: 3d medical image transformer for knee cartilage defect assessment',\n",
       "  ('defect', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('clouds', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('3dvg-transformer:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('point', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('grounding', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('modeling', 1, 6.25892204189325, 6.25892204189325)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('visual', 1, 4.998686269412129, 4.998686269412129)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('3dvg-transformer: relation modeling for visual grounding on point clouds',\n",
       "  ('relation', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('coding', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('domain', 1, 6.399784577733099, 6.399784577733099)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('event', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('crime', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('3m-transformers', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('3m-transformers for event coding on organized crime domain',\n",
       "  ('organized', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('estimation', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('category-level', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('via', 1, 4.640792677236894, 4.640792677236894)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('6d', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('6d-vit:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('instance', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('representation', 1, 5.707906873095431, 5.707906873095431)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('pose', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('6d-vit: category-level 6d object pose estimation via transformer-based instance representation learning',\n",
       "  ('object', 1, 5.327634791977264, 5.327634791977264)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('glass-based', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('density', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('fan-out', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('transformer-in-package', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('1.25w', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('wafer-level', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('achieving', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('packaging', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('isolated', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('dc-dc', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('50mw/mm2', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('46.5%-peak-efficiency', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.25w 46.5%-peak-efficiency transformer-in-package isolated dc-dc converter using glass-based fan-out wafer-level packaging achieving 50mw/mm2 power density',\n",
       "  ('converter', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('5ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('1.75db-nf', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('noise-', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('cancelling', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('front-end', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('receiver', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 1.75db-nf 25mw 5ghz transformer-based noise- cancelling cmos receiver front-end',\n",
       "  ('25mw', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('vco', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('16.8-to-21.6', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('optimal', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('tank', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('65-nm', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('196.2', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('fomt', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('class-f23', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('dbc/hz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('ghz', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 196.2 dbc/hz fomt 16.8-to-21.6 ghz class-f23 vco with transformer-based optimal q-factor tank in 65-nm cmos',\n",
       "  ('q-factor', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('2-ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('class-d', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('a', 3, 2.657280800025463, 7.971842400076389)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('reconfigurable', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('pa', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('multi-tapped', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a 2-ghz reconfigurable transmitter using a class-d pa and a multi-tapped transformer',\n",
       "  ('transmitter', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('application', 1, 7.100224295874192, 7.100224295874192)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('high-k', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('x-band', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('compact', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('output', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('21.6dbm', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 21.6dbm cmos power amplifier using a compact high-k output transformer for x-band application',\n",
       "  ('amplifier', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('voltage', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('25.4%', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('25.1', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('x-band', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('combining', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('65-nm', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('gain', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('dbm', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('utilizing', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('25.9-db', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('amplifier', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a 25.1 dbm 25.9-db gain 25.4% pae x-band power amplifier utilizing voltage combining transformer in 65-nm cmos',\n",
       "  ('pae', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('doubler', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('separation', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('268-325', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('psat', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('sige', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('5.2', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('technology', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('dbm', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('bicmos', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('frequency', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('ghz', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 268-325 ghz 5.2 dbm psat frequency doubler using transformer-based mode separation in sige bicmos technology',\n",
       "  ('mode', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('hybrid', 1, 6.193333700265673, 6.193333700265673)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('quadrature', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('doherty', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('28-ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('compact', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('65-nm', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a 28-ghz doherty power amplifier with a compact transformer-based quadrature hybrid in 65-nm cmos',\n",
       "  ('amplifier', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('hybrid', 1, 6.193333700265673, 6.193333700265673)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('shifter', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('passive', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('shifting', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('phase', 2, 8.685186796595348, 17.370373593190696)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('30-36', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('technique', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('reflect-type', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('high-resolution', 1, 7.778296200986829, 7.778296200986829)),\n",
       " ('a 30-36 ghz passive hybrid phase shifter with a transformer-based high-resolution reflect-type phase shifting technique',\n",
       "  ('ghz', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('60ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('vco', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('no', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('circular', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('65nm', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('186.5dbc/hz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('quad-core', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('fundamental', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('fom', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('ambiguity', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('triple-coupled', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 60ghz 186.5dbc/hz fom quad-core fundamental vco using circular triple-coupled transformer with no mode ambiguity in 65nm cmos',\n",
       "  ('mode', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('vco', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('pll', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('dual-mode', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('fomt', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('sub-sampling', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('7.9-14.3ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('40nm', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a 7.9-14.3ghz -243.3db fomt sub-sampling pll with transformer-based dual-mode vco in 40nm cmos',\n",
       "  ('-243.3db', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('structures:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('mlp', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('study', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('empirical', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('an', 1, 5.08527395440822, 5.08527395440822)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('transformer,', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('of', 2, 2.603037755241476, 5.206075510482952)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('battle', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('cnn,', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a battle of network structures: an empirical study of cnn, transformer, and mlp',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('word', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('alignment', 2, 7.877831874537744, 15.755663749075488)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('unsupervised', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a bidirectional transformer based alignment model for unsupervised word alignment',\n",
       "  ('bidirectional', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('end-to-end', 2, 5.515261795153036, 11.030523590306071)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('spotter', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('video', 4, 5.012761454623852, 20.051045818495407)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('text', 4, 5.055830176515738, 20.223320706062953)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('bilingual,', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('openworld', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('dataset', 2, 8.685186796595348, 17.370373593190696)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('transformer', 2, 1.1058708590153334, 2.211741718030667)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('and', 2, 2.3587573094730443, 4.717514618946089)),\n",
       " ('a bilingual, openworld video text dataset and end-to-end video text spotter with transformer',\n",
       "  ('with', 2, 2.0834160081876374, 4.166832016375275)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('cascode', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('amplifiers', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('tri-coil', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('mm-wave', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('broadband', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a broadband tri-coil based transformer design for mm-wave cascode amplifiers',\n",
       "  ('design', 1, 6.363258701707985, 6.363258701707985)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('voltage', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('cvt', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('study', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('(cvt)', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('400', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('transmission', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('case', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('behaviour', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('secondary', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('capacitive', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('on', 2, 3.21758124651235, 6.4351624930247)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('line', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('earthing', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('multiple', 1, 7.2257551779580504, 7.2257551779580504)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('kv', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a case study on capacitive voltage transformer (cvt) behaviour on multiple earthing of cvt secondary circuit in a 400 kv transmission line',\n",
       "  ('circuit', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('charging', 2, 9.685186796595348, 19.370373593190696)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('strategy', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('reduce', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('cost', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('mitigate', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('operation', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('electric', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('aging', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('fast', 1, 6.877831874537744, 6.877831874537744)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('station', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('distribution', 1, 7.0413306068206225, 7.0413306068206225)),\n",
       " ('a charging strategy for electric vehicle fast charging station to mitigate distribution transformer aging and reduce operation cost',\n",
       "  ('vehicle', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('joint', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('intent', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('slot', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('co-interactive', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a co-interactive transformer for joint slot filling and intent detection',\n",
       "  ('filling', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('landmark', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('facial', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('coarse-to-fine', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('mechanism', 1, 6.161624840538335, 6.161624840538335)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a coarse-to-fine facial landmark detection method based on self-attention mechanism',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('element', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('bearings', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('fault', 1, 6.685186796595348, 6.685186796595348)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('fourier', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('short', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('combined', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('time', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('transform', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('electric', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('rolling', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('diagnosis', 1, 6.2257551779580504, 6.2257551779580504)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('motors', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a combined short time fourier transform and image classification transformer model for rolling element bearings fault diagnosis in electric motors',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('grounded', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('transformerless', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('common', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('type', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('dual-mode', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('photovoltaic', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('five-level', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('applications', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a common grounded type dual-mode five-level transformerless inverter for photovoltaic applications',\n",
       "  ('inverter', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('fractional-n', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('compact', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('10-nm', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('finfet', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a compact transformer-based fractional-n adpll in 10-nm finfet cmos',\n",
       "  ('adpll', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('question', 1, 6.399784577733099, 6.399784577733099)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('comparative', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('study', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('answering', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('video', 1, 5.012761454623852, 5.012761454623852)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('language', 1, 4.33645864236427, 4.33645864236427)),\n",
       " ('a comparative study of language transformers for video question answering',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('question', 1, 6.399784577733099, 6.399784577733099)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('comparative', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('study', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('answering', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('models', 1, 4.2257551779580504, 4.2257551779580504)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('transformer-based', 1, 3.49536223771533, 3.49536223771533)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('language', 1, 4.33645864236427, 4.33645864236427)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('extractive', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a comparative study of transformer-based language models on extractive question answering',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('disambiguation', 2, 9.363258701707986, 18.726517403415972)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('word', 2, 7.597723955345009, 15.195447910690017)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('comparative', 2, 8.363258701707986, 16.726517403415972)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('study', 2, 6.13059794491771, 12.26119588983542)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('sense', 2, 9.685186796595348, 19.370373593190696)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('transformers', 2, 1.9454061868220873, 3.8908123736441746)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('of', 2, 2.603037755241476, 5.206075510482952)),\n",
       " ('a comparative study of transformers on word sense disambiguation',\n",
       "  ('on', 2, 3.21758124651235, 6.4351624930247)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('anti-noise', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('neural', 1, 4.427798953902696, 4.427798953902696)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('robustness', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('methods', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('visual', 1, 4.998686269412129, 4.998686269412129)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('performer', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('tiny', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('comparison', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('dataset:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('convolutional', 1, 5.418400255900446, 5.418400255900446)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a comparison for anti-noise robustness of deep learning classification methods on a tiny object image dataset: from convolutional neural network to visual transformer and performer',\n",
       "  ('object', 1, 5.327634791977264, 5.327634791977264)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('neural', 1, 4.427798953902696, 4.427798953902696)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('methods', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('images:', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('visual', 1, 4.998686269412129, 4.998686269412129)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('patch-level', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('transparent', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('comparison', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('convolutional', 1, 5.418400255900446, 5.418400255900446)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a comparison for patch-level classification of deep learning methods on transparent images: from convolutional neural networks to visual transformers',\n",
       "  ('networks', 1, 4.629904361094158, 4.629904361094158)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('neural', 1, 4.427798953902696, 4.427798953902696)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('set:', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('methods', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('data', 1, 5.685186796595348, 5.685186796595348)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('visual', 1, 4.998686269412129, 4.998686269412129)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('comparison', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('convolutional', 1, 5.418400255900446, 5.418400255900446)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('small-scale', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a comparison of deep learning classification methods on small-scale image data set: from convolutional neural networks to visual transformers',\n",
       "  ('networks', 1, 4.629904361094158, 4.629904361094158)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('multimodal', 1, 5.555903779650381, 5.555903779650381)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('emotion', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('structure', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('residual', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('fusion', 1, 6.161624840538335, 6.161624840538335)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('cross-modal', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a cross-modal fusion network based on self-attention and residual structure for multimodal emotion recognition',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('estimation', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('video', 1, 5.012761454623852, 5.012761454623852)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('attention', 1, 4.707906873095431, 4.707906873095431)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('facial', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('expression', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('pain', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a deep attention transformer network for pain estimation with facial expression video',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('transformers', 1, 1.9454061868220873, 1.9454061868220873)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('twitter', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('approach', 1, 6.012761454623852, 6.012761454623852)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('bots', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a deep learning approach for robust detection of bots in twitter using transformers',\n",
       "  ('robust', 1, 6.778296200986829, 6.778296200986829)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('deep', 1, 4.852296782430606, 4.852296782430606)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('sentence', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('social', 1, 7.2257551779580504, 7.2257551779580504)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('data', 1, 5.685186796595348, 5.685186796595348)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('bert', 1, 6.877831874537744, 6.877831874537744)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('big', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('on', 2, 3.21758124651235, 6.4351624930247)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('extraction', 1, 6.292869373816587, 6.292869373816587)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('keyphrase', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a deep learning model based on bert and sentence transformer for semantic keyphrase extraction on big social data',\n",
       "  ('semantic', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('energy', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('matching', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('harvesting', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('rf', 2, 10.100224295874192, 20.200448591748383)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('ambient', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('front-end', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('systems', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('a differential rf front-end cmos transformer matching for ambient rf energy harvesting systems',\n",
       "  ('differential', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('discriminative', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('super-resolution', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('gan', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('face', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('cycle', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a discriminative self-attention cycle gan for face super-resolution and recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('grid-connected', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('doubly', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('shoot-through', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('grounded', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('without', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('transformerless', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('problem', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('pv', 1, 8.363258701707986, 8.363258701707986)),\n",
       " ('a doubly grounded transformerless pv grid-connected inverter without shoot-through problem',\n",
       "  ('inverter', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('notch', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('application', 1, 7.100224295874192, 7.100224295874192)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('transformer-coupled', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('filter', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('2.45-/5.2-ghz', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('mixer', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('dual-band', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a dual-band transformer-coupled notch filter mixer for 2.45-/5.2-ghz wlan application',\n",
       "  ('wlan', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('quasi-steady-state', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('five-limb', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('three-phase', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('duality', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a duality based quasi-steady-state model of three-phase five-limb sen transformer',\n",
       "  ('sen', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('super-resolution', 1, 7.597723955345009, 7.597723955345009)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('dynamic', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('residual', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('lightweight', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('single', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a dynamic residual self-attention network for lightweight single image super-resolution',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('system', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('facial', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('yolo', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('vision', 1, 3.784319988614599, 3.784319988614599)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('expression', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('smart', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a facial expression recognition system for smart learning based on yolo and vision transformer',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('fitting', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('module', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('added', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('lane', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('fast', 1, 6.877831874537744, 6.877831874537744)),\n",
       " ('a fast detection method for polynomial fitting lane with self-attention module added',\n",
       "  ('polynomial', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('fine-grained', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a fine-grained classification method based on self-attention siamese network',\n",
       "  ('siamese', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('free', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('attention', 1, 4.707906873095431, 4.707906873095431)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('visual', 1, 4.998686269412129, 4.998686269412129)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('fine-grained', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('vit:', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('lunch', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('fusion', 1, 6.161624840538335, 6.161624840538335)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('multi-scale', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('adaptive', 1, 6.399784577733099, 6.399784577733099)),\n",
       " ('a free lunch from vit: adaptive attention multi-scale fusion transformer for fine-grained visual recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('pretraining', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('study', 1, 6.13059794491771, 6.13059794491771)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('further', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('unsupervised', 1, 6.730990486208472, 6.730990486208472)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a further study of unsupervised pretraining for transformer based speech recognition',\n",
       "  ('speech', 1, 4.86500783418016, 4.86500783418016)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('proposal', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('logic', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('a', 2, 2.657280800025463, 5.314561600050926)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('fuzzy', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('incipient', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('diagnosis', 1, 6.2257551779580504, 6.2257551779580504)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('multiple', 1, 7.2257551779580504, 7.2257551779580504)),\n",
       " ('a fuzzy logic proposal for diagnosis multiple incipient faults in a power transformer',\n",
       "  ('faults', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('architectures', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('raw', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('generative', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a generative model for raw audio using transformer architectures',\n",
       "  ('audio', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('generating', 1, 7.515261795153036, 7.515261795153036)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('vae', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('graph', 2, 5.026975313843553, 10.053950627687106)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('molecular', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('approach', 1, 6.012761454623852, 6.012761454623852)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a graph vae and graph transformer approach to generating molecular graphs',\n",
       "  ('graphs', 1, 7.778296200986829, 7.778296200986829)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('measure', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('falling', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('flow', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('based', 1, 3.345336793710723, 3.345336793710723)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('dissipation', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('heat', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('film', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a heat dissipation enhancement measure for transformer based on falling film flow',\n",
       "  ('enhancement', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('dc', 1, 8.22575517795805, 8.22575517795805)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('hybrid', 1, 6.193333700265673, 6.193333700265673)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('dc/dc', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('isolated', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('solid-state', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('bidirectional', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('distribution', 1, 7.0413306068206225, 7.0413306068206225)),\n",
       " ('a hybrid isolated bidirectional dc/dc solid-state transformer for dc distribution network',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('joint', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('e-commerce', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('model', 1, 4.292869373816587, 4.292869373816587)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('category', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('aspect', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a joint self-attention model for aspect category detection in e-commerce reviews',\n",
       "  ('reviews', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('cmos', 1, 7.877831874537744, 7.877831874537744)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('power', 1, 5.242243300746619, 5.242243300746619)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('rf', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('slow-wave', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('high-gain', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('transmission-line', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('k-band', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('130-nm', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a k-band high-gain power amplifier with slow-wave transmission-line transformer in 130-nm rf cmos',\n",
       "  ('amplifier', 1, 8.100224295874192, 8.100224295874192)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('estimation', 1, 5.827205801467775, 5.827205801467775)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('discover', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('cobb', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('structure', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('spine', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('keypoint', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('angle', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a keypoint transformer to discover spine structure for cobb angle estimation',\n",
       "  ('to', 1, 4.505277706580413, 4.505277706580413)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('named', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('masked', 1, 7.778296200986829, 7.778296200986829)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('bi-lstm-crf', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('entity', 1, 6.778296200986829, 6.778296200986829)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a korean named entity recognition method using bi-lstm-crf and masked self-attention',\n",
       "  ('korean', 1, 8.877831874537744, 8.877831874537744)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('identity-preserving', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('face', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('disentangled', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('editing', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a latent transformer for disentangled and identity-preserving face editing',\n",
       "  ('latent', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('images', 1, 6.100224295874192, 6.100224295874192)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('videos', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('face', 1, 7.161624840538335, 7.161624840538335)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('and', 1, 2.3587573094730443, 2.3587573094730443)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('disentangled', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('editing', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a latent transformer for disentangled face editing in images and videos',\n",
       "  ('latent', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('light', 1, 9.100224295874192, 9.100224295874192)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('speech-to-intent', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a light transformer for speech-to-intent applications',\n",
       "  ('applications', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('augmented', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('1-d', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('convolution', 1, 6.984747078454255, 6.984747078454255)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('image', 1, 3.9236355641508682, 3.9236355641508682)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('metric', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('learning', 1, 3.640792677236894, 3.640792677236894)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('lightweight', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('with', 1, 2.0834160081876374, 2.0834160081876374)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('classification', 1, 4.446782057270268, 4.446782057270268)),\n",
       " ('a lightweight 1-d convolution augmented transformer with metric learning for hyperspectral image classification',\n",
       "  ('hyperspectral', 1, 7.685186796595348, 7.685186796595348)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('2d', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('mesh', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('from', 1, 4.827205801467775, 4.827205801467775)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('lightweight', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('graph', 1, 5.026975313843553, 5.026975313843553)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('reconstruction', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('human', 2, 6.363258701707985, 12.72651740341597)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " ('a lightweight graph transformer network for human mesh reconstruction from 2d human pose',\n",
       "  ('pose', 1, 6.640792677236894, 6.640792677236894)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('multidimensional', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('fine-grained', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('self-attention', 1, 3.0889970404509373, 3.0889970404509373)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('lightweight', 1, 7.292869373816587, 7.292869373816587)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('recognition', 1, 3.964087607888162, 3.964087607888162)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('action', 1, 6.070476952480139, 6.070476952480139)),\n",
       " ('a lightweight multidimensional self-attention network for fine-grained action recognition',\n",
       "  ('network', 1, 3.597723955345008, 3.597723955345008)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('detection', 1, 3.437259283151762, 3.437259283151762)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('temperature', 1, 7.877831874537744, 7.877831874537744)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('monitoring', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('malfunction', 1, 10.685186796595348, 10.685186796595348)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('using', 1, 3.197346762772296, 3.197346762772296)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('potential', 1, 8.877831874537744, 8.877831874537744)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('top-oil', 1, 10.685186796595348, 10.685186796595348)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  ('onaf', 1, 10.685186796595348, 10.685186796595348)),\n",
       " (\"a method for fans' potential malfunction detection of onaf transformer using top-oil temperature monitoring\",\n",
       "  (\"fans'\", 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('processing', 1, 7.363258701707985, 7.363258701707985)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('in', 1, 2.8875252707415875, 2.8875252707415875)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('point', 1, 6.4372592831517625, 6.4372592831517625)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('substation', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('method', 1, 5.802543747233506, 5.802543747233506)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('cloud', 1, 6.827205801467775, 6.827205801467775)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('of', 1, 2.603037755241476, 2.603037755241476)),\n",
       " ('a method of point cloud processing in transformer substation',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('need:', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('endnodes', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('execution', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('low-power', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('microcontroller', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('all', 1, 7.4372592831517625, 7.4372592831517625)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('enabling', 1, 9.363258701707986, 9.363258701707986)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('iot', 1, 9.685186796595348, 9.685186796595348)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('is', 1, 6.9302992944318795, 6.9302992944318795)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('transformer', 1, 1.1058708590153334, 1.1058708590153334)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('on', 1, 3.21758124651235, 3.21758124651235)),\n",
       " ('a microcontroller is all you need: enabling transformer execution on low-power iot endnodes',\n",
       "  ('you', 1, 7.984747078454255, 7.984747078454255)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('tweets', 2, 8.22575517795805, 16.4515103559161)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('are', 2, 7.100224295874192, 14.200448591748383)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('for', 2, 1.0198508794101715, 2.039701758820343)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('service', 2, 9.100224295874192, 18.200448591748383)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('a', 4, 2.657280800025463, 10.629123200101851)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('tasks', 2, 7.100224295874192, 14.200448591748383)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('transformers', 2, 1.9454061868220873, 3.8908123736441746)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('few', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('tuning', 2, 10.100224295874192, 20.200448591748383)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('worth', 2, 8.877831874537744, 17.755663749075488)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('customer', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('points:', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a million tweets are worth a few points: tuning transformers for customer service tasks',\n",
       "  ('million', 2, 10.685186796595348, 21.370373593190696)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('for', 1, 1.0198508794101715, 1.0198508794101715)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('transformer-coupled', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('sensors', 1, 8.685186796595348, 8.685186796595348)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('a', 1, 2.657280800025463, 2.657280800025463)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('low-noise', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('resistance', 1, 10.100224295874192, 10.100224295874192)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('low', 2, 7.984747078454255, 15.96949415690851)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('miniature', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('source', 1, 8.515261795153036, 8.515261795153036)),\n",
       " ('a miniature transformer-coupled low-noise preamplifier for low source resistance sensors at low frequency',\n",
       "  ('preamplifier', 1, 10.685186796595348, 10.685186796595348)),\n",
       " ...]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(title,(feature, tf, idf, tf*idf))] : calculate tf-idf\n",
    "rdd=rdd.map(lambda x: (x[1][0][0],(x[0],x[1][0][1],x[1][1],x[1][0][1]*x[1][1]))).sortByKey()\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "561afe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---+------------------+------------------+\n",
      "|               title|            feature| TF|               IDF|            TF-IDF|\n",
      "+--------------------+-------------------+---+------------------+------------------+\n",
      "|$\\mathcal{laja}{-...|             icd-10|  1|10.100224295874192|10.100224295874192|\n",
      "|$\\mathcal{laja}{-...|$\\mathcal{laja}{-}$|  1|10.685186796595348|10.685186796595348|\n",
      "|$\\mathcal{laja}{-...|                for|  1|1.0198508794101715|1.0198508794101715|\n",
      "|$\\mathcal{laja}{-...|       unstructured|  1|10.685186796595348|10.685186796595348|\n",
      "|$\\mathcal{laja}{-...|      architectures|  1| 7.515261795153036| 7.515261795153036|\n",
      "|$\\mathcal{laja}{-...|             coding|  1| 9.100224295874192| 9.100224295874192|\n",
      "|$\\mathcal{laja}{-...|              notes|  1|10.685186796595348|10.685186796595348|\n",
      "|$\\mathcal{laja}{-...|          attention|  1| 4.707906873095431| 4.707906873095431|\n",
      "|$\\mathcal{laja}{-...|                 of|  1| 2.603037755241476| 2.603037755241476|\n",
      "|$\\mathcal{laja}{-...|        transformer|  1|1.1058708590153334|1.1058708590153334|\n",
      "|$\\mathcal{laja}{-...|              label|  1|10.100224295874192|10.100224295874192|\n",
      "|$\\mathcal{laja}{-...|           clinical|  1| 7.685186796595348| 7.685186796595348|\n",
      "|1d self-attention...|       segmentation|  1| 4.651763795057898| 4.651763795057898|\n",
      "|1d self-attention...|                for|  1|1.0198508794101715|1.0198508794101715|\n",
      "|1d self-attention...|              point|  1|6.4372592831517625|6.4372592831517625|\n",
      "|1d self-attention...|              cloud|  1| 6.827205801467775| 6.827205801467775|\n",
      "|1d self-attention...|              using|  1| 3.197346762772296| 3.197346762772296|\n",
      "|1d self-attention...|                 1d|  1|10.685186796595348|10.685186796595348|\n",
      "|1d self-attention...|     self-attention|  1|3.0889970404509373|3.0889970404509373|\n",
      "|1d self-attention...|              lidar|  1|10.100224295874192|10.100224295874192|\n",
      "+--------------------+-------------------+---+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# put into dataframe\n",
    "rdd=rdd.map(lambda x: (x[0],x[1][0],x[1][1],x[1][2],x[1][3]))\n",
    "rdd.toDF([\"title\",\"feature\",\"TF\",\"IDF\",\"TF-IDF\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3ee23693",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdddf = rdd.toDF([\"title\",\"feature\",\"TF\",\"IDF\",\"TF-IDF\"])\n",
    "rdddf.createOrReplaceTempView(\"rdddfv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2f285a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- feature: string (nullable = true)\n",
      " |-- TF: long (nullable = true)\n",
      " |-- IDF: double (nullable = true)\n",
      " |-- (CAST(TF AS DOUBLE) - IDF): double (nullable = true)\n",
      " |-- TF_norm: double (nullable = true)\n",
      " |-- TF_IDF_norm: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdddf2 = spark.sql(\"select r.title, r.feature, r.TF, r.IDF, r.TF-IDF, r.TF/d.total_terms as TF_norm, r.TF*r.IDF/d.total_terms as TF_IDF_norm  \\\n",
    "                    from rdddfv r \\\n",
    "                    join dblp_tfidf1v d \\\n",
    "                       on r.title = d.title \")\n",
    "rdddf2.printSchema()\n",
    "rdddf2.createOrReplaceTempView(\"rdddf2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1f648fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- TF_IDF: double (nullable = true)\n",
      " |-- TF_IDF_norm: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate sum of tf-idf of both self-attention and transformer\n",
    "dblp_tfidf9 = spark.sql(\"select r.title, sum(r.TF-IDF) as TF_IDF, sum(r.TF_IDF_norm) as TF_IDF_norm \\\n",
    "                         from rdddf2v r \\\n",
    "                         where r.feature = 'self-attention' \\\n",
    "                             or r.feature = 'transformer' \\\n",
    "                         group by r.title \\\n",
    "                         order by TF_IDF_norm desc \\\n",
    "                         limit 10\")\n",
    "dblp_tfidf9.printSchema()\n",
    "dblp_tfidf9.createOrReplaceTempView(\"dblp_tfidf9v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c17e40fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- journal_conference: string (nullable = true)\n",
      " |-- TF_IDF_norm: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get results\n",
    "dblp_tfidf10 = spark.sql(\"select d9.title, d.author._VALUE as author, d.year, d.journal_conference, d9.TF_IDF_norm \\\n",
    "                          from dblp_tfidf9v d9 \\\n",
    "                          join dblp_allv d \\\n",
    "                             on d9.title = d.title \\\n",
    "                          order by TF_IDF_norm desc\")\n",
    "dblp_tfidf10.printSchema()\n",
    "dblp_tfidf10.createOrReplaceTempView(\"dblp_tfidf10v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e386f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- journal_conference: string (nullable = true)\n",
      " |-- TF_IDF: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get results filter out corr\n",
    "dblp_tfidf11 = spark.sql(\"select distinct title, min(author) author, min(year) year, first(journal_conference) journal_conference, min(TF_IDF_norm) TF_IDF\\\n",
    "                          from dblp_tfidf10v \\\n",
    "                          group by title \\\n",
    "                          order by TF_IDF desc\")\n",
    "dblp_tfidf11.printSchema()\n",
    "dblp_tfidf11.createOrReplaceTempView(\"dblp_tfidf11v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37621e52",
   "metadata": {},
   "source": [
    "### Query 4 result<a name=\"4.4.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7633f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+--------------------+------------------+\n",
      "|               title|              author|year|  journal_conference|            TF_IDF|\n",
      "+--------------------+--------------------+----+--------------------+------------------+\n",
      "|relative molecule...|[Lukasz Maziarka,...|2021|                CoRR|1.0487169748665677|\n",
      "|self-attention fo...|[Nathanaeumll Car...|2021|                MLSP|0.7722492601127343|\n",
      "|self-attention ag...|[Rita Pucci, Chri...|2021|               ICCVW|0.7722492601127343|\n",
      "|transformer in tr...|[Kai Han 0002, An...|2021|             NeurIPS|0.7372472393435556|\n",
      "|lite vision trans...|[Chenglin Yang, Y...|2021|                CoRR|0.6991446499110451|\n",
      "|synthesizer: reth...|[Yi Tay, Dara Bah...|2021|                ICML|0.6991446499110451|\n",
      "|spatial self-atte...|[Adu Asare Baffou...|2021|J. Vis. Commun. I...|0.6177994080901874|\n",
      "|session-based rec...|          [Jun Fang]|2021|                CoRR|0.6177994080901874|\n",
      "|local-to-global s...|[Jinpeng Li, Yich...|2021|                CoRR|0.6177994080901874|\n",
      "|self-attention me...|[Ghada Sokar, Dec...|2021|                CoRR|0.6177994080901874|\n",
      "+--------------------+--------------------+----+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "18b4a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+\n",
      "|title                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|relative molecule self-attention transformer                                                      |\n",
      "|self-attention for audio super-resolution                                                         |\n",
      "|self-attention agreement among capsules                                                           |\n",
      "|transformer in transformer                                                                        |\n",
      "|synthesizer: rethinking self-attention for transformer models                                     |\n",
      "|lite vision transformer with enhanced self-attention                                              |\n",
      "|self-attention meta-learner for continual learning                                                |\n",
      "|spatial self-attention network with self-attention distillation for fine-grained image recognition|\n",
      "|local-to-global self-attention in vision transformers                                             |\n",
      "|session-based recommendation with self-attention networks                                         |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dblp_tfidf11.select('title').show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03839357",
   "metadata": {},
   "source": [
    "# 5- Preprocess XML to remove HTML escaped characters <a name=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "023c5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlines(path):\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines() \n",
    "    return Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fed9c8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'dblp.xml'\n",
    "Lines = getlines(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b57dd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "specdict2 = {\"&amp;\":\"and\",\n",
    "\"&lt;\":\"lessthan\",\n",
    "\"&gt;\":\"greaterthan\",\n",
    "\"&nbsp;\":\"nbsp\",\n",
    "\"&iexcl;\":\"iexcl\",\n",
    "\"&cent;\":\"cent\",\n",
    "\"&pound;\":\"pound\",\n",
    "\"&curren;\":\"curren\",\n",
    "\"&yen;\":\"yen\",\n",
    "\"&brvbar;\":\"brvbar\",\n",
    "\"&sect;\":\"sect\",\n",
    "\"&uml;\":\"uml\",\n",
    "\"&copy;\":\"copy\",\n",
    "\"&ordf;\":\"ordf\",\n",
    "\"&laquo;\":\"laquo\",\n",
    "\"&not;\":\"not\",\n",
    "\"&shy;\":\"shy\",\n",
    "\"&reg;\":\"reg\",\n",
    "\"&macr;\":\"macr\",\n",
    "\"&deg;\":\"deg\",\n",
    "\"&plusmn;\":\"plusmn\",\n",
    "\"&sup2;\":\"sup2\",\n",
    "\"&sup3;\":\"sup3\",\n",
    "\"&acute;\":\"acute\",\n",
    "\"&micro;\":\"micro\",\n",
    "\"&para;\":\"para\",\n",
    "\"&middot;\":\"middot\",\n",
    "\"&cedil;\":\"cedil\",\n",
    "\"&sup1;\":\"sup1\",\n",
    "\"&ordm;\":\"ordm\",\n",
    "\"&raquo;\":\"raquo\",\n",
    "\"&frac14;\":\"frac14\",\n",
    "\"&frac12;\":\"frac12\",\n",
    "\"&frac34;\":\"frac34\",\n",
    "\"&iquest;\":\"iquest\",\n",
    "\"&Agrave;\":\"Agrave\",\n",
    "\"&Aacute;\":\"Aacute\",\n",
    "\"&Acirc;\":\"Acirc\",\n",
    "\"&Atilde;\":\"Atilde\",\n",
    "\"&Auml;\":\"Auml\",\n",
    "\"&Aring;\":\"Aring\",\n",
    "\"&AElig;\":\"AElig\",\n",
    "\"&Ccedil;\":\"Ccedil\",\n",
    "\"&Egrave;\":\"Egrave\",\n",
    "\"&Eacute;\":\"Eacute\",\n",
    "\"&Ecirc;\":\"Ecirc\",\n",
    "\"&Euml;\":\"Euml\",\n",
    "\"&Igrave;\":\"Igrave\",\n",
    "\"&Iacute;\":\"Iacute\",\n",
    "\"&Icirc;\":\"Icirc\",\n",
    "\"&Iuml;\":\"Iuml\",\n",
    "\"&ETH;\":\"ETH\",\n",
    "\"&Ntilde;\":\"Ntilde\",\n",
    "\"&Ograve;\":\"Ograve\",\n",
    "\"&Oacute;\":\"Oacute\",\n",
    "\"&Ocirc;\":\"Ocirc\",\n",
    "\"&Otilde;\":\"Otilde\",\n",
    "\"&Ouml;\":\"Ouml\",\n",
    "\"&times;\":\"times\",\n",
    "\"&Oslash;\":\"Oslash\",\n",
    "\"&Ugrave;\":\"Ugrave\",\n",
    "\"&Uacute;\":\"Uacute\",\n",
    "\"&Ucirc;\":\"Ucirc\",\n",
    "\"&Uuml;\":\"Uuml\",\n",
    "\"&Yacute;\":\"Yacute\",\n",
    "\"&THORN;\":\"THORN\",\n",
    "\"&szlig;\":\"szlig\",\n",
    "\"&agrave;\":\"agrave\",\n",
    "\"&aacute;\":\"aacute\",\n",
    "\"&acirc;\":\"acirc\",\n",
    "\"&atilde;\":\"atilde\",\n",
    "\"&auml;\":\"auml\",\n",
    "\"&aring;\":\"aring\",\n",
    "\"&aelig;\":\"aelig\",\n",
    "\"&ccedil;\":\"ccedil\",\n",
    "\"&egrave;\":\"egrave\",\n",
    "\"&eacute;\":\"eacute\",\n",
    "\"&ecirc;\":\"ecirc\",\n",
    "\"&euml;\":\"euml\",\n",
    "\"&igrave;\":\"igrave\",\n",
    "\"&iacute;\":\"iacute\",\n",
    "\"&icirc;\":\"icirc\",\n",
    "\"&iuml;\":\"iuml\",\n",
    "\"&eth;\":\"eth\",\n",
    "\"&ntilde;\":\"ntilde\",\n",
    "\"&ograve;\":\"ograve\",\n",
    "\"&oacute;\":\"oacute\",\n",
    "\"&ocirc;\":\"ocirc\",\n",
    "\"&otilde;\":\"otilde\",\n",
    "\"&ouml;\":\"ouml\",\n",
    "\"&divide;\":\"divide\",\n",
    "\"&oslash;\":\"oslash\",\n",
    "\"&ugrave;\":\"ugrave\",\n",
    "\"&uacute;\":\"uacute\",\n",
    "\"&ucirc;\":\"ucirc\",\n",
    "\"&uuml;\":\"uuml\",\n",
    "\"&yacute;\":\"yacute\",\n",
    "\"&thorn;\":\"thorn\",\n",
    "\"&yuml;\":\"yuml\",\n",
    "\"&fnof;\":\"fnof\",\n",
    "\"&Alpha;\":\"Alpha\",\n",
    "\"&Beta;\":\"Beta\",\n",
    "\"&Gamma;\":\"Gamma\",\n",
    "\"&Delta;\":\"Delta\",\n",
    "\"&Epsilon;\":\"Epsilon\",\n",
    "\"&Zeta;\":\"Zeta\",\n",
    "\"&Eta;\":\"Eta\",\n",
    "\"&Theta;\":\"Theta\",\n",
    "\"&Iota;\":\"Iota\",\n",
    "\"&Kappa;\":\"Kappa\",\n",
    "\"&Lambda;\":\"Lambda\",\n",
    "\"&Mu;\":\"Mu\",\n",
    "\"&Nu;\":\"Nu\",\n",
    "\"&Xi;\":\"Xi\",\n",
    "\"&Omicron;\":\"Omicron\",\n",
    "\"&Pi;\":\"Pi\",\n",
    "\"&Rho;\":\"Rho\",\n",
    "\"&Sigma;\":\"Sigma\",\n",
    "\"&Tau;\":\"Tau\",\n",
    "\"&Upsilon;\":\"Upsilon\",\n",
    "\"&Phi;\":\"Phi\",\n",
    "\"&Chi;\":\"Chi\",\n",
    "\"&Psi;\":\"Psi\",\n",
    "\"&Omega;\":\"Omega\",\n",
    "\"&alpha;\":\"alpha\",\n",
    "\"&beta;\":\"beta\",\n",
    "\"&gamma;\":\"gamma\",\n",
    "\"&delta;\":\"delta\",\n",
    "\"&epsilon;\":\"epsilon\",\n",
    "\"&zeta;\":\"zeta\",\n",
    "\"&eta;\":\"eta\",\n",
    "\"&theta;\":\"theta\",\n",
    "\"&iota;\":\"iota\",\n",
    "\"&kappa;\":\"kappa\",\n",
    "\"&lambda;\":\"lambda\",\n",
    "\"&mu;\":\"mu\",\n",
    "\"&nu;\":\"nu\",\n",
    "\"&xi;\":\"xi\",\n",
    "\"&omicron;\":\"omicron\",\n",
    "\"&pi;\":\"pi\",\n",
    "\"&rho;\":\"rho\",\n",
    "\"&sigmaf;\":\"sigmaf\",\n",
    "\"&sigma;\":\"sigma\",\n",
    "\"&tau;\":\"tau\",\n",
    "\"&upsilon;\":\"upsilon\",\n",
    "\"&phi;\":\"phi\",\n",
    "\"&chi;\":\"chi\",\n",
    "\"&psi;\":\"psi\",\n",
    "\"&omega;\":\"omega\",\n",
    "\"&thetasym;\":\"thetasym\",\n",
    "\"&upsih;\":\"upsih\",\n",
    "\"&piv;\":\"piv\",\n",
    "\"&bull;\":\"bull\",\n",
    "\"&hellip;\":\"hellip\",\n",
    "\"&prime;\":\"prime\",\n",
    "\"&Prime;\":\"Prime\",\n",
    "\"&oline;\":\"oline\",\n",
    "\"&frasl;\":\"frasl\",\n",
    "\"&weierp;\":\"weierp\",\n",
    "\"&image;\":\"image\",\n",
    "\"&real;\":\"real\",\n",
    "\"&trade;\":\"trade\",\n",
    "\"&alefsym;\":\"alefsym\",\n",
    "\"&larr;\":\"larr\",\n",
    "\"&uarr;\":\"uarr\",\n",
    "\"&rarr;\":\"rarr\",\n",
    "\"&darr;\":\"darr\",\n",
    "\"&harr;\":\"harr\",\n",
    "\"&crarr;\":\"crarr\",\n",
    "\"&lArr;\":\"lArr\",\n",
    "\"&uArr;\":\"uArr\",\n",
    "\"&rArr;\":\"rArr\",\n",
    "\"&dArr;\":\"dArr\",\n",
    "\"&hArr;\":\"hArr\",\n",
    "\"&forall;\":\"forall\",\n",
    "\"&part;\":\"part\",\n",
    "\"&exist;\":\"exist\",\n",
    "\"&empty;\":\"empty\",\n",
    "\"&nabla;\":\"nabla\",\n",
    "\"&isin;\":\"isin\",\n",
    "\"&notin;\":\"notin\",\n",
    "\"&ni;\":\"ni\",\n",
    "\"&prod;\":\"prod\",\n",
    "\"&sum;\":\"sum\",\n",
    "\"&minus;\":\"minus\",\n",
    "\"&lowast;\":\"lowast\",\n",
    "\"&radic;\":\"radic\",\n",
    "\"&prop;\":\"prop\",\n",
    "\"&infin;\":\"infin\",\n",
    "\"&ang;\":\"ang\",\n",
    "\"&and;\":\"and\",\n",
    "\"&or;\":\"or\",\n",
    "\"&cap;\":\"cap\",\n",
    "\"&cup;\":\"cup\",\n",
    "\"&int;\":\"int\",\n",
    "\"&there4;\":\"there4\",\n",
    "\"&sim;\":\"sim\",\n",
    "\"&cong;\":\"cong\",\n",
    "\"&asymp;\":\"asymp\",\n",
    "\"&ne;\":\"ne\",\n",
    "\"&equiv;\":\"equiv\",\n",
    "\"&le;\":\"le\",\n",
    "\"&ge;\":\"ge\",\n",
    "\"&sub;\":\"sub\",\n",
    "\"&sup;\":\"sup\",\n",
    "\"&nsub;\":\"nsub\",\n",
    "\"&sube;\":\"sube\",\n",
    "\"&supe;\":\"supe\",\n",
    "\"&oplus;\":\"oplus\",\n",
    "\"&otimes;\":\"otimes\",\n",
    "\"&perp;\":\"perp\",\n",
    "\"&sdot;\":\"sdot\",\n",
    "\"&lceil;\":\"lceil\",\n",
    "\"&rceil;\":\"rceil\",\n",
    "\"&lfloor;\":\"lfloor\",\n",
    "\"&rfloor;\":\"rfloor\",\n",
    "\"&lang;\":\"lang\",\n",
    "\"&rang;\":\"rang\",\n",
    "\"&loz;\":\"loz\",\n",
    "\"&spades;\":\"spades\",\n",
    "\"&clubs;\":\"clubs\",\n",
    "\"&hearts;\":\"hearts\",\n",
    "\"&diams;\":\"diams\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca4bcd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b359620f0548aabfce7c60e2b90629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87653933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tlist = tqdm(Lines)\n",
    "for i, line in enumerate(tlist):\n",
    "    for k,v in specdict2.items():\n",
    "        while k in line:\n",
    "            line = line.replace(k, v)\n",
    "    Lines[i] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a86e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dblp_cleaned.txt','w') as f:\n",
    "    for line in Lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09974fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not used\n",
    "import html\n",
    "from tqdm.notebook import tqdm\n",
    "tlist = tqdm(Lines)\n",
    "for i, line in enumerate(tlist):\n",
    "    line = html.unescape(line)  #replace escaped characters with utf-8 special characters\n",
    "    line = line.encode(\"ascii\", \"replace\") #replace utf-8 special characters with question mark\n",
    "    line = line.decode(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    line = line.replace('&', ' and ')\n",
    "    Lines[i] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709cadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
